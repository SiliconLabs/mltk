import importlib
import numpy as np

from .audio_feature_generator_settings import AudioFeatureGeneratorSettings


class AudioFeatureGenerator:
    """AudioFeatureGenerator Interface

    .. seealso::
       - `AudioFeatureGenerator documentation <https://siliconlabs.github.io/mltk/docs/audio/audio_feature_generator.html>`_
       - `AudioFeatureGenerator Python Wrapper <https://siliconlabs.github.io/mltk/docs/cpp_development/wrappers/audio_feature_generator_wrapper.html>`_
       - `Microfrontend implementation <https://github.com/siliconlabs/mltk/tree/master/cpp/shared/microfrontend>`_
       - `ParallelAudioDataGenerator API docs <https://siliconlabs.github.io/mltk/docs/python_api/data_preprocessing/audio_data_generator.html>`_
    """

    def __init__(self, settings: AudioFeatureGeneratorSettings):
        try:
            wrapper_module = importlib.import_module('mltk.core.preprocess.audio.audio_feature_generator._audio_feature_generator_wrapper')
        except (ImportError, ModuleNotFoundError) as e:
            raise ImportError(f'Failed to import the AudioFeatureGenerator wrapper C++ shared library, err: {e}\n' \
                            'This likely means you need to re-build the AudioFeatureGenerator wrapper package\n\n') from e

        self._spectrogram_shape = settings.spectrogram_shape
        self._wrapper = wrapper_module.AudioFeatureGeneratorWrapper(settings)



    def process_sample(self, sample: np.ndarray, dtype=np.float32) -> np.ndarray:
        """Convert the provided 1D audio sample to a 2D spectrogram using the AudioFeatureGenerator

        The generated 2D spectrogram dimensions are calculated as follows::

           sample_length = len(sample) = int(sample_length_ms*sample_rate_hz / 1000)
           window_size_length = int(window_size_ms * sample_rate_hz / 1000)
           window_step_length = int(window_step_ms * sample_rate_hz / 1000)
           height = n_features = (sample_length - window_size_length) // window_step_length + 1
           width = n_channels = AudioFeatureGeneratorSettings.filterbank_n_channels


        The dtype argument specifies the data type of the returned spectrogram.
        This must be one of the following:

        * **uint16**: This the raw value generated by the internal AudioFeatureGenerator library
        * **float32**: This is the uint16 value directly casted to a float32
        * **int8**: This is the int8 value generated by the TFLM "micro features" library.
            Refer to the following for the magic that happens here: `micro_features_generator.cc#L84 <https://github.com/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/examples/micro_speech/micro_features/micro_features_generator.cc#L84>`_

        Args:
            sample: [sample_length] int16 audio sample
            dtype: Output data type, must be int8, uint16, or float32 

        Returns:
            [n_features, n_channels] int8, uint16, or float32  spectrogram
        """
        spectrogram = np.zeros(self._spectrogram_shape, dtype=dtype)
        self._wrapper.process_sample(sample, spectrogram)
        return spectrogram


    def activity_was_detected(self) -> bool:
        """Return if activity was detected in the previously processed sample"""
        return self._wrapper.activity_was_detected()