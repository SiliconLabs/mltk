
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width,initial-scale=1">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="title" content="Machine Learning Toolkit">
<meta name="description" content="A Python package with command-line utilities and scripts to aid the development of machine learning models for Silicon Lab's embedded platforms">
<meta name="keywords" content="machine learning, machine-learning, machinelearning, ml, ai, iot, Internet of things, aiot, tinyml, tensorflow, tensorflow-lite, tensorflow-lite-micro, keras-tensorflow, keras, tflite, embedded, embedded-systems, mcu, Microcontrollers, hardware, python, c++, cmake, keras, numpy, silabs, silicon labs">
<meta name="robots" content="index, follow">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="language" content="English">
<meta name="author" content="Silicon Labs">
  <meta name="lang:clipboard.copy" content="Copy to clipboard">
  <meta name="lang:clipboard.copied" content="Copied to clipboard">
  <meta name="lang:search.language" content="en">
  <meta name="lang:search.pipeline.stopwords" content="True">
  <meta name="lang:search.pipeline.trimmer" content="True">
  <meta name="lang:search.result.none" content="No matching documents">
  <meta name="lang:search.result.one" content="1 matching document">
  <meta name="lang:search.result.other" content="# matching documents">
  <meta name="lang:search.tokenizer" content="[\s\-]+">

  
    <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&display=fallback" rel="stylesheet">

    <style>
      body,
      input {
        font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif
      }

      code,
      kbd,
      pre {
        font-family: "Roboto Mono", "Courier New", Courier, monospace
      }
    </style>
  

  <link rel="stylesheet" href="../../_static/stylesheets/application.css"/>
  <link rel="stylesheet" href="../../_static/stylesheets/application-palette.css"/>
  <link rel="stylesheet" href="../../_static/stylesheets/application-fixes.css"/>
  
  <link rel="stylesheet" href="../../_static/fonts/material-icons.css"/>
  
  <meta name="theme-color" content="#3f51b5">
  <script src="../../_static/javascripts/modernizr.js"></script>
  
<script async src="https://www.googletagmanager.com/gtag/js?id=G-HZ5MW943WF"></script>
<script>
    window.gTrackingId = 'G-HZ5MW943WF';
</script>
<meta name="google-site-verification" content="dsSsmnE2twOnfSAQk5zBBTrjMArsTJj809Bp-8mVlIw" />
  
  
    <title>Keyword Spotting - Pac-Man &#8212; MLTK 0.15.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/material.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/design-tabs.js"></script>
    <script src="../../_static/js/custom.js"></script>
    <script src="../../_static/js/apitoc.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Keyword Spotting - Alexa" href="keyword_spotting_alexa.html" />
    <link rel="prev" title="Keyword Spotting - On/Off" href="keyword_spotting_on_off.html" />
  
   

  </head>
  <body dir=ltr
        data-md-color-primary=red data-md-color-accent=light-blue>
  
  <svg class="md-svg">
    <defs data-children-count="0">
      
      <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
      
    </defs>
  </svg>
  
  <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer">
  <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search">
  <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
  <a href="#mltk/tutorials/keyword_spotting_pacman" tabindex="1" class="md-skip"> Skip to content </a>
  <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex navheader">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../../index.html" title="MLTK 0.15.0 documentation"
           class="md-header-nav__button md-logo">
          
              <img src="../../_static/logo.png"
                   alt="MLTK 0.15.0 documentation logo">
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          <span class="md-header-nav__topic">Machine Learning Toolkit</span>
          <span class="md-header-nav__topic"> Keyword Spotting - Pac-Man </span>
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
        
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" action="../../search.html" method="get" name="search">
      <input type="text" class="md-search__input" name="q" placeholder=""Search""
             autocapitalize="off" autocomplete="off" spellcheck="false"
             data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>

      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            <a href="https://github.com/siliconlabs/mltk" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    MLTK Github Repository
  </div>
</a>
          </div>
        </div>
      
      
    </div>
  </nav>
</header>

  
  <div class="md-container">
    
    
    
  <nav class="md-tabs" data-md-component="tabs">
    <div class="md-tabs__inner md-grid">
      <ul class="md-tabs__list">
            
            <li class="md-tabs__item"><a href="https://docs.silabs.com/gecko-platform/latest/machine-learning/tensorflow/overview" class="md-tabs__link">Gecko SDK Documentation</a></li>
            
            <li class="md-tabs__item"><a href="https://github.com/tensorflow/tflite-micro" class="md-tabs__link">Tensorflow-Lite Micro Repository</a></li>
            
            <li class="md-tabs__item"><a href="https://www.tensorflow.org/learn" class="md-tabs__link">Tensorflow Documentation</a></li>
          <li class="md-tabs__item"><a href="../../docs/tutorials.html" class="md-tabs__link">Tutorials</a></li>
      </ul>
    </div>
  </nav>
    <main class="md-main">
      <div class="md-main__inner md-grid" data-md-component="container">
        
          <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../../index.html" title="MLTK 0.15.0 documentation" class="md-nav__button md-logo">
      
        <img src="../../_static/logo.png" alt=" logo" width="48" height="48">
      
    </a>
    <a href="../../index.html"
       title="MLTK 0.15.0 documentation">Machine Learning Toolkit</a>
  </label>
    <div class="md-nav__source">
      <a href="https://github.com/siliconlabs/mltk" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    MLTK Github Repository
  </div>
</a>
    </div>
  
  

  
  <ul class="md-nav__list">
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Basics</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../docs/overview.html" class="md-nav__link">Overview</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../docs/why_mltk.html" class="md-nav__link">Why MLTK?</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../docs/installation.html" class="md-nav__link">Installation</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../docs/command_line/index.html" class="md-nav__link">Command-Line</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../docs/guides/index.html" class="md-nav__link">Modeling Guides</a>
      
    
    </li>
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Usage</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../docs/tutorials.html" class="md-nav__link">Tutorials</a>
      <ul class="md-nav__list"> 
    <li class="md-nav__item">
    
    
      <a href="keyword_spotting_on_off.html" class="md-nav__link">Keyword Spotting - On/Off</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    <label class="md-nav__link md-nav__link--active" for="__toc"> Keyword Spotting - Pac-Man </label>
    
      <a href="#" class="md-nav__link md-nav__link--active">Keyword Spotting - Pac-Man</a>
      
        
<nav class="md-nav md-nav--secondary">
    <label class="md-nav__title" for="__toc">Contents</label>
  <ul class="md-nav__list" data-md-scrollfix="" id="localtoc">
        <li class="md-nav__item"><a href="#mltk-tutorials-keyword-spotting-pacman--page-root" class="md-nav__link">Keyword Spotting - Pac-Man</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#live-demo" class="md-nav__link">Live Demo</a>
        </li>
        <li class="md-nav__item"><a href="#quick-links" class="md-nav__link">Quick Links</a>
        </li>
        <li class="md-nav__item"><a href="#overview" class="md-nav__link">Overview</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#objectives" class="md-nav__link">Objectives</a>
        </li>
        <li class="md-nav__item"><a href="#content" class="md-nav__link">Content</a>
        </li>
        <li class="md-nav__item"><a href="#running-this-tutorial-from-a-notebook" class="md-nav__link">Running this tutorial from a notebook</a>
        </li>
        <li class="md-nav__item"><a href="#running-this-tutorial-from-the-command-line" class="md-nav__link">Running this tutorial from the command-line</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#required-hardware" class="md-nav__link">Required Hardware</a>
        </li>
        <li class="md-nav__item"><a href="#install-mltk-python-package" class="md-nav__link">Install MLTK Python Package</a>
        </li>
        <li class="md-nav__item"><a href="#prerequisite-reading" class="md-nav__link">Prerequisite Reading</a>
        </li>
        <li class="md-nav__item"><a href="#creating-the-machine-learning-model" class="md-nav__link">Creating the Machine Learning Model</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#select-the-dataset" class="md-nav__link">Select the dataset</a>
        </li>
        <li class="md-nav__item"><a href="#model-parameter-tradeoffs" class="md-nav__link">Model Parameter Tradeoffs</a>
        </li>
        <li class="md-nav__item"><a href="#audio-feature-generator-settings" class="md-nav__link">Audio Feature Generator Settings</a>
        </li>
        <li class="md-nav__item"><a href="#module-architecture" class="md-nav__link">Module Architecture</a>
        </li>
        <li class="md-nav__item"><a href="#audio-data-generator" class="md-nav__link">Audio Data Generator</a>
        </li>
        <li class="md-nav__item"><a href="#profiling-the-model" class="md-nav__link">Profiling the model</a>
        </li>
        <li class="md-nav__item"><a href="#training-the-model" class="md-nav__link">Training the model</a>
        </li>
        <li class="md-nav__item"><a href="#train-in-cloud" class="md-nav__link">Train in cloud</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#creating-the-firmware-application" class="md-nav__link">Creating the Firmware Application</a>
        </li>
        <li class="md-nav__item"><a href="#creating-the-pac-man-webpage" class="md-nav__link">Creating the Pac-Man Webpage</a>
        </li>
        <li class="md-nav__item"><a href="#running-the-demo" class="md-nav__link">Running the Demo</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#build-firmware-application-from-source" class="md-nav__link">Build firmware application from source</a>
        </li>
        <li class="md-nav__item"><a href="#run-webpage-locally" class="md-nav__link">Run webpage locally</a>
        </li></ul>
            </nav>
        </li></ul>
            </nav>
        </li>
      <script type="text/javascript" src=../../_static/js/apitoc.js></script>
  </ul>
</nav>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="keyword_spotting_alexa.html" class="md-nav__link">Keyword Spotting - Alexa</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="image_classification.html" class="md-nav__link">Image Classification - Rock, Paper, Scissors</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="cloud_training_with_vast_ai.html" class="md-nav__link">Cloud Training with vast.ai</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="cloud_logging_with_wandb.html" class="md-nav__link">Cloud Logging with Weights & Biases</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="model_optimization.html" class="md-nav__link">Model Optimization for MVP Hardware Accelerator</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="keyword_spotting_with_transfer_learning.html" class="md-nav__link">Keyword Spotting with Transfer Learning</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="fingerprint_authentication.html" class="md-nav__link">Fingerprint Authentication</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="onnx_to_tflite.html" class="md-nav__link">ONNX to TF-Lite Model Conversion</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="model_debugging.html" class="md-nav__link">Model Debugging</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="add_existing_script_to_mltk.html" class="md-nav__link">Add an Existing Script to the MLTK</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="synthetic_audio_dataset_generation.html" class="md-nav__link">Synthetic Audio Dataset Generation</a>
      
    
    </li></ul>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../docs/examples.html" class="md-nav__link">API Examples</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../docs/python_api/index.html" class="md-nav__link">API Reference</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../docs/python_api/models/index.html" class="md-nav__link">Reference Models</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../docs/python_api/datasets/index.html" class="md-nav__link">Reference Datasets</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../docs/cpp_development/index.html" class="md-nav__link">C++ Development</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../docs/cpp_development/examples/index.html" class="md-nav__link">C++ Examples</a>
      
    
    </li>
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Audio Related</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../docs/audio/keyword_spotting_overview.html" class="md-nav__link">Keyword Spotting Overview</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../docs/audio/audio_feature_generator.html" class="md-nav__link">Audio Feature Generator</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../docs/audio/audio_utilities.html" class="md-nav__link">Audio Utilities</a>
      
    
    </li>
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Other Information</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../docs/faq/index.html" class="md-nav__link">Frequently Asked Questions</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../docs/other/quick_reference.html" class="md-nav__link">Quick Reference</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../docs/other/supported_hardware.html" class="md-nav__link">Supported Hardware</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../docs/guides/notebook_examples_guide.html" class="md-nav__link">Notebook Examples Guide</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../docs/other/settings_file.html" class="md-nav__link">Settings File</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../docs/other/environment_variables.html" class="md-nav__link">Environment Variables</a>
      
    
    </li>
  </ul>
  

</nav>
              </div>
            </div>
          </div>
          <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                
<nav class="md-nav md-nav--secondary">
    <label class="md-nav__title" for="__toc">Contents</label>
  <ul class="md-nav__list" data-md-scrollfix="" id="localtoc">
        <li class="md-nav__item"><a href="#mltk-tutorials-keyword-spotting-pacman--page-root" class="md-nav__link">Keyword Spotting - Pac-Man</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#live-demo" class="md-nav__link">Live Demo</a>
        </li>
        <li class="md-nav__item"><a href="#quick-links" class="md-nav__link">Quick Links</a>
        </li>
        <li class="md-nav__item"><a href="#overview" class="md-nav__link">Overview</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#objectives" class="md-nav__link">Objectives</a>
        </li>
        <li class="md-nav__item"><a href="#content" class="md-nav__link">Content</a>
        </li>
        <li class="md-nav__item"><a href="#running-this-tutorial-from-a-notebook" class="md-nav__link">Running this tutorial from a notebook</a>
        </li>
        <li class="md-nav__item"><a href="#running-this-tutorial-from-the-command-line" class="md-nav__link">Running this tutorial from the command-line</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#required-hardware" class="md-nav__link">Required Hardware</a>
        </li>
        <li class="md-nav__item"><a href="#install-mltk-python-package" class="md-nav__link">Install MLTK Python Package</a>
        </li>
        <li class="md-nav__item"><a href="#prerequisite-reading" class="md-nav__link">Prerequisite Reading</a>
        </li>
        <li class="md-nav__item"><a href="#creating-the-machine-learning-model" class="md-nav__link">Creating the Machine Learning Model</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#select-the-dataset" class="md-nav__link">Select the dataset</a>
        </li>
        <li class="md-nav__item"><a href="#model-parameter-tradeoffs" class="md-nav__link">Model Parameter Tradeoffs</a>
        </li>
        <li class="md-nav__item"><a href="#audio-feature-generator-settings" class="md-nav__link">Audio Feature Generator Settings</a>
        </li>
        <li class="md-nav__item"><a href="#module-architecture" class="md-nav__link">Module Architecture</a>
        </li>
        <li class="md-nav__item"><a href="#audio-data-generator" class="md-nav__link">Audio Data Generator</a>
        </li>
        <li class="md-nav__item"><a href="#profiling-the-model" class="md-nav__link">Profiling the model</a>
        </li>
        <li class="md-nav__item"><a href="#training-the-model" class="md-nav__link">Training the model</a>
        </li>
        <li class="md-nav__item"><a href="#train-in-cloud" class="md-nav__link">Train in cloud</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#creating-the-firmware-application" class="md-nav__link">Creating the Firmware Application</a>
        </li>
        <li class="md-nav__item"><a href="#creating-the-pac-man-webpage" class="md-nav__link">Creating the Pac-Man Webpage</a>
        </li>
        <li class="md-nav__item"><a href="#running-the-demo" class="md-nav__link">Running the Demo</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#build-firmware-application-from-source" class="md-nav__link">Build firmware application from source</a>
        </li>
        <li class="md-nav__item"><a href="#run-webpage-locally" class="md-nav__link">Run webpage locally</a>
        </li></ul>
            </nav>
        </li></ul>
            </nav>
        </li>
      <script type="text/javascript" src=../../_static/js/apitoc.js></script>
  </ul>
</nav>
              </div>
            </div>
          </div>
        
        <div class="md-content">

          
          <div class="breadcrumbs md-typeset">
            <ul class="breadcrumb">
              <li></li>
              <li><a href="../../index.html"><i class="md-icon">home</i></a></li>
                <li><a href="../../docs/tutorials.html" accesskey="U">Tutorials</a></li>

              <li class="activate"><a>Keyword Spotting - Pac-Man</a></li>
            </ul>
          </div>
          

          <article class="md-content__inner md-typeset" role="main">
            
  <section id="keyword-spotting-pac-man">
<h1 id="mltk-tutorials-keyword-spotting-pacman--page-root">Keyword Spotting - Pac-Man<a class="headerlink" href="#mltk-tutorials-keyword-spotting-pacman--page-root" title="Permalink to this heading">¶</a></h1>
<p>This tutorial describes how to use the MLTK to develop a “Pac-Man” keyword spotting demo.</p>
<p>The basic setup for this demo is as follows:<br/>
<img alt="" src="../../_images/pacman_demo_overview.png"/></p>
<p>In the demo, embedded machine learning is used to detect the keywords:</p>
<ul class="simple">
<li><p><strong>Left</strong></p></li>
<li><p><strong>Right</strong></p></li>
<li><p><strong>Up</strong></p></li>
<li><p><strong>Down</strong></p></li>
<li><p><strong>Stop</strong></p></li>
<li><p><strong>Go</strong></p></li>
</ul>
<p>When a keyword is detected, its corresponding ID is sent to a webpage via Bluetooth Low-Energy. The webpage uses Javascript to process keyword ID to move the Pac-Man accordingly.</p>
<section id="live-demo">
<h2 id="live-demo">Live Demo<a class="headerlink" href="#live-demo" title="Permalink to this heading">¶</a></h2>
<p>A live demo for this tutorial is available online:<br/>
<a class="reference external" href="https://mltk-pacman.web.app">https://mltk-pacman.web.app</a></p>
<p><strong>NOTE:</strong> To use this demo, you must have a <a class="reference internal" href="../../docs/other/supported_hardware.html#brd2601"><span class="std std-doc">BRD2601</span></a> development board.</p>
</section>
<section id="quick-links">
<h2 id="quick-links">Quick Links<a class="headerlink" href="#quick-links" title="Permalink to this heading">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/SiliconLabs/mltk/blob/master/mltk/tutorials/keyword_spotting_pacman.ipynb">GitHub Source</a> - View this tutorial on Github</p></li>
<li><p><a class="reference external" href="https://colab.research.google.com/github/siliconlabs/mltk/blob/master/mltk/tutorials/keyword_spotting_pacman.ipynb">Run on Colab</a> - Run this tutorial on Google Colab</p></li>
<li><p><a class="reference internal" href="cloud_training_with_vast_ai.html"><span class="doc std std-doc">Train in the “Cloud”</span></a> - <em>Vastly</em> improve training times by training this model in the “cloud”</p></li>
<li><p><a class="reference internal" href="../../docs/cpp_development/examples/ble_audio_classifier.html"><span class="doc std std-doc">C++ Example Application</span></a> - View this tutorial’s associated C++ example application</p></li>
<li><p><a class="reference external" href="https://github.com/SiliconLabs/mltk/blob/master/cpp/shared/apps/ble_audio_classifier/web/pacman">Pac-Man Webpage Source</a> - View the Pac-Man webpage’s source code on Github</p></li>
<li><p><a class="reference internal" href="../../docs/python_api/models/siliconlabs/keyword_spotting_pacman_v3.html"><span class="doc std std-doc">Machine Learning Model</span></a> - View this tutorial’s associated machine learning model</p></li>
<li><p><a class="reference external" href="https://mltk-pacman.web.app">Live Demo</a> - Play Pac-Man using the keywords: Left, Right, Up, Down</p></li>
<li><p><a class="reference external" href="https://cms.tinyml.org/wp-content/uploads/talks2022/tinyML_Talks_Dan_Riedler_221025.pdf">Presentation PDF</a> - Presentation describing how this demo was created</p></li>
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=xhiFMDOyA0g">Presentation Video</a> - YouTube video of the presentation given to TinyML.org for this tutorial</p></li>
</ul>
</section>
<section id="overview">
<h2 id="overview">Overview<a class="headerlink" href="#overview" title="Permalink to this heading">¶</a></h2>
<section id="objectives">
<h3 id="objectives">Objectives<a class="headerlink" href="#objectives" title="Permalink to this heading">¶</a></h3>
<p>After completing this tutorial, you will have:</p>
<ol class="arabic simple">
<li><p>A better understanding of how audio classification machine learning models work</p></li>
<li><p>All of the tools needed to develop your own keyword spotting model</p></li>
<li><p>A better understanding of how to issue commands to a webpage from an embedded MCU via Bluetooth Low Energy</p></li>
<li><p>A working demo to play the game Pac-Man using the keywords: “Left”, “Right”, “Up”, “Down”, “Stop”, “Go”</p></li>
</ol>
</section>
<section id="content">
<h3 id="content">Content<a class="headerlink" href="#content" title="Permalink to this heading">¶</a></h3>
<p>This tutorial is divided into the following sections:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#prerequisite-reading"><span class="std std-doc">Prerequisite reading</span></a></p></li>
<li><p><a class="reference internal" href="#creating-the-machine-learning-model"><span class="std std-doc">Creating the machine learning model</span></a></p></li>
<li><p><a class="reference internal" href="#creating-the-firmware-application"><span class="std std-doc">Creating the firmware application</span></a></p></li>
<li><p><a class="reference internal" href="#creating-the-pac-man-webpage"><span class="std std-doc">Creating the Pac-Man webpage</span></a></p></li>
<li><p><a class="reference internal" href="#running-the-demo"><span class="std std-doc">Running the demo</span></a></p></li>
</ul>
</section>
<section id="running-this-tutorial-from-a-notebook">
<h3 id="running-this-tutorial-from-a-notebook">Running this tutorial from a notebook<a class="headerlink" href="#running-this-tutorial-from-a-notebook" title="Permalink to this heading">¶</a></h3>
<p>For documentation purposes, this tutorial was designed to run within a <a class="reference external" href="https://jupyter.org">Jupyter Notebook</a>.
The notebook can either run locally on your PC <em>or</em> on a remote server like <a class="reference external" href="https://colab.research.google.com/notebooks/welcome.ipynb">Google Colab</a>.</p>
<ul class="simple">
<li><p>Refer to the <a class="reference internal" href="../../docs/guides/notebook_examples_guide.html"><span class="doc std std-doc">Notebook Examples Guide</span></a> for more details</p></li>
<li><p>Click here: <a class="reference external" href="https://colab.research.google.com/github/siliconlabs/mltk/blob/master/mltk/tutorials/keyword_spotting_pacman.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a> to run this tutorial interactively in your browser</p></li>
</ul>
<p><strong>NOTE:</strong> Some of the following sections require this tutorial to be running locally with a supported embedded platform connected.</p>
</section>
<section id="running-this-tutorial-from-the-command-line">
<h3 id="running-this-tutorial-from-the-command-line">Running this tutorial from the command-line<a class="headerlink" href="#running-this-tutorial-from-the-command-line" title="Permalink to this heading">¶</a></h3>
<p>While this tutorial uses a <a class="reference external" href="https://jupyter.org">Jupyter Notebook</a>,
the recommended approach is to use your favorite text editor and standard command terminal, no Jupyter Notebook required.</p>
<p>See the <a class="reference external" href="../../docs/installation.html#standard-python-package">Standard Python Package Installation</a> guide for more details on how to enable the <code class="docutils literal notranslate"><span class="pre">mltk</span></code> command in your local terminal.</p>
<p>In this mode, when you encounter a <code class="docutils literal notranslate"><span class="pre">!mltk</span></code> command in this tutorial, the command should actually run in your local terminal (excluding the <code class="docutils literal notranslate"><span class="pre">!</span></code>)</p>
</section>
</section>
<section id="required-hardware">
<h2 id="required-hardware">Required Hardware<a class="headerlink" href="#required-hardware" title="Permalink to this heading">¶</a></h2>
<p>To play this tutorial’s game using machine learning + keyword spotting, the <a class="reference internal" href="../../docs/other/supported_hardware.html#brd2601"><span class="std std-doc">BRD2601</span></a> development board is required.</p>
</section>
<section id="install-mltk-python-package">
<h2 id="install-mltk-python-package">Install MLTK Python Package<a class="headerlink" href="#install-mltk-python-package" title="Permalink to this heading">¶</a></h2>
<p>Before using the MLTK, it must first be installed.<br/>
See the <a class="reference internal" href="../../docs/installation.html"><span class="doc std std-doc">Installation Guide</span></a> for more details.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>silabs-mltk
</pre></div>
</div>
</div>
</div>
<p>All MLTK modeling operations are accessible via the <code class="docutils literal notranslate"><span class="pre">mltk</span></code> command.<br/>
Run the command <code class="docutils literal notranslate"><span class="pre">mltk</span> <span class="pre">--help</span></code> to ensure it is working.<br/>
<strong>NOTE:</strong> The exclamation point <code class="docutils literal notranslate"><span class="pre">!</span></code> tells the Notebook to run a shell command, it is not required in a <a class="reference external" href="../../docs/installation.html#standard-python-package">standard terminal</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>mltk<span class="w"> </span>--help
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Usage: mltk [OPTIONS] COMMAND [ARGS]...

  Silicon Labs Machine Learning Toolkit

  This is a Python package with command-line utilities and scripts to aid the
  development of machine learning models for Silicon Lab's embedded platforms.

Options:
  --version         Display the version of this mltk package and exit
  --gpu / --no-gpu  Disable usage of the GPU. 
                    This does the same as defining the environment variable: CUDA_VISIBLE_DEVICES=-1
                    Example:
                    mltk --no-gpu train image_example1
  --help            Show this message and exit.

Commands:
  build               MLTK build commands
  classify_audio      Classify keywords/events detected in a microphone's...
  classify_image      Classify images detected by a camera connected to...
  commander           Silab's Commander Utility
  compile             Compile a model for the specified accelerator
  custom              Custom Model Operations
  evaluate            Evaluate a trained ML model
  fingerprint_reader  View/save fingerprints captured by the fingerprint...
  profile             Profile a model
  quantize            Quantize a model into a .tflite file
  summarize           Generate a summary of a model
  train               Train an ML model
  update_params       Update the parameters of a previously trained model
  utest               Run the all unit tests
  view                View an interactive graph of the given model in a...
  view_audio          View the spectrograms generated by the...
</pre></div>
</div>
</div>
</div>
</section>
<section id="prerequisite-reading">
<h2 id="prerequisite-reading">Prerequisite Reading<a class="headerlink" href="#prerequisite-reading" title="Permalink to this heading">¶</a></h2>
<p>Before continuing with this tutorial, it is recommended to review the following documentation:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../../docs/audio/keyword_spotting_overview.html"><span class="doc std std-doc">Keyword Spotting Overview</span></a> - Provides overview of how embedded keyword spotting works</p></li>
<li><p><a class="reference internal" href="keyword_spotting_on_off.html"><span class="doc std std-doc">Keyword Spotting Tutorial</span></a> - Provides an in-depth tutorial on how to create a keyword spotting model</p></li>
</ul>
</section>
<section id="creating-the-machine-learning-model">
<h2 id="creating-the-machine-learning-model">Creating the Machine Learning Model<a class="headerlink" href="#creating-the-machine-learning-model" title="Permalink to this heading">¶</a></h2>
<p>The pre-defined <a class="reference internal" href="../../docs/guides/model_specification.html"><span class="doc std std-doc">Model Specification</span></a> used by the tutorial may be found on <a class="reference external" href="https://github.com/SiliconLabs/mltk/tree/master/mltk/models/siliconlabs/keyword_spotting_pacman_v3.py">Github</a>.</p>
<p>This model is a standard audio classification model designed to detect the classes:</p>
<ul class="simple">
<li><p>Left</p></li>
<li><p>Right</p></li>
<li><p>Up</p></li>
<li><p>Down</p></li>
<li><p>Stop</p></li>
<li><p>Go</p></li>
<li><p><em>unknown</em></p></li>
</ul>
<p>Additionally, this model augments the training samples by adding audio recorded while playing the Pac-Man game. In this way, the model can be more robust to the background noise generated while playing the game.</p>
<p>Refer to the model, <a class="reference internal" href="../../docs/python_api/models/siliconlabs/keyword_spotting_pacman_v3.html"><span class="doc std std-doc">keyword_spotting_pacman_v3</span></a> for more details.</p>
<section id="select-the-dataset">
<h3 id="select-the-dataset">Select the dataset<a class="headerlink" href="#select-the-dataset" title="Permalink to this heading">¶</a></h3>
<p>This model was trained using several different datasets:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../../docs/python_api/datasets/audio/direction_commands.html"><span class="doc std std-doc">mltk.datasets.audio.direction_commands</span></a> - Synthetically generated keywords: left, right, up, down, stop, go</p></li>
<li><p><a class="reference internal" href="../../docs/python_api/datasets/audio/speech_commands_v2.html"><span class="doc std std-doc">mltk.datasets.audio.speech_commands_v2</span></a> - Human generated keywords: left, right, up, down, stop, go</p></li>
<li><p><a class="reference internal" href="../../docs/python_api/datasets/audio/ml_commons/keywords.html"><span class="doc std std-doc">mltk.datasets.audio.mlcommons.ml_commons_keyword</span></a> - Large collection of keywords, random subset used for <em>unknown</em> class</p></li>
<li><p><a class="reference internal" href="../../docs/python_api/datasets/audio/background_noise/esc50.html"><span class="doc std std-doc">mltk.datasets.audio.background_noise.esc50</span></a> - Collection of various noises, random subset used for <em>unknown</em> class</p></li>
<li><p><a class="reference internal" href="../../docs/python_api/datasets/audio/background_noise/ambient.html"><span class="doc std std-doc">mltk.datasets.audio.background_noise.ambient</span></a> - Collection of various background noises, mixed into other samples for augmentation</p></li>
<li><p><a class="reference internal" href="../../docs/python_api/datasets/audio/background_noise/brd2601.html"><span class="doc std std-doc">mltk.datasets.audio.background_noise.brd2601</span></a> - “Silence” recorded by BRD2601 microphone, mixed into other samples to make them “sound” like they came from the BRD2601’s microphone</p></li>
<li><p>Pac-Man game noise - Recording from Pac-Man game play, mixed into other samples for augmentation</p></li>
</ul>
</section>
<section id="model-parameter-tradeoffs">
<h3 id="model-parameter-tradeoffs">Model Parameter Tradeoffs<a class="headerlink" href="#model-parameter-tradeoffs" title="Permalink to this heading">¶</a></h3>
<p>We have two main requirements when choosing the model parameters:</p>
<ul class="simple">
<li><p>We want the spectrogram resolution and convolutional filters to be as high as possible so that the model can make accurate predictions</p></li>
<li><p>We want the model’s computational complexity to be as small as possible so that inference latency is small and keywords are quickly detected while playing the game</p></li>
</ul>
<p>Note that the larger the spectrogram resolution, the larger the model’s input size and thus the larger the model’s computational complexity. Likewise, more convolution filters also increases the model’s computational complexity. As such, we need to find a middle ground for these parameters.</p>
<p>The MLTK offers two tools that can help when choosing these parameters:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../../docs/guides/model_profiler.html"><span class="doc std std-doc">Model Profiler</span></a> - This allows for profiling the model on the embedded device and determining the inference latency <strong>before</strong> fully training the model</p></li>
<li><p><a class="reference external" href="../../docs/audio/audio_feature_generator.html#audio-visualizer-utility">Audio Visualizer Utility</a> - This allows for visualizing the generated spectrograms in real-time</p></li>
</ul>
</section>
<section id="audio-feature-generator-settings">
<h3 id="audio-feature-generator-settings">Audio Feature Generator Settings<a class="headerlink" href="#audio-feature-generator-settings" title="Permalink to this heading">¶</a></h3>
<p>This model uses the following <a class="reference internal" href="../../docs/audio/audio_feature_generator.html"><span class="doc std std-doc">Audio Feature Generator</span></a> settings:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mltk.core.preprocess.audio.audio_feature_generator</span> <span class="kn">import</span> <span class="n">AudioFeatureGeneratorSettings</span>

<span class="n">frontend_settings</span> <span class="o">=</span> <span class="n">AudioFeatureGeneratorSettings</span><span class="p">()</span>

<span class="n">frontend_settings</span><span class="o">.</span><span class="n">sample_rate_hz</span> <span class="o">=</span> <span class="mi">16000</span>
<span class="n">frontend_settings</span><span class="o">.</span><span class="n">sample_length_ms</span> <span class="o">=</span> <span class="mi">1000</span>                       <span class="c1"># A 1s buffer should be enough to capture the keywords</span>
<span class="n">frontend_settings</span><span class="o">.</span><span class="n">window_size_ms</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">frontend_settings</span><span class="o">.</span><span class="n">window_step_ms</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">frontend_settings</span><span class="o">.</span><span class="n">filterbank_n_channels</span> <span class="o">=</span> <span class="mi">104</span>                   <span class="c1"># We want this value to be as large as possible</span>
                                                                <span class="c1"># while still allowing for the ML model to execute efficiently on the hardware</span>
<span class="n">frontend_settings</span><span class="o">.</span><span class="n">filterbank_upper_band_limit</span> <span class="o">=</span> <span class="mf">7500.0</span>
<span class="n">frontend_settings</span><span class="o">.</span><span class="n">filterbank_lower_band_limit</span> <span class="o">=</span> <span class="mf">125.0</span>           <span class="c1"># The dev board mic seems to have a lot of noise at lower frequencies</span>

<span class="n">frontend_settings</span><span class="o">.</span><span class="n">noise_reduction_enable</span> <span class="o">=</span> <span class="kc">True</span>                 <span class="c1"># Enable the noise reduction block to help ignore background noise in the field</span>
<span class="n">frontend_settings</span><span class="o">.</span><span class="n">noise_reduction_smoothing_bits</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">frontend_settings</span><span class="o">.</span><span class="n">noise_reduction_even_smoothing</span> <span class="o">=</span>  <span class="mf">0.025</span>
<span class="n">frontend_settings</span><span class="o">.</span><span class="n">noise_reduction_odd_smoothing</span> <span class="o">=</span> <span class="mf">0.06</span>
<span class="n">frontend_settings</span><span class="o">.</span><span class="n">noise_reduction_min_signal_remaining</span> <span class="o">=</span> <span class="mf">0.40</span>   <span class="c1"># This value is fairly large (which makes the background noise reduction small)</span>
                                                                <span class="c1"># But it has been found to still give good results</span>
                                                                <span class="c1"># i.e. There is still some background noise reduction,</span>
                                                                <span class="c1"># but the actual signal is still (mostly) untouched</span>

<span class="n">frontend_settings</span><span class="o">.</span><span class="n">dc_notch_filter_enable</span> <span class="o">=</span> <span class="kc">True</span>                 <span class="c1"># Enable the DC notch filter, to help remove the DC signal from the dev board's mic</span>
<span class="n">frontend_settings</span><span class="o">.</span><span class="n">dc_notch_filter_coefficient</span> <span class="o">=</span> <span class="mf">0.95</span>

<span class="n">frontend_settings</span><span class="o">.</span><span class="n">quantize_dynamic_scale_enable</span> <span class="o">=</span> <span class="kc">True</span>          <span class="c1"># Enable dynamic quantization, this dynamically converts the uint16 spectrogram to int8</span>
<span class="n">frontend_settings</span><span class="o">.</span><span class="n">quantize_dynamic_scale_range_db</span> <span class="o">=</span> <span class="mf">40.0</span>
</pre></div>
</div>
</div>
</div>
<p>This uses a 16kHz sample rate which was found to give better performance at the expense of more RAM.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">frontend_settings</span><span class="o">.</span><span class="n">sample_rate_hz</span> <span class="o">=</span> <span class="mi">16000</span>
</pre></div>
</div>
<p>To help reduce the model computational complexity, only a 1000ms sample length is used.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">frontend_settings</span><span class="o">.</span><span class="n">sample_length_ms</span> <span class="o">=</span> <span class="mi">1000</span>
</pre></div>
</div>
<p>The idea here is that it only takes at most ~1000ms to say any of the keywords (i.e. the audio buffer needs to be large enough to hold the entire keyword but no larger).</p>
<p>This model uses a window size of 30ms and a step of 10ms.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">frontend_settings</span><span class="o">.</span><span class="n">window_size_ms</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">frontend_settings</span><span class="o">.</span><span class="n">window_step_ms</span> <span class="o">=</span> <span class="mi">10</span>
</pre></div>
</div>
<p>These values were found experimentally using the <a class="reference external" href="../../docs/audio/audio_feature_generator.html#audio-visualizer-utility">Audio Visualizer Utility</a>.</p>
<p>104 frequency bins are used to generate the spectrogram:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">frontend_settings</span><span class="o">.</span><span class="n">filterbank_n_channels</span> <span class="o">=</span> <span class="mi">104</span>
</pre></div>
</div>
<p>Increasing this value improves the resolution of spectrogram at the cost of model computational complexity (i.e. inference latency).</p>
<p>The noise reduction block is enabled but uses a fairly large <code class="docutils literal notranslate"><span class="pre">min_signal_remaining</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">frontend_settings</span><span class="o">.</span><span class="n">noise_reduction_enable</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">frontend_settings</span><span class="o">.</span><span class="n">noise_reduction_smoothing_bits</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">frontend_settings</span><span class="o">.</span><span class="n">noise_reduction_even_smoothing</span> <span class="o">=</span>  <span class="mf">0.025</span>
<span class="n">frontend_settings</span><span class="o">.</span><span class="n">noise_reduction_odd_smoothing</span> <span class="o">=</span> <span class="mf">0.06</span>
<span class="n">frontend_settings</span><span class="o">.</span><span class="n">noise_reduction_min_signal_remaining</span> <span class="o">=</span> <span class="mf">0.40</span>
</pre></div>
</div>
<p>This helps to reduce background noise in the field.<br/>
<strong>NOTE:</strong> We also add padding to the audio samples during training to “warm up” the noise reduction block when generating the spectrogram using the
<a class="reference internal" href="../../docs/audio/audio_feature_generator.html"><span class="doc std std-doc">Audio Feature Generator</span></a>. See the <code class="docutils literal notranslate"><span class="pre">audio_pipeline_with_augmentations()</span></code>
function in <a class="reference external" href="../../docs/python_api/models/siliconlabs/keyword_spotting_pacman_v3.html#model-specification">keyword_spotting_pacman_v3.py</a> for more details.</p>
<p>The DC notch filter was enabled to help remove the DC component from the development board’s microphone:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">frontend_settings</span><span class="o">.</span><span class="n">dc_notch_filter_enable</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># Enable the DC notch filter</span>
<span class="n">frontend_settings</span><span class="o">.</span><span class="n">dc_notch_filter_coefficient</span> <span class="o">=</span> <span class="mf">0.95</span>
</pre></div>
</div>
<p>Dynamic quantization was enabled to convert the generated spectrogram from uint16 to int8</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">frontend_settings</span><span class="o">.</span><span class="n">quantize_dynamic_scale_enable</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># Enable dynamic quantization</span>
<span class="n">frontend_settings</span><span class="o">.</span><span class="n">quantize_dynamic_scale_range_db</span> <span class="o">=</span> <span class="mf">40.0</span>
</pre></div>
</div>
</section>
<section id="module-architecture">
<h3 id="module-architecture">Module Architecture<a class="headerlink" href="#module-architecture" title="Permalink to this heading">¶</a></h3>
<p>The model is based on the <a class="reference external" href="https://arxiv.org/pdf/2010.09960.pdf">Temporal efficient neural network (TENet)</a> model architecture.</p>
<blockquote>
<div><p>A network for processing spectrogram data using temporal and depthwise convolutions. The network treats the [T, F] spectrogram as a timeseries shaped [T, 1, F].</p>
</div></blockquote>
<p>More details at <a class="reference internal" href="../../docs/python_api/models/common_models.html#tenet"><span class="std std-doc">mltk.models.shared.tenet.TENet</span></a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">my_model_builder</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">MyModel</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Build the Keras model</span>
<span class="sd">    """</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">input_shape</span>
    <span class="c1"># NOTE: This model requires the input shape: &lt;time, 1, features&gt;</span>
    <span class="c1">#       while the embedded device expects: &lt;time, features, 1&gt;</span>
    <span class="c1">#       Since the &lt;time&gt; axis is still row-major, we can swap the &lt;features&gt; with 1 without issue</span>
    <span class="n">time_size</span><span class="p">,</span> <span class="n">feature_size</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">input_shape</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">time_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">feature_size</span><span class="p">)</span>

    <span class="n">keras_model</span> <span class="o">=</span> <span class="n">tenet</span><span class="o">.</span><span class="n">TENet12</span><span class="p">(</span>
        <span class="n">input_shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">,</span>
        <span class="n">classes</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">n_classes</span><span class="p">,</span>
        <span class="n">channels</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
        <span class="n">blocks</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">keras_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">loss</span><span class="o">=</span><span class="s1">'categorical_crossentropy'</span><span class="p">,</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">),</span>
        <span class="n">metrics</span><span class="o">=</span> <span class="p">[</span><span class="s1">'accuracy'</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">keras_model</span>
</pre></div>
</div>
</div>
</div>
<p>The main parameters to modify are:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">channels</span> <span class="o">=</span> <span class="mi">40</span>
<span class="n">blocks</span> <span class="o">=</span> <span class="mi">5</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">channels</span></code> sets the base number of channels in the network.<br/>
<code class="docutils literal notranslate"><span class="pre">block</span></code> set the number of <code class="docutils literal notranslate"><span class="pre">(StridedIBB</span> <span class="pre">-&gt;</span> <span class="pre">IBB</span> <span class="pre">-&gt;</span> <span class="pre">...)</span></code> blocks in the networks.</p>
<p>The larger these values are, the more trainable parameters the model will have which should allow for it to have better accuracy.
However, increasing this value also increases the model’s computational complexity which increases the model inference latency.</p>
</section>
<section id="audio-data-generator">
<h3 id="audio-data-generator">Audio Data Generator<a class="headerlink" href="#audio-data-generator" title="Permalink to this heading">¶</a></h3>
<p>This model has an additional requirement that the keywords need to be said while the Pac-Man video game noises are generated in the background. As such, the model is trained by taking each keyword sample and adding a snippet of background noise to the sample. In this way, the model learns to pick out the keywords from the Pac-Man video game’s noises.</p>
<p>The Pac-Man game audio was acquired by recording during game play (using the arrows on the keyboard). Recording was done using the MLTK command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mltk</span> <span class="n">classify_audio</span> <span class="n">keyword_spotting_pacman_v3</span> <span class="o">--</span><span class="n">dump</span><span class="o">-</span><span class="n">audio</span> <span class="o">--</span><span class="n">device</span>
</pre></div>
</div>
<p>This command uses the microphone on the development board to record the video game’s generated audio. The recorded audio is saved to the local PC as a <code class="docutils literal notranslate"><span class="pre">.wav</span></code> file.</p>
<p>The <a class="reference external" href="https://github.com/SiliconLabs/mltk/tree/master/mltk/models/siliconlabs/keyword_spotting_pacman_v3.py">model specification</a> file was then modified to apply random augmentations to the dataset samples and then <a class="reference external" href="../../docs/python_api/data_preprocessing/audio.html#mltk.core.preprocess.utils.audio.apply_frontend">generate spectrograms</a> from the augmented samples.
The spectrograms are given to the model for training.</p>
<p><strong>NOTE:</strong> The spectrogram generation algorithm <a class="reference internal" href="../../docs/audio/audio_feature_generator.html"><span class="doc std std-doc">source code</span></a> is shared between the model training script and embedded runtime. This way, the generated spectrograms “look” the same during training and inference which should make the model more robust in the field.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">audio_pipeline_with_augmentations</span><span class="p">(</span>
    <span class="n">path_batch</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">label_batch</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">seed</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Augment a batch of audio clips and generate spectrograms</span>

<span class="sd">    This does the following, for each audio file path in the input batch:</span>
<span class="sd">    1. Read audio file</span>
<span class="sd">    2. Adjust its length to fit within the specified length</span>
<span class="sd">    3. Apply random augmentations to the audio sample using audiomentations</span>
<span class="sd">    4. Convert to the specified sample rate (if necessary)</span>
<span class="sd">    5. Generate a spectrogram from the augmented audio sample</span>
<span class="sd">    6. Dump the augmented audio and spectrogram (if necessary)</span>

<span class="sd">    NOTE: This will be execute in parallel across *separate* subprocesses.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        path_batch: Batch of audio file paths</span>
<span class="sd">        label_batch: Batch of corresponding labels</span>
<span class="sd">        seed: Batch of seeds to use for random number generation,</span>
<span class="sd">            This ensures that the "random" augmentations are reproducible</span>

<span class="sd">    Return:</span>
<span class="sd">        Generated batch of spectrograms from augmented audio samples</span>
<span class="sd">    """</span>
    <span class="n">batch_length</span> <span class="o">=</span> <span class="n">path_batch</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">height</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="n">frontend_settings</span><span class="o">.</span><span class="n">spectrogram_shape</span>
    <span class="n">x_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch_length</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">width</span><span class="p">)</span>
    <span class="n">x_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">x_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>

    <span class="c1"># This is the amount of padding we add to the beginning of the sample</span>
    <span class="c1"># This allows for "warming up" the noise reduction block</span>
    <span class="n">padding_length_ms</span> <span class="o">=</span> <span class="mi">1000</span>
    <span class="n">padded_frontend_settings</span> <span class="o">=</span> <span class="n">frontend_settings</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">padded_frontend_settings</span><span class="o">.</span><span class="n">sample_length_ms</span> <span class="o">+=</span> <span class="n">padding_length_ms</span>

    <span class="c1"># For each audio sample path in the current batch</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">audio_path</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">path_batch</span><span class="p">,</span> <span class="n">label_batch</span><span class="p">)):</span>
        <span class="n">class_id</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

        <span class="n">rn</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
        <span class="c1"># 3% of the time we want to replace the "unknown" sample with silence</span>
        <span class="k">if</span> <span class="n">class_id</span> <span class="o">==</span> <span class="n">unknown_class_id</span> <span class="ow">and</span> <span class="n">rn</span> <span class="o">&lt;</span> <span class="mf">0.03</span><span class="p">:</span>
            <span class="n">original_sample_rate</span> <span class="o">=</span> <span class="n">frontend_settings</span><span class="o">.</span><span class="n">sample_rate_hz</span>
            <span class="n">sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">original_sample_rate</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="n">audio_path</span> <span class="o">=</span> <span class="s1">'silence.wav'</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">'utf-8'</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Read the audio file</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">sample</span><span class="p">,</span> <span class="n">original_sample_rate</span> <span class="o">=</span> <span class="n">audio_utils</span><span class="o">.</span><span class="n">read_audio_file</span><span class="p">(</span><span class="n">audio_path</span><span class="p">,</span> <span class="n">return_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_sample_rate</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Failed to read: </span><span class="si">{</span><span class="n">audio_path</span><span class="si">}</span><span class="s1">, err: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

        <span class="c1"># Create a buffer to hold the padded sample</span>
        <span class="n">padding_length</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">original_sample_rate</span> <span class="o">*</span> <span class="n">padding_length_ms</span><span class="p">)</span> <span class="o">/</span> <span class="mi">1000</span><span class="p">)</span>
        <span class="n">padded_sample_length</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">original_sample_rate</span> <span class="o">*</span> <span class="n">padded_frontend_settings</span><span class="o">.</span><span class="n">sample_length_ms</span><span class="p">)</span> <span class="o">/</span> <span class="mi">1000</span><span class="p">)</span>
        <span class="n">padded_sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">padded_sample_length</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>


        <span class="c1"># Adjust the audio clip to the length defined in the frontend_settings</span>
        <span class="n">out_length</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">original_sample_rate</span> <span class="o">*</span> <span class="n">frontend_settings</span><span class="o">.</span><span class="n">sample_length_ms</span><span class="p">)</span> <span class="o">/</span> <span class="mi">1000</span><span class="p">)</span>
        <span class="n">sample</span> <span class="o">=</span> <span class="n">audio_utils</span><span class="o">.</span><span class="n">adjust_length</span><span class="p">(</span>
            <span class="n">sample</span><span class="p">,</span>
            <span class="n">out_length</span><span class="o">=</span><span class="n">out_length</span><span class="p">,</span>
            <span class="n">trim_threshold_db</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
            <span class="n">offset</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">padded_sample</span><span class="p">[</span><span class="n">padding_length</span><span class="p">:</span><span class="n">padding_length</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">sample</span><span class="p">)]</span> <span class="o">+=</span> <span class="n">sample</span>



        <span class="c1"># Initialize the global audio augmentations instance</span>
        <span class="c1"># NOTE: We want this to be global so that we only initialize it once per subprocess</span>
        <span class="n">audio_augmentations</span> <span class="o">=</span> <span class="nb">globals</span><span class="p">()</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'audio_augmentations'</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">audio_augmentations</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">audio_augmentations</span> <span class="o">=</span> <span class="n">audiomentations</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
                <span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                <span class="n">transforms</span><span class="o">=</span><span class="p">[</span>
                <span class="n">audiomentations</span><span class="o">.</span><span class="n">Gain</span><span class="p">(</span><span class="n">min_gain_in_db</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">max_gain_in_db</span><span class="o">=</span><span class="mf">1.2</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="p">),</span>
                <span class="n">audiomentations</span><span class="o">.</span><span class="n">AddBackgroundNoise</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">dataset_dir</span><span class="si">}</span><span class="s1">/_background_noise_/ambient'</span><span class="p">,</span>
                    <span class="n">min_snr_in_db</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="c1"># The lower the SNR, the louder the background noise</span>
                    <span class="n">max_snr_in_db</span><span class="o">=</span><span class="mi">35</span><span class="p">,</span>
                    <span class="n">noise_rms</span><span class="o">=</span><span class="s2">"relative"</span><span class="p">,</span>
                    <span class="n">lru_cache_size</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                    <span class="n">p</span><span class="o">=</span><span class="mf">0.80</span>
                <span class="p">),</span>
                <span class="n">audiomentations</span><span class="o">.</span><span class="n">AddBackgroundNoise</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">dataset_dir</span><span class="si">}</span><span class="s1">/_background_noise_/pacman'</span><span class="p">,</span>
                    <span class="n">min_absolute_rms_in_db</span><span class="o">=-</span><span class="mi">60</span><span class="p">,</span>
                    <span class="n">max_absolute_rms_in_db</span><span class="o">=-</span><span class="mi">35</span><span class="p">,</span>
                    <span class="n">noise_rms</span><span class="o">=</span><span class="s2">"absolute"</span><span class="p">,</span>
                    <span class="n">lru_cache_size</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                    <span class="n">p</span><span class="o">=</span><span class="mf">0.50</span>
                <span class="p">),</span>
                <span class="n">audiomentations</span><span class="o">.</span><span class="n">AddBackgroundNoise</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">dataset_dir</span><span class="si">}</span><span class="s1">/_background_noise_/brd2601'</span><span class="p">,</span>
                    <span class="n">min_absolute_rms_in_db</span><span class="o">=-</span><span class="mf">75.0</span><span class="p">,</span>
                    <span class="n">max_absolute_rms_in_db</span><span class="o">=-</span><span class="mf">60.0</span><span class="p">,</span>
                    <span class="n">noise_rms</span><span class="o">=</span><span class="s2">"absolute"</span><span class="p">,</span>
                    <span class="n">lru_cache_size</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                    <span class="n">p</span><span class="o">=</span><span class="mf">1.0</span>
                <span class="p">),</span>
                <span class="c1">#audiomentations.AddGaussianSNR(min_snr_in_db=25, max_snr_in_db=40, p=0.25),</span>
            <span class="p">])</span>
            <span class="nb">globals</span><span class="p">()[</span><span class="s1">'audio_augmentations'</span><span class="p">]</span> <span class="o">=</span> <span class="n">audio_augmentations</span>

        <span class="c1"># Apply random augmentations to the audio sample</span>
        <span class="n">augmented_sample</span> <span class="o">=</span> <span class="n">audio_augmentations</span><span class="p">(</span><span class="n">padded_sample</span><span class="p">,</span> <span class="n">original_sample_rate</span><span class="p">)</span>

        <span class="c1"># Convert the sample rate (if necessary)</span>
        <span class="k">if</span> <span class="n">original_sample_rate</span> <span class="o">!=</span> <span class="n">frontend_settings</span><span class="o">.</span><span class="n">sample_rate_hz</span><span class="p">:</span>
            <span class="n">augmented_sample</span> <span class="o">=</span> <span class="n">audio_utils</span><span class="o">.</span><span class="n">resample</span><span class="p">(</span>
                <span class="n">augmented_sample</span><span class="p">,</span>
                <span class="n">orig_sr</span><span class="o">=</span><span class="n">original_sample_rate</span><span class="p">,</span>
                <span class="n">target_sr</span><span class="o">=</span><span class="n">frontend_settings</span><span class="o">.</span><span class="n">sample_rate_hz</span>
            <span class="p">)</span>

        <span class="c1"># Ensure the sample values are within (-1,1)</span>
        <span class="n">augmented_sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">augmented_sample</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>

        <span class="c1"># Generate a spectrogram from the augmented audio sample</span>
        <span class="n">spectrogram</span> <span class="o">=</span> <span class="n">audio_utils</span><span class="o">.</span><span class="n">apply_frontend</span><span class="p">(</span>
            <span class="n">sample</span><span class="o">=</span><span class="n">augmented_sample</span><span class="p">,</span>
            <span class="n">settings</span><span class="o">=</span><span class="n">padded_frontend_settings</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int8</span>
        <span class="p">)</span>

        <span class="c1"># The input audio sample was padded with padding_length_ms of background noise</span>
        <span class="c1"># Drop the padded background noise from the final spectrogram used for training</span>
        <span class="n">spectrogram</span> <span class="o">=</span> <span class="n">spectrogram</span><span class="p">[</span><span class="o">-</span><span class="n">height</span><span class="p">:,</span> <span class="p">:]</span>
        <span class="c1"># The output spectrogram is 2D, add a channel dimension to make it 3D:</span>
        <span class="c1"># (height, width, channels=1)</span>

        <span class="c1"># Convert the spectrogram dimension from</span>
        <span class="c1"># &lt;time, features&gt; to</span>
        <span class="c1"># &lt;time, 1, features&gt;</span>
        <span class="n">spectrogram</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">spectrogram</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>

        <span class="n">x_batch</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">spectrogram</span>

    <span class="k">return</span> <span class="n">x_batch</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="profiling-the-model">
<h3 id="profiling-the-model">Profiling the model<a class="headerlink" href="#profiling-the-model" title="Permalink to this heading">¶</a></h3>
<p>Before training a machine learning model, it is important to know how efficiently the model will execute on the embedded target. This is especially true when using keyword spotting to control a Pac-Man (a keyword that takes &gt; 1s to detect will not be useful when trying to avoid the ghosts).</p>
<p>If the model inference takes too long to execute on the embedded target, then the model parameters need to be decreased to reduce the model’s computational complexity. The desired model parameters should be known before the model is fully trained.</p>
<p>To help determine the best model parameters, the MLTK features a <a class="reference internal" href="../../docs/guides/model_profiler.html"><span class="doc std std-doc">Model Profiler</span></a> command:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>mltk<span class="w"> </span>profile<span class="w"> </span>keyword_spotting_pacman_v3<span class="w"> </span>--device<span class="w"> </span>--build<span class="w"> </span>--accelerator<span class="w"> </span>MVP
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Profiling ML model on device ...

Profiling Summary
Name: my_model
Accelerator: MVP
Input Shape: 1x98x1x104
Input Data Type: int8
Output Shape: 1x7
Output Data Type: int8
Flash, Model File Size (bytes): 446.5k
RAM, Runtime Memory Size (bytes): 76.7k
Operation Count: 12.4M
Multiply-Accumulate Count: 6.0M
Layer Count: 90
Unsupported Layer Count: 0
Accelerator Cycle Count: 5.3M
CPU Cycle Count: 954.1k
CPU Utilization (%): 16.7
Clock Rate (hz): 78.0M
Time (s): 73.3m
Ops/s: 169.2M
MACs/s: 82.1M
Inference/s: 13.7

Model Layers
+-------+-------------------+--------+--------+------------+------------+----------+--------------------------+--------------+------------------------------------------------------+
| Index | OpCode            | # Ops  | # MACs | Acc Cycles | CPU Cycles | Time (s) | Input Shape              | Output Shape | Options                                              |
+-------+-------------------+--------+--------+------------+------------+----------+--------------------------+--------------+------------------------------------------------------+
| 0     | conv_2d           | 2.5M   | 1.2M   | 928.9k     | 11.3k      | 11.8m    | 1x98x1x104,40x3x1x104,40 | 1x98x1x40    | Padding:Same stride:1x1 activation:None              |
| 1     | conv_2d           | 976.1k | 470.4k | 390.2k     | 5.2k       | 5.0m     | 1x98x1x40,120x1x1x40,120 | 1x98x1x120   | Padding:Valid stride:1x1 activation:Relu             |
| 2     | depthwise_conv_2d | 123.5k | 52.9k  | 96.4k      | 78.7k      | 1.6m     | 1x98x1x120,1x9x1x120,120 | 1x49x1x120   | Multiplier:1 padding:Same stride:2x2 activation:Relu |
| 3     | conv_2d           | 472.4k | 235.2k | 185.3k     | 5.3k       | 2.4m     | 1x49x1x120,40x1x1x120,40 | 1x49x1x40    | Padding:Valid stride:1x1 activation:None             |
| 4     | conv_2d           | 162.7k | 78.4k  | 66.7k      | 5.2k       | 870.0u   | 1x98x1x40,40x1x1x40,40   | 1x49x1x40    | Padding:Same stride:2x2 activation:Relu              |
| 5     | add               | 2.0k   | 0      | 6.9k       | 2.7k       | 120.0u   | 1x49x1x40,1x49x1x40      | 1x49x1x40    | Activation:Relu                                      |
| 6     | conv_2d           | 488.0k | 235.2k | 195.2k     | 5.3k       | 2.5m     | 1x49x1x40,120x1x1x40,120 | 1x49x1x120   | Padding:Valid stride:1x1 activation:Relu             |
| 7     | depthwise_conv_2d | 123.5k | 52.9k  | 94.5k      | 78.5k      | 1.6m     | 1x49x1x120,1x9x1x120,120 | 1x49x1x120   | Multiplier:1 padding:Same stride:1x1 activation:Relu |
| 8     | conv_2d           | 472.4k | 235.2k | 185.3k     | 5.3k       | 2.4m     | 1x49x1x120,40x1x1x120,40 | 1x49x1x40    | Padding:Valid stride:1x1 activation:None             |
| 9     | add               | 2.0k   | 0      | 6.9k       | 2.6k       | 120.0u   | 1x49x1x40,1x49x1x40      | 1x49x1x40    | Activation:Relu                                      |
| 10    | conv_2d           | 488.0k | 235.2k | 195.2k     | 5.3k       | 2.5m     | 1x49x1x40,120x1x1x40,120 | 1x49x1x120   | Padding:Valid stride:1x1 activation:Relu             |
| 11    | depthwise_conv_2d | 123.5k | 52.9k  | 94.5k      | 78.5k      | 1.6m     | 1x49x1x120,1x9x1x120,120 | 1x49x1x120   | Multiplier:1 padding:Same stride:1x1 activation:Relu |
| 12    | conv_2d           | 472.4k | 235.2k | 185.3k     | 5.3k       | 2.4m     | 1x49x1x120,40x1x1x120,40 | 1x49x1x40    | Padding:Valid stride:1x1 activation:None             |
| 13    | add               | 2.0k   | 0      | 6.9k       | 2.6k       | 120.0u   | 1x49x1x40,1x49x1x40      | 1x49x1x40    | Activation:Relu                                      |
| 14    | conv_2d           | 488.0k | 235.2k | 195.2k     | 5.3k       | 2.5m     | 1x49x1x40,120x1x1x40,120 | 1x49x1x120   | Padding:Valid stride:1x1 activation:Relu             |
| 15    | depthwise_conv_2d | 123.5k | 52.9k  | 94.5k      | 78.5k      | 1.6m     | 1x49x1x120,1x9x1x120,120 | 1x49x1x120   | Multiplier:1 padding:Same stride:1x1 activation:Relu |
| 16    | conv_2d           | 472.4k | 235.2k | 185.3k     | 5.3k       | 2.4m     | 1x49x1x120,40x1x1x120,40 | 1x49x1x40    | Padding:Valid stride:1x1 activation:None             |
| 17    | add               | 2.0k   | 0      | 6.9k       | 2.6k       | 120.0u   | 1x49x1x40,1x49x1x40      | 1x49x1x40    | Activation:Relu                                      |
| 18    | conv_2d           | 488.0k | 235.2k | 195.5k     | 5.3k       | 2.5m     | 1x49x1x40,120x1x1x40,120 | 1x49x1x120   | Padding:Valid stride:1x1 activation:Relu             |
| 19    | depthwise_conv_2d | 63.0k  | 27.0k  | 47.9k      | 40.6k      | 810.0u   | 1x49x1x120,1x9x1x120,120 | 1x25x1x120   | Multiplier:1 padding:Same stride:2x2 activation:Relu |
| 20    | conv_2d           | 241.0k | 120.0k | 95.3k      | 5.3k       | 1.3m     | 1x25x1x120,40x1x1x120,40 | 1x25x1x40    | Padding:Valid stride:1x1 activation:None             |
| 21    | conv_2d           | 83.0k  | 40.0k  | 34.4k      | 5.2k       | 480.0u   | 1x49x1x40,40x1x1x40,40   | 1x25x1x40    | Padding:Same stride:2x2 activation:Relu              |
| 22    | add               | 1.0k   | 0      | 3.5k       | 2.6k       | 90.0u    | 1x25x1x40,1x25x1x40      | 1x25x1x40    | Activation:Relu                                      |
| 23    | conv_2d           | 249.0k | 120.0k | 99.9k      | 5.3k       | 1.3m     | 1x25x1x40,120x1x1x40,120 | 1x25x1x120   | Padding:Valid stride:1x1 activation:Relu             |
| 24    | depthwise_conv_2d | 63.0k  | 27.0k  | 46.4k      | 40.5k      | 810.0u   | 1x25x1x120,1x9x1x120,120 | 1x25x1x120   | Multiplier:1 padding:Same stride:1x1 activation:Relu |
| 25    | conv_2d           | 241.0k | 120.0k | 95.3k      | 5.3k       | 1.2m     | 1x25x1x120,40x1x1x120,40 | 1x25x1x40    | Padding:Valid stride:1x1 activation:None             |
| 26    | add               | 1.0k   | 0      | 3.5k       | 2.6k       | 90.0u    | 1x25x1x40,1x25x1x40      | 1x25x1x40    | Activation:Relu                                      |
| 27    | conv_2d           | 249.0k | 120.0k | 99.7k      | 5.3k       | 1.3m     | 1x25x1x40,120x1x1x40,120 | 1x25x1x120   | Padding:Valid stride:1x1 activation:Relu             |
| 28    | depthwise_conv_2d | 63.0k  | 27.0k  | 46.4k      | 40.5k      | 810.0u   | 1x25x1x120,1x9x1x120,120 | 1x25x1x120   | Multiplier:1 padding:Same stride:1x1 activation:Relu |
| 29    | conv_2d           | 241.0k | 120.0k | 95.3k      | 5.3k       | 1.2m     | 1x25x1x120,40x1x1x120,40 | 1x25x1x40    | Padding:Valid stride:1x1 activation:None             |
| 30    | add               | 1.0k   | 0      | 3.5k       | 2.6k       | 60.0u    | 1x25x1x40,1x25x1x40      | 1x25x1x40    | Activation:Relu                                      |
| 31    | conv_2d           | 249.0k | 120.0k | 99.9k      | 5.3k       | 1.3m     | 1x25x1x40,120x1x1x40,120 | 1x25x1x120   | Padding:Valid stride:1x1 activation:Relu             |
| 32    | depthwise_conv_2d | 63.0k  | 27.0k  | 46.4k      | 40.5k      | 810.0u   | 1x25x1x120,1x9x1x120,120 | 1x25x1x120   | Multiplier:1 padding:Same stride:1x1 activation:Relu |
| 33    | conv_2d           | 241.0k | 120.0k | 95.3k      | 5.3k       | 1.3m     | 1x25x1x120,40x1x1x120,40 | 1x25x1x40    | Padding:Valid stride:1x1 activation:None             |
| 34    | add               | 1.0k   | 0      | 3.5k       | 2.6k       | 60.0u    | 1x25x1x40,1x25x1x40      | 1x25x1x40    | Activation:Relu                                      |
| 35    | conv_2d           | 249.0k | 120.0k | 99.9k      | 5.3k       | 1.3m     | 1x25x1x40,120x1x1x40,120 | 1x25x1x120   | Padding:Valid stride:1x1 activation:Relu             |
| 36    | depthwise_conv_2d | 32.8k  | 14.0k  | 23.8k      | 21.6k      | 420.0u   | 1x25x1x120,1x9x1x120,120 | 1x13x1x120   | Multiplier:1 padding:Same stride:2x2 activation:Relu |
| 37    | conv_2d           | 125.3k | 62.4k  | 49.6k      | 5.3k       | 660.0u   | 1x13x1x120,40x1x1x120,40 | 1x13x1x40    | Padding:Valid stride:1x1 activation:None             |
| 38    | conv_2d           | 43.2k  | 20.8k  | 18.0k      | 5.2k       | 270.0u   | 1x25x1x40,40x1x1x40,40   | 1x13x1x40    | Padding:Same stride:2x2 activation:Relu              |
| 39    | add               | 520.0  | 0      | 1.8k       | 2.6k       | 60.0u    | 1x13x1x40,1x13x1x40      | 1x13x1x40    | Activation:Relu                                      |
| 40    | conv_2d           | 129.5k | 62.4k  | 52.0k      | 5.3k       | 720.0u   | 1x13x1x40,120x1x1x40,120 | 1x13x1x120   | Padding:Valid stride:1x1 activation:Relu             |
| 41    | depthwise_conv_2d | 32.8k  | 14.0k  | 22.4k      | 21.6k      | 420.0u   | 1x13x1x120,1x9x1x120,120 | 1x13x1x120   | Multiplier:1 padding:Same stride:1x1 activation:Relu |
| 42    | conv_2d           | 125.3k | 62.4k  | 49.6k      | 5.3k       | 660.0u   | 1x13x1x120,40x1x1x120,40 | 1x13x1x40    | Padding:Valid stride:1x1 activation:None             |
| 43    | add               | 520.0  | 0      | 1.8k       | 2.6k       | 30.0u    | 1x13x1x40,1x13x1x40      | 1x13x1x40    | Activation:Relu                                      |
| 44    | conv_2d           | 129.5k | 62.4k  | 52.0k      | 5.3k       | 720.0u   | 1x13x1x40,120x1x1x40,120 | 1x13x1x120   | Padding:Valid stride:1x1 activation:Relu             |
| 45    | depthwise_conv_2d | 32.8k  | 14.0k  | 22.4k      | 21.6k      | 420.0u   | 1x13x1x120,1x9x1x120,120 | 1x13x1x120   | Multiplier:1 padding:Same stride:1x1 activation:Relu |
| 46    | conv_2d           | 125.3k | 62.4k  | 49.6k      | 5.3k       | 690.0u   | 1x13x1x120,40x1x1x120,40 | 1x13x1x40    | Padding:Valid stride:1x1 activation:None             |
| 47    | add               | 520.0  | 0      | 1.8k       | 2.6k       | 60.0u    | 1x13x1x40,1x13x1x40      | 1x13x1x40    | Activation:Relu                                      |
| 48    | conv_2d           | 129.5k | 62.4k  | 52.0k      | 5.3k       | 720.0u   | 1x13x1x40,120x1x1x40,120 | 1x13x1x120   | Padding:Valid stride:1x1 activation:Relu             |
| 49    | depthwise_conv_2d | 32.8k  | 14.0k  | 22.4k      | 21.6k      | 420.0u   | 1x13x1x120,1x9x1x120,120 | 1x13x1x120   | Multiplier:1 padding:Same stride:1x1 activation:Relu |
| 50    | conv_2d           | 125.3k | 62.4k  | 49.6k      | 5.3k       | 660.0u   | 1x13x1x120,40x1x1x120,40 | 1x13x1x40    | Padding:Valid stride:1x1 activation:None             |
| 51    | add               | 520.0  | 0      | 1.8k       | 2.6k       | 60.0u    | 1x13x1x40,1x13x1x40      | 1x13x1x40    | Activation:Relu                                      |
| 52    | conv_2d           | 129.5k | 62.4k  | 52.0k      | 5.3k       | 720.0u   | 1x13x1x40,120x1x1x40,120 | 1x13x1x120   | Padding:Valid stride:1x1 activation:Relu             |
| 53    | depthwise_conv_2d | 17.6k  | 7.6k   | 11.8k      | 12.1k      | 240.0u   | 1x13x1x120,1x9x1x120,120 | 1x7x1x120    | Multiplier:1 padding:Same stride:2x2 activation:Relu |
| 54    | conv_2d           | 67.5k  | 33.6k  | 26.7k      | 5.3k       | 390.0u   | 1x7x1x120,40x1x1x120,40  | 1x7x1x40     | Padding:Valid stride:1x1 activation:None             |
| 55    | conv_2d           | 23.2k  | 11.2k  | 9.7k       | 5.2k       | 180.0u   | 1x13x1x40,40x1x1x40,40   | 1x7x1x40     | Padding:Same stride:2x2 activation:Relu              |
| 56    | add               | 280.0  | 0      | 992.0      | 2.6k       | 30.0u    | 1x7x1x40,1x7x1x40        | 1x7x1x40     | Activation:Relu                                      |
| 57    | conv_2d           | 69.7k  | 33.6k  | 28.1k      | 5.3k       | 420.0u   | 1x7x1x40,120x1x1x40,120  | 1x7x1x120    | Padding:Valid stride:1x1 activation:Relu             |
| 58    | depthwise_conv_2d | 17.6k  | 7.6k   | 10.3k      | 12.1k      | 210.0u   | 1x7x1x120,1x9x1x120,120  | 1x7x1x120    | Multiplier:1 padding:Same stride:1x1 activation:Relu |
| 59    | conv_2d           | 67.5k  | 33.6k  | 26.7k      | 5.3k       | 390.0u   | 1x7x1x120,40x1x1x120,40  | 1x7x1x40     | Padding:Valid stride:1x1 activation:None             |
| 60    | add               | 280.0  | 0      | 992.0      | 2.6k       | 30.0u    | 1x7x1x40,1x7x1x40        | 1x7x1x40     | Activation:Relu                                      |
| 61    | conv_2d           | 69.7k  | 33.6k  | 28.1k      | 5.3k       | 420.0u   | 1x7x1x40,120x1x1x40,120  | 1x7x1x120    | Padding:Valid stride:1x1 activation:Relu             |
| 62    | depthwise_conv_2d | 17.6k  | 7.6k   | 10.3k      | 12.1k      | 210.0u   | 1x7x1x120,1x9x1x120,120  | 1x7x1x120    | Multiplier:1 padding:Same stride:1x1 activation:Relu |
| 63    | conv_2d           | 67.5k  | 33.6k  | 26.7k      | 5.3k       | 390.0u   | 1x7x1x120,40x1x1x120,40  | 1x7x1x40     | Padding:Valid stride:1x1 activation:None             |
| 64    | add               | 280.0  | 0      | 992.0      | 2.6k       | 30.0u    | 1x7x1x40,1x7x1x40        | 1x7x1x40     | Activation:Relu                                      |
| 65    | conv_2d           | 69.7k  | 33.6k  | 28.1k      | 5.3k       | 420.0u   | 1x7x1x40,120x1x1x40,120  | 1x7x1x120    | Padding:Valid stride:1x1 activation:Relu             |
| 66    | depthwise_conv_2d | 17.6k  | 7.6k   | 10.3k      | 12.1k      | 210.0u   | 1x7x1x120,1x9x1x120,120  | 1x7x1x120    | Multiplier:1 padding:Same stride:1x1 activation:Relu |
| 67    | conv_2d           | 67.5k  | 33.6k  | 26.7k      | 5.3k       | 420.0u   | 1x7x1x120,40x1x1x120,40  | 1x7x1x40     | Padding:Valid stride:1x1 activation:None             |
| 68    | add               | 280.0  | 0      | 992.0      | 2.6k       | 30.0u    | 1x7x1x40,1x7x1x40        | 1x7x1x40     | Activation:Relu                                      |
| 69    | conv_2d           | 69.7k  | 33.6k  | 28.1k      | 5.3k       | 420.0u   | 1x7x1x40,120x1x1x40,120  | 1x7x1x120    | Padding:Valid stride:1x1 activation:Relu             |
| 70    | depthwise_conv_2d | 10.1k  | 4.3k   | 5.8k       | 7.4k       | 150.0u   | 1x7x1x120,1x9x1x120,120  | 1x4x1x120    | Multiplier:1 padding:Same stride:2x2 activation:Relu |
| 71    | conv_2d           | 38.6k  | 19.2k  | 15.3k      | 5.3k       | 240.0u   | 1x4x1x120,40x1x1x120,40  | 1x4x1x40     | Padding:Valid stride:1x1 activation:None             |
| 72    | conv_2d           | 13.3k  | 6.4k   | 5.6k       | 5.2k       | 150.0u   | 1x7x1x40,40x1x1x40,40    | 1x4x1x40     | Padding:Same stride:2x2 activation:Relu              |
| 73    | add               | 160.0  | 0      | 572.0      | 2.6k       | 30.0u    | 1x4x1x40,1x4x1x40        | 1x4x1x40     | Activation:Relu                                      |
| 74    | conv_2d           | 39.8k  | 19.2k  | 16.1k      | 5.3k       | 270.0u   | 1x4x1x40,120x1x1x40,120  | 1x4x1x120    | Padding:Valid stride:1x1 activation:Relu             |
| 75    | depthwise_conv_2d | 10.1k  | 4.3k   | 4.3k       | 7.3k       | 120.0u   | 1x4x1x120,1x9x1x120,120  | 1x4x1x120    | Multiplier:1 padding:Same stride:1x1 activation:Relu |
| 76    | conv_2d           | 38.6k  | 19.2k  | 15.3k      | 5.3k       | 270.0u   | 1x4x1x120,40x1x1x120,40  | 1x4x1x40     | Padding:Valid stride:1x1 activation:None             |
| 77    | add               | 160.0  | 0      | 572.0      | 2.6k       | 30.0u    | 1x4x1x40,1x4x1x40        | 1x4x1x40     | Activation:Relu                                      |
| 78    | conv_2d           | 39.8k  | 19.2k  | 16.1k      | 5.3k       | 270.0u   | 1x4x1x40,120x1x1x40,120  | 1x4x1x120    | Padding:Valid stride:1x1 activation:Relu             |
| 79    | depthwise_conv_2d | 10.1k  | 4.3k   | 4.3k       | 7.3k       | 120.0u   | 1x4x1x120,1x9x1x120,120  | 1x4x1x120    | Multiplier:1 padding:Same stride:1x1 activation:Relu |
| 80    | conv_2d           | 38.6k  | 19.2k  | 15.3k      | 5.3k       | 240.0u   | 1x4x1x120,40x1x1x120,40  | 1x4x1x40     | Padding:Valid stride:1x1 activation:None             |
| 81    | add               | 160.0  | 0      | 572.0      | 2.6k       | 30.0u    | 1x4x1x40,1x4x1x40        | 1x4x1x40     | Activation:Relu                                      |
| 82    | conv_2d           | 39.8k  | 19.2k  | 16.1k      | 5.3k       | 270.0u   | 1x4x1x40,120x1x1x40,120  | 1x4x1x120    | Padding:Valid stride:1x1 activation:Relu             |
| 83    | depthwise_conv_2d | 10.1k  | 4.3k   | 4.3k       | 7.3k       | 120.0u   | 1x4x1x120,1x9x1x120,120  | 1x4x1x120    | Multiplier:1 padding:Same stride:1x1 activation:Relu |
| 84    | conv_2d           | 38.6k  | 19.2k  | 15.3k      | 5.3k       | 240.0u   | 1x4x1x120,40x1x1x120,40  | 1x4x1x40     | Padding:Valid stride:1x1 activation:None             |
| 85    | add               | 160.0  | 0      | 572.0      | 2.6k       | 60.0u    | 1x4x1x40,1x4x1x40        | 1x4x1x40     | Activation:Relu                                      |
| 86    | average_pool_2d   | 200.0  | 0      | 154.0      | 3.8k       | 60.0u    | 1x4x1x40                 | 1x1x1x40     | Padding:Valid stride:1x4 filter:1x4 activation:None  |
| 87    | reshape           | 0      | 0      | 0          | 640.0      | 0        | 1x1x1x40,2               | 1x40         | Type=none                                            |
| 88    | fully_connected   | 567.0  | 280.0  | 477.0      | 2.1k       | 30.0u    | 1x40,7x40,7              | 1x7          | Activation:None                                      |
| 89    | softmax           | 35.0   | 0      | 0          | 5.5k       | 90.0u    | 1x7                      | 1x7          | Type=softmaxoptions                                  |
+-------+-------------------+--------+--------+------------+------------+----------+--------------------------+--------------+------------------------------------------------------+
Profiling time: 115.656699 seconds
</pre></div>
</div>
</div>
</div>
<p>This command builds the model then profiles it on the development board using the <a class="reference external" href="https://docs.silabs.com/gecko-platform/latest/machine-learning/tensorflow/mvp-accelerator">MVP</a> hardware accelerator.</p>
</section>
<section id="training-the-model">
<h3 id="training-the-model">Training the model<a class="headerlink" href="#training-the-model" title="Permalink to this heading">¶</a></h3>
<p>Once the <a class="reference external" href="https://github.com/SiliconLabs/mltk/tree/master/mltk/models/siliconlabs/keyword_spotting_pacman_v3.py">model specification</a> is ready, it can be <a class="reference internal" href="../../docs/guides/model_training.html"><span class="doc std std-doc">trained</span></a> with the command:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>mltk<span class="w"> </span>train<span class="w"> </span>keyword_spotting_pacman_v3
</pre></div>
</div>
</div>
</div>
</section>
<section id="train-in-cloud">
<h3 id="train-in-cloud">Train in cloud<a class="headerlink" href="#train-in-cloud" title="Permalink to this heading">¶</a></h3>
<p>Alternatively, you can <em>vastly</em> improve the model training time by training this model in the “cloud”.<br/>
See the tutorial: <a class="reference internal" href="cloud_training_with_vast_ai.html"><span class="doc std std-doc">Cloud Training with vast.ai</span></a> for more details.</p>
<p>After training completes, a <a class="reference external" href="https://github.com/SiliconLabs/mltk/tree/master/mltk/models/siliconlabs/keyword_spotting_pacman_v3.mltk.zip">model archive</a> file is generated containing the quantized <code class="docutils literal notranslate"><span class="pre">.tflite</span></code> model file. This is the file that is built into the firmware application.</p>
</section>
</section>
<section id="creating-the-firmware-application">
<h2 id="creating-the-firmware-application">Creating the Firmware Application<a class="headerlink" href="#creating-the-firmware-application" title="Permalink to this heading">¶</a></h2>
<p>The <a class="reference internal" href="../../docs/cpp_development/examples/ble_audio_classifier.html"><span class="doc std std-doc">BLE Audio Classifier</span></a> C++ example application may be used with the train model.</p>
<p>The application uses the <a class="reference external" href="../../docs/audio/audio_feature_generator.html#gecko-sdk-component">Audio Feature Generator</a> library to generate spectrograms from the streaming microphone audio.
The spectrograms are then passed to the <a class="reference external" href="https://github.com/tensorflow/tflite-micro">Tensorflow-Lite Micro</a> inference engine which uses the trained model from above to make predictions on if a keyword is found in the spectrogram.
If a keyword is detected, a connected BLE client is sent a notification containing the detected class ID of the keyword and prediction probability.</p>
</section>
<section id="creating-the-pac-man-webpage">
<h2 id="creating-the-pac-man-webpage">Creating the Pac-Man Webpage<a class="headerlink" href="#creating-the-pac-man-webpage" title="Permalink to this heading">¶</a></h2>
<p>A <a class="reference external" href="https://github.com/SiliconLabs/mltk/blob/master/cpp/shared/apps/ble_audio_classifier/web/pacman">Pac-Man Webpage</a> is available that allows for playing the game “Pac-Man” using
the keywords detected by the firmware application described above.</p>
<p>This webpage was adapted from a game created by Lucio Panpinto, view original source code on <a class="reference external" href="https://github.com/luciopanepinto/pacman">GitHub</a>.</p>
<p>The webpage was modified to use the <a class="reference external" href="https://itpnyu.github.io/p5ble-website/">p5.ble.js</a> library for communicating with the firmware application via Bluetooth Low Energy.</p>
</section>
<section id="running-the-demo">
<h2 id="running-the-demo">Running the Demo<a class="headerlink" href="#running-the-demo" title="Permalink to this heading">¶</a></h2>
<p>With the following components complete:</p>
<ul class="simple">
<li><p>Keyword spotting machine learning model</p></li>
<li><p>Firmware application with Audio Feature Generator, Tensorflow-Lite Micro, and Bluetooth libraries</p></li>
<li><p>Pac-Man webpage with Bluetooth</p></li>
</ul>
<p>We can now run the demo.</p>
<p>A live demo may be found at: <a class="reference external" href="https://mltk-pacman.web.app">https://mltk-pacman.web.app</a>.</p>
<p>Alternatively, you can build the firmware application from source and run the webpage locally:</p>
<section id="build-firmware-application-from-source">
<h3 id="build-firmware-application-from-source">Build firmware application from source<a class="headerlink" href="#build-firmware-application-from-source" title="Permalink to this heading">¶</a></h3>
<p>The MLTK supports building <a class="reference internal" href="../../docs/cpp_development/index.html"><span class="doc std std-doc">C++ Applications</span></a>.</p>
<p>It also features a <a class="reference internal" href="../../docs/cpp_development/examples/ble_audio_classifier.html"><span class="doc std std-doc">ble_audio_classifier</span></a> C++ application
which can be built using:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../../docs/cpp_development/vscode.html"><span class="doc std std-doc">Visual Studio Code</span></a></p></li>
<li><p><a class="reference internal" href="../../docs/cpp_development/simplicity_studio.html"><span class="doc std std-doc">Simplicity Studio</span></a></p></li>
<li><p><a class="reference internal" href="../../docs/cpp_development/command_line.html"><span class="doc std std-doc">Command Line</span></a></p></li>
</ul>
<p>Refer to the <a class="reference internal" href="../../docs/cpp_development/examples/ble_audio_classifier.html"><span class="doc std std-doc">ble_audio_classifier</span></a> application’s documentation
for how include your model into the built application.</p>
</section>
<section id="run-webpage-locally">
<h3 id="run-webpage-locally">Run webpage locally<a class="headerlink" href="#run-webpage-locally" title="Permalink to this heading">¶</a></h3>
<p>The demo’s webpage uses “vanilla” javascript+css+html. No special build systems are required.</p>
<p>To run the webpage locally, simply open <a class="reference external" href="https://github.com/SiliconLabs/mltk/blob/master/cpp/shared/apps/ble_audio_classifier/web/pacman/index.html">index.html</a> in your web browser (NOTE: double-click the <strong>locally cloned</strong> <code class="docutils literal notranslate"><span class="pre">index.html</span></code> on your PC, not the one on Github).</p>
<p>When the webpage starts, follow the instructions but do <em>not</em> program the <code class="docutils literal notranslate"><span class="pre">.s37</span></code>. The locally built firmware application should have already been programmed as described in the the previous section.</p>
</section>
</section>
</section>


          </article>
        </div>
      </div>
      <a href="#" class="go-top"><i class="md-icon">arrow_upward</i>Back to Top</a>
    </main>
  </div>
  <footer class="md-footer">
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
          
            <a href="keyword_spotting_on_off.html" title="Keyword Spotting - On/Off"
               class="md-flex md-footer-nav__link md-footer-nav__link--prev"
               rel="prev">
              <div class="md-flex__cell md-flex__cell--shrink">
                <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
              </div>
              <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
                <span class="md-flex__ellipsis">
                  <span
                      class="md-footer-nav__direction"> Previous </span> Keyword Spotting - On/Off </span>
              </div>
            </a>
          
          
            <a href="keyword_spotting_alexa.html" title="Keyword Spotting - Alexa"
               class="md-flex md-footer-nav__link md-footer-nav__link--next"
               rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title"><span
                class="md-flex__ellipsis"> <span
                class="md-footer-nav__direction"> Next </span> Keyword Spotting - Alexa </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink"><i
                class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          
        </a>
        
      </nav>
    </div>
    <div class="md-footer-meta md-typeset">
      <div class="md-footer-meta__inner md-grid">
        <div class="md-footer-copyright">
          <div class="md-footer-copyright__highlight">
              &#169; Copyright 2023, Silicon Labs.
              
          </div>
            Last updated on
              Mar 01, 2023.
            <br/>
            Created using
            <a href="http://www.sphinx-doc.org/">Sphinx</a> 5.3.0.
             and
            <a href="https://github.com/bashtage/sphinx-material/">Material for
              Sphinx</a>
        </div>
        <button id="survey-link" class="feedback-button">Feedback</button>
      </div>
    </div>
  </footer>
  <div class="privacy-banner">
    <div class="privacy-banner-wrapper">
      <p>
        <b>Important:</b> We use cookies only for functional and traffic analytics. <br />
        We DO NOT use cookies for any marketing purposes. By using our site you acknowledge you have read and understood our <a class="privacy-policy" href="https://www.silabs.com/about-us/legal/cookie-policy" target="_blank">Cookie Policy</a>.
      </p>
      <a class="privacy-banner-accept" href="#">Got it</a>
    </div>
</div>
  
<div class="survey-container" id="dlg-survey"> 
    <div class="close" id="dlg-survey-close"><i class="md-icon">close</i></div>
    <div class="msg">Please click the <b>submit</b> button at the end even if you do not answer all of the questions</div>
    <iframe id="iframe-survey" style="width: 100%; height: 100%;"></iframe>
</div>
  
  <script src="../../_static/javascripts/application.js"></script>
  <script>app.initialize({version: "1.0.4", url: {base: ".."}})</script>
  </body>
</html>