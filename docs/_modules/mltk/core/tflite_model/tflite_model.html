
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="title" content="Machine Learning Toolkit">
<meta name="description" content="A Python package with command-line utilities and scripts to aid the development of machine learning models for Silicon Lab's embedded platforms">
<meta name="keywords" content="machine learning, machine-learning, machinelearning, ml, ai, iot, Internet of things, aiot, tinyml, tensorflow, tensorflow-lite, tensorflow-lite-micro, keras-tensorflow, keras, tflite, embedded, embedded-systems, mcu, Microcontrollers, hardware, python, c++, cmake, keras, numpy, silabs, silicon labs">
<meta name="robots" content="index, follow">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="language" content="English">
<meta name="author" content="Silicon Labs">
  <meta name="lang:clipboard.copy" content="Copy to clipboard">
  <meta name="lang:clipboard.copied" content="Copied to clipboard">
  <meta name="lang:search.language" content="en">
  <meta name="lang:search.pipeline.stopwords" content="True">
  <meta name="lang:search.pipeline.trimmer" content="True">
  <meta name="lang:search.result.none" content="No matching documents">
  <meta name="lang:search.result.one" content="1 matching document">
  <meta name="lang:search.result.other" content="# matching documents">
  <meta name="lang:search.tokenizer" content="[\s\-]+">

  
    <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&display=fallback" rel="stylesheet">

    <style>
      body,
      input {
        font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif
      }

      code,
      kbd,
      pre {
        font-family: "Roboto Mono", "Courier New", Courier, monospace
      }
    </style>
  

  <link rel="stylesheet" href="../../../../_static/stylesheets/application.css"/>
  <link rel="stylesheet" href="../../../../_static/stylesheets/application-palette.css"/>
  <link rel="stylesheet" href="../../../../_static/stylesheets/application-fixes.css"/>
  
  <link rel="stylesheet" href="../../../../_static/fonts/material-icons.css"/>
  
  <meta name="theme-color" content="#3f51b5">
  <script src="../../../../_static/javascripts/modernizr.js"></script>
  
<script async src="https://www.googletagmanager.com/gtag/js?id=G-HZ5MW943WF"></script>
<script>
    window.gTrackingId = 'G-HZ5MW943WF';
</script>
<meta name="google-site-verification" content="dsSsmnE2twOnfSAQk5zBBTrjMArsTJj809Bp-8mVlIw" />
  
  
    <title>mltk.core.tflite_model.tflite_model &#8212; MLTK 0.19.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/material.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/css/custom.css" />
    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/sphinx_highlight.js"></script>
    <script src="../../../../_static/clipboard.min.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script src="../../../../_static/design-tabs.js"></script>
    <script src="../../../../_static/js/custom.js"></script>
    <script src="../../../../_static/js/apitoc.js"></script>
    <link rel="shortcut icon" href="../../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
  
   

  </head>
  <body dir=ltr
        data-md-color-primary=red data-md-color-accent=light-blue>
  
  <svg class="md-svg">
    <defs data-children-count="0">
      
      <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
      
    </defs>
  </svg>
  
  <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer">
  <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search">
  <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
  <a href="#_modules/mltk/core/tflite_model/tflite_model" tabindex="1" class="md-skip"> Skip to content </a>
  <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex navheader">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../../../../index.html" title="MLTK 0.19.0 documentation"
           class="md-header-nav__button md-logo">
          
              <img src="../../../../_static/logo.png"
                   alt="MLTK 0.19.0 documentation logo">
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          <span class="md-header-nav__topic">Machine Learning Toolkit</span>
          <span class="md-header-nav__topic"> mltk.core.tflite_model.tflite_model </span>
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
        
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" action="../../../../search.html" method="get" name="search">
      <input type="text" class="md-search__input" name="q" placeholder=""Search""
             autocapitalize="off" autocomplete="off" spellcheck="false"
             data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>

      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            <a href="https://github.com/siliconlabs/mltk" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    MLTK Github Repository
  </div>
</a>
          </div>
        </div>
      
      
    </div>
  </nav>
</header>

  
  <div class="md-container">
    
    
    
  <nav class="md-tabs" data-md-component="tabs">
    <div class="md-tabs__inner md-grid">
      <ul class="md-tabs__list">
            
            <li class="md-tabs__item"><a href="https://docs.silabs.com/gecko-platform/latest/machine-learning/tensorflow/overview" class="md-tabs__link">Gecko SDK Documentation</a></li>
            
            <li class="md-tabs__item"><a href="https://github.com/tensorflow/tflite-micro" class="md-tabs__link">Tensorflow-Lite Micro Repository</a></li>
            
            <li class="md-tabs__item"><a href="https://www.tensorflow.org/learn" class="md-tabs__link">Tensorflow Documentation</a></li>
          <li class="md-tabs__item"><a href="../../../index.html" class="md-tabs__link">Module code</a></li>
      </ul>
    </div>
  </nav>
    <main class="md-main">
      <div class="md-main__inner md-grid" data-md-component="container">
        
          <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../../../../index.html" title="MLTK 0.19.0 documentation" class="md-nav__button md-logo">
      
        <img src="../../../../_static/logo.png" alt=" logo" width="48" height="48">
      
    </a>
    <a href="../../../../index.html"
       title="MLTK 0.19.0 documentation">Machine Learning Toolkit</a>
  </label>
    <div class="md-nav__source">
      <a href="https://github.com/siliconlabs/mltk" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    MLTK Github Repository
  </div>
</a>
    </div>
  
  

  
  <ul class="md-nav__list">
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Basics</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../../docs/overview.html" class="md-nav__link">Overview</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../../docs/why_mltk.html" class="md-nav__link">Why MLTK?</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../../docs/installation.html" class="md-nav__link">Installation</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../../docs/command_line/index.html" class="md-nav__link">Command-Line</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../../docs/guides/index.html" class="md-nav__link">Modeling Guides</a>
      
    
    </li>
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Usage</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../../docs/tutorials.html" class="md-nav__link">Tutorials</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../../docs/examples.html" class="md-nav__link">API Examples</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../../docs/python_api/index.html" class="md-nav__link">API Reference</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../../docs/python_api/models/index.html" class="md-nav__link">Reference Models</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../../docs/python_api/datasets/index.html" class="md-nav__link">Reference Datasets</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../../docs/cpp_development/index.html" class="md-nav__link">C++ Development</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../../docs/cpp_development/examples/index.html" class="md-nav__link">C++ Examples</a>
      
    
    </li>
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Audio Related</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../../docs/audio/keyword_spotting_overview.html" class="md-nav__link">Keyword Spotting Overview</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../../docs/audio/audio_feature_generator.html" class="md-nav__link">Audio Feature Generator</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../../docs/audio/audio_utilities.html" class="md-nav__link">Audio Utilities</a>
      
    
    </li>
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Other Information</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../../docs/faq/index.html" class="md-nav__link">Frequently Asked Questions</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../../docs/other/quick_reference.html" class="md-nav__link">Quick Reference</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../../docs/other/supported_hardware.html" class="md-nav__link">Supported Hardware</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../../docs/guides/notebook_examples_guide.html" class="md-nav__link">Notebook Examples Guide</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../../docs/other/settings_file.html" class="md-nav__link">Settings File</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../../docs/other/environment_variables.html" class="md-nav__link">Environment Variables</a>
      
    
    </li>
  </ul>
  

</nav>
              </div>
            </div>
          </div>
          <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                
<nav class="md-nav md-nav--secondary">
  <ul class="md-nav__list" data-md-scrollfix="" id="localtoc">
  </ul>
</nav>
              </div>
            </div>
          </div>
        
        <div class="md-content">

          
          <div class="breadcrumbs md-typeset">
            <ul class="breadcrumb">
              <li></li>
              <li><a href="../../../../index.html"><i class="md-icon">home</i></a></li>
                <li><a href="../../../index.html" accesskey="U">Module code</a></li>

              <li class="activate"><a>mltk.core.tflite_model.tflite_model</a></li>
            </ul>
          </div>
          

          <article class="md-content__inner md-typeset" role="main">
            
  <h1 id="modules-mltk-core-tflite-model-tflite-model--page-root">Source code for mltk.core.tflite_model.tflite_model</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Union</span><span class="p">,</span> <span class="n">Iterator</span>
<span class="kn">from</span> <span class="nn">prettytable</span> <span class="kn">import</span> <span class="n">PrettyTable</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Disable the "DeprecationWarning" found in the flatbuffer package</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">"ignore"</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">DeprecationWarning</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">tflite_schema</span> <span class="k">as</span> <span class="n">_tflite_schema_fb</span>
<span class="kn">from</span> <span class="nn">.tflite_schema</span> <span class="kn">import</span> <span class="n">BuiltinOperator</span> <span class="k">as</span> <span class="n">TfliteOpCode</span> <span class="c1"># pylint: disable=unused-import</span>
<span class="kn">from</span> <span class="nn">.tflite_schema</span> <span class="kn">import</span> <span class="n">flatbuffers</span>

<span class="kn">from</span> <span class="nn">.tflite_tensor</span> <span class="kn">import</span> <span class="n">TfliteTensor</span>
<span class="kn">from</span> <span class="nn">.tflite_layer</span> <span class="kn">import</span> <span class="n">TfliteLayer</span>



<span class="n">TFLITE_FILE_IDENTIFIER</span> <span class="o">=</span> <span class="sa">b</span><span class="s2">"TFL3"</span>




<div class="viewcode-block" id="TfliteModel"><a class="viewcode-back" href="../../../../docs/python_api/tflite_model/model.html#mltk.core.TfliteModel">[docs]</a><span class="k">class</span> <span class="nc">TfliteModel</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Class to access a .tflite model flatbuffer's layers and tensors</span>

<span class="sd">    Refer to `schema_v3.fbs &lt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/schema/schema_v3.fbs&gt;`_</span>
<span class="sd">    for more details on the .tflite flatbuffer schema</span>

<span class="sd">    **Example Usage**</span>

<span class="sd">    .. highlight:: python</span>
<span class="sd">    .. code-block:: python</span>

<span class="sd">        from mltk.core import TfliteModel</span>

<span class="sd">        # Load you .tflite model file</span>
<span class="sd">        model = TfliteModel.load_flatbuffer_file('some/path/my_model.tflite')</span>

<span class="sd">        # Print a summary of the model</span>
<span class="sd">        print(tflite_model.summary())</span>

<span class="sd">        # Iterate through each layer of the model</span>
<span class="sd">        for layer in tflite_model.layers:</span>
<span class="sd">            # See TfliteLayer for additional info</span>
<span class="sd">            print(layer)</span>


<span class="sd">        # Update the model's description</span>
<span class="sd">        # This updates the .tflite's "description" field (which will be displayed in GUIs like https://netron.app)</span>
<span class="sd">        tflite_model.description = "My awesome model"</span>
<span class="sd">        print(f'New model description: {tflite_model.description}')</span>

<span class="sd">        # Save a new .tflite with the updated description</span>
<span class="sd">        tflite_model.save('some/path/my_new_model.tflite')</span>

<span class="sd">        # Add some metadata to the .tflite</span>
<span class="sd">        metadata = 'this is metadata'.encode('utf-8')</span>
<span class="sd">        tflite_model.add_metadata('my_metadata', metadata)</span>

<span class="sd">        # Retrieve all the metadata in the .tflite</span>
<span class="sd">        all_metadata = tflite_model.get_all_metadata()</span>
<span class="sd">        for key, data in all_metadata.items():</span>
<span class="sd">            print(f'{key}: length={len(data)} bytes')</span>

<span class="sd">        # Save a new .tflite with the updated metadata</span>
<span class="sd">        tflite_model.save('some/path/my_new_model.tflite')</span>

<span class="sd">        # You must have Tensorflow instance to perform this step</span>
<span class="sd">        # This will run inference with the given buffer and return</span>
<span class="sd">        # the results. The input_buffer can be:</span>
<span class="sd">        # - a single sample as a numpy array</span>
<span class="sd">        # - a numpy array of 1 or more samples</span>
<span class="sd">        # - A Python generator that returns (batch_x, batch_y)</span>
<span class="sd">        # inference_results = tflite_model.predict(..)</span>
<span class="sd">    """</span>

<div class="viewcode-block" id="TfliteModel.load_flatbuffer_file"><a class="viewcode-back" href="../../../../docs/python_api/tflite_model/model.html#mltk.core.TfliteModel.load_flatbuffer_file">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">load_flatbuffer_file</span><span class="p">(</span><span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">cwd</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TfliteModel</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Load a .tflite flatbuffer file"""</span>
        <span class="n">found_path</span> <span class="o">=</span> <span class="n">_existing_path</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">cwd</span><span class="o">=</span><span class="n">cwd</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">found_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s1">'.tflite model file not found: </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">found_path</span><span class="p">,</span> <span class="s1">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">flatbuffer_data</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">TfliteModel</span><span class="p">(</span><span class="n">flatbuffer_data</span><span class="o">=</span><span class="n">flatbuffer_data</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="n">found_path</span><span class="p">)</span></div>


<div class="viewcode-block" id="TfliteModel.__init__"><a class="viewcode-back" href="../../../../docs/python_api/tflite_model/model.html#mltk.core.TfliteModel.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">flatbuffer_data</span><span class="p">:</span> <span class="nb">bytes</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">path</span> <span class="o">=</span> <span class="n">path</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_interpreter</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_interpreter_batch_size</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_flatbuffer_data</span> <span class="p">:</span> <span class="nb">bytes</span> <span class="o">=</span> <span class="n">flatbuffer_data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="p">:</span><span class="n">_tflite_schema_fb</span><span class="o">.</span><span class="n">ModelT</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_selected_model_subgraph_index</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_subgraphs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">_TfliteSubgraph</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_load_model</span><span class="p">()</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">path</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Path to .tflite file</span>
<span class="sd">        Returns None if no path was specified.</span>
<span class="sd">        The path is normalized and backslashes are converted to forward slash</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="kc">None</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_path</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">normpath</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_path</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'</span><span class="se">\\</span><span class="s1">'</span><span class="p">,</span> <span class="s1">'/'</span><span class="p">)</span>
    <span class="nd">@path</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">path</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Path to .tflite file"""</span>
        <span class="k">if</span> <span class="n">v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'</span><span class="se">\\</span><span class="s1">'</span><span class="p">,</span> <span class="s1">'/'</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_path</span> <span class="o">=</span> <span class="n">v</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">filename</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""File name of associated .tflite model file</span>
<span class="sd">        Return None if not path is set"""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_path</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_path</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">name</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""The name of the model which is the :py:attr:`~filename` without the ``.tflite`` extension or "my_model" if no path is set"""</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">filename</span>
        <span class="k">if</span> <span class="n">filename</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">filename</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">'.tflite'</span><span class="p">):</span>
                <span class="n">filename</span> <span class="o">=</span> <span class="n">filename</span><span class="p">[:</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="s1">'.tflite'</span><span class="p">)]</span>
            <span class="k">return</span> <span class="n">filename</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="s1">'my_model'</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">description</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Get/set model description</span>

<span class="sd">        .. note:: :py:func:`~save` must be called for changes to persist</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="s1">''</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">description</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">'utf-8'</span><span class="p">)</span>
    <span class="nd">@description</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">description</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">desc</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">'Model not loaded'</span><span class="p">)</span>
        <span class="n">desc</span> <span class="o">=</span> <span class="n">desc</span> <span class="ow">or</span> <span class="s1">''</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">description</span> <span class="o">=</span> <span class="n">desc</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">'utf-8'</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regenerate_flatbuffer</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">flatbuffer_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bytes</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Flatbuffer binary data"""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_flatbuffer_data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="nb">bytes</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_flatbuffer_data</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">flatbuffer_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Size of the model flatbuffer in bytes"""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatbuffer_data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flatbuffer_data</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatbuffer_size</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">flatbuffer_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_tflite_schema_fb</span><span class="o">.</span><span class="n">ModelT</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Flatbuffer schema Model object"""</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">flatbuffer_subgraph</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_tflite_schema_fb</span><span class="o">.</span><span class="n">SubGraphT</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Flatbuffer schema model subgraph"""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">subgraphs</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_selected_model_subgraph_index</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">selected_model_subgraph</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""The index of the selected model subgraph.</span>
<span class="sd">        Other properties and APIs will return layers/tensors from the selected subgraph</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_selected_model_subgraph_index</span>
    <span class="nd">@selected_model_subgraph</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">selected_model_subgraph</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">if</span> <span class="n">v</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">v</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_subgraphs</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">'Invalid model subgraph index'</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_selected_model_subgraph_index</span> <span class="o">=</span> <span class="n">v</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">n_subgraphs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Return the number of model subgraphs"""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">subgraphs</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">n_inputs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Return the number of model inputs"""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatbuffer_subgraph</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flatbuffer_subgraph</span><span class="o">.</span><span class="n">inputs</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">inputs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">TfliteTensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">"""List of all input tensors"""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatbuffer_subgraph</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="n">retval</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatbuffer_subgraph</span><span class="o">.</span><span class="n">inputs</span><span class="p">:</span>
            <span class="n">retval</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="n">index</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">retval</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">n_outputs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Return the number of model outputs"""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatbuffer_subgraph</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flatbuffer_subgraph</span><span class="o">.</span><span class="n">outputs</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">outputs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">TfliteTensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">"""List of all output tensors"""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatbuffer_subgraph</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="n">retval</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatbuffer_subgraph</span><span class="o">.</span><span class="n">outputs</span><span class="p">:</span>
            <span class="n">retval</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="n">index</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">retval</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">layers</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">TfliteLayer</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">"""List of all model layers for the current subgraph"""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_selected_model_subgraph_index</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_subgraphs</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_selected_model_subgraph_index</span><span class="p">]</span><span class="o">.</span><span class="n">layers</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">TfliteTensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">"""List of all model tensors for the current subgraph"""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_selected_model_subgraph_index</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_subgraphs</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_selected_model_subgraph_index</span><span class="p">]</span><span class="o">.</span><span class="n">tensors</span>


<div class="viewcode-block" id="TfliteModel.summary"><a class="viewcode-back" href="../../../../docs/python_api/tflite_model/model.html#mltk.core.TfliteModel.summary">[docs]</a>    <span class="k">def</span> <span class="nf">summary</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Generate a summary of the model"""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_flatbuffer_data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="s1">'Not loaded'</span>

        <span class="n">t</span> <span class="o">=</span> <span class="n">PrettyTable</span><span class="p">()</span>
        <span class="n">t</span><span class="o">.</span><span class="n">field_names</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s1">'Index'</span><span class="p">,</span>
            <span class="s1">'OpCode'</span><span class="p">,</span>
            <span class="s1">'Input(s)'</span><span class="p">,</span>
            <span class="s1">'Output(s)'</span><span class="p">,</span>
            <span class="s1">'Config'</span>
        <span class="p">]</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">):</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">x</span><span class="o">.</span><span class="n">shape_dtype_str</span><span class="p">(</span><span class="n">include_batch</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">inputs</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">])</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">x</span><span class="o">.</span><span class="n">shape_dtype_str</span><span class="p">(</span><span class="n">include_batch</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">outputs</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">])</span>
            <span class="n">t</span><span class="o">.</span><span class="n">add_row</span><span class="p">([</span>
                <span class="n">i</span><span class="p">,</span>
                <span class="n">layer</span><span class="o">.</span><span class="n">opcode_str</span><span class="p">,</span>
                <span class="n">inputs</span><span class="p">,</span>
                <span class="n">outputs</span><span class="p">,</span>
                <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">layer</span><span class="o">.</span><span class="n">options</span><span class="si">}</span><span class="s1">'</span>
            <span class="p">])</span>

        <span class="n">t</span><span class="o">.</span><span class="n">align</span> <span class="o">=</span> <span class="s1">'l'</span>
        <span class="k">return</span> <span class="n">t</span><span class="o">.</span><span class="n">get_string</span><span class="p">()</span></div>


<div class="viewcode-block" id="TfliteModel.get_flatbuffer_subgraph"><a class="viewcode-back" href="../../../../docs/python_api/tflite_model/model.html#mltk.core.TfliteModel.get_flatbuffer_subgraph">[docs]</a>    <span class="k">def</span> <span class="nf">get_flatbuffer_subgraph</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_tflite_schema_fb</span><span class="o">.</span><span class="n">SubGraphT</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Flatbuffer schema model subgraph at the given index</span>

<span class="sd">        If no index is given, then use the selected_model_subgraph</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">'Model not loaded'</span><span class="p">)</span>
        <span class="n">index</span> <span class="o">=</span> <span class="n">index</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_selected_model_subgraph_index</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">subgraphs</span><span class="p">[</span><span class="n">index</span><span class="p">]</span></div>


<div class="viewcode-block" id="TfliteModel.get_tensor"><a class="viewcode-back" href="../../../../docs/python_api/tflite_model/model.html#mltk.core.TfliteModel.get_tensor">[docs]</a>    <span class="k">def</span> <span class="nf">get_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span> <span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TfliteTensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Return a specific model tensor as a TfliteTensor """</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">'Model not loaded'</span><span class="p">)</span>
        <span class="n">subgraph</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_subgraphs</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_selected_model_subgraph_index</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">index</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">subgraph</span><span class="o">.</span><span class="n">tensors</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Index overflow (</span><span class="si">{</span><span class="n">index</span><span class="si">}</span><span class="s1"> &gt;= </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">subgraph</span><span class="o">.</span><span class="n">tensors</span><span class="p">)</span><span class="si">}</span><span class="s1">)'</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">subgraph</span><span class="o">.</span><span class="n">tensors</span><span class="p">[</span><span class="n">index</span><span class="p">]</span></div>


<div class="viewcode-block" id="TfliteModel.get_tensor_data"><a class="viewcode-back" href="../../../../docs/python_api/tflite_model/model.html#mltk.core.TfliteModel.get_tensor_data">[docs]</a>    <span class="k">def</span> <span class="nf">get_tensor_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span> <span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Return a specific model tensor as a np.ndarray """</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">index</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">tensor</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">tensor</span><span class="o">.</span><span class="n">data</span></div>


<div class="viewcode-block" id="TfliteModel.get_input_tensor"><a class="viewcode-back" href="../../../../docs/python_api/tflite_model/model.html#mltk.core.TfliteModel.get_input_tensor">[docs]</a>    <span class="k">def</span> <span class="nf">get_input_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TfliteTensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Return a model input tensor as a TfliteTensor"""</span>
        <span class="k">if</span> <span class="n">index</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_inputs</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Index overflow (</span><span class="si">{</span><span class="n">index</span><span class="si">}</span><span class="s1"> &gt;= </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_inputs</span><span class="si">}</span><span class="s1">)'</span><span class="p">)</span>
        <span class="n">tensor_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatbuffer_subgraph</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="n">tensor_index</span><span class="p">)</span></div>


<div class="viewcode-block" id="TfliteModel.get_input_data"><a class="viewcode-back" href="../../../../docs/python_api/tflite_model/model.html#mltk.core.TfliteModel.get_input_data">[docs]</a>    <span class="k">def</span> <span class="nf">get_input_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Return a model input as a np.ndarray"""</span>
        <span class="k">if</span> <span class="n">index</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_inputs</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Index overflow (</span><span class="si">{</span><span class="n">index</span><span class="si">}</span><span class="s1"> &gt;= </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_inputs</span><span class="si">}</span><span class="s1">)'</span><span class="p">)</span>
        <span class="n">tensor_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatbuffer_subgraph</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_tensor_data</span><span class="p">(</span><span class="n">tensor_index</span><span class="p">)</span></div>


<div class="viewcode-block" id="TfliteModel.get_output_tensor"><a class="viewcode-back" href="../../../../docs/python_api/tflite_model/model.html#mltk.core.TfliteModel.get_output_tensor">[docs]</a>    <span class="k">def</span> <span class="nf">get_output_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TfliteTensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Return a model output tensor as a TfliteTensor"""</span>
        <span class="k">if</span> <span class="n">index</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_outputs</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Index overflow (</span><span class="si">{</span><span class="n">index</span><span class="si">}</span><span class="s1"> &gt;= </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_outputs</span><span class="si">}</span><span class="s1">)'</span><span class="p">)</span>
        <span class="n">tensor_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatbuffer_subgraph</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="n">tensor_index</span><span class="p">)</span></div>


<div class="viewcode-block" id="TfliteModel.get_output_data"><a class="viewcode-back" href="../../../../docs/python_api/tflite_model/model.html#mltk.core.TfliteModel.get_output_data">[docs]</a>    <span class="k">def</span> <span class="nf">get_output_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Return a model output tensor as a np.ndarray"""</span>
        <span class="k">if</span> <span class="n">index</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_outputs</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Index overflow (</span><span class="si">{</span><span class="n">index</span><span class="si">}</span><span class="s1"> &gt;= </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_outputs</span><span class="si">}</span><span class="s1">)'</span><span class="p">)</span>
        <span class="n">tensor_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatbuffer_subgraph</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_tensor_data</span><span class="p">(</span><span class="n">tensor_index</span><span class="p">)</span></div>


<div class="viewcode-block" id="TfliteModel.get_all_metadata"><a class="viewcode-back" href="../../../../docs/python_api/tflite_model/model.html#mltk.core.TfliteModel.get_all_metadata">[docs]</a>    <span class="k">def</span> <span class="nf">get_all_metadata</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span><span class="nb">bytes</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">"""Return all model metadata as a dictionary"""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">'Model not loaded'</span><span class="p">)</span>
        <span class="n">retval</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">metadata</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">metadata</span><span class="p">:</span>
            <span class="n">name</span> <span class="o">=</span> <span class="n">metadata</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">"utf-8"</span><span class="p">)</span>
            <span class="n">buffer_index</span> <span class="o">=</span> <span class="n">metadata</span><span class="o">.</span><span class="n">buffer</span>
            <span class="n">retval</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">buffers</span><span class="p">[</span><span class="n">buffer_index</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">tobytes</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">retval</span></div>


<div class="viewcode-block" id="TfliteModel.get_metadata"><a class="viewcode-back" href="../../../../docs/python_api/tflite_model/model.html#mltk.core.TfliteModel.get_metadata">[docs]</a>    <span class="k">def</span> <span class="nf">get_metadata</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tag</span> <span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bytes</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Return model metadata with specified tag"""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">'Model not loaded'</span><span class="p">)</span>
        <span class="n">metadata_value</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">for</span> <span class="n">metadata</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">metadata</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">metadata</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">"utf-8"</span><span class="p">)</span> <span class="o">==</span> <span class="n">tag</span><span class="p">:</span>
                <span class="n">buffer_index</span> <span class="o">=</span> <span class="n">metadata</span><span class="o">.</span><span class="n">buffer</span>
                <span class="n">metadata_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">buffers</span><span class="p">[</span><span class="n">buffer_index</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">tobytes</span><span class="p">()</span>
                <span class="k">break</span>

        <span class="k">return</span> <span class="n">metadata_value</span></div>


<div class="viewcode-block" id="TfliteModel.add_metadata"><a class="viewcode-back" href="../../../../docs/python_api/tflite_model/model.html#mltk.core.TfliteModel.add_metadata">[docs]</a>    <span class="k">def</span> <span class="nf">add_metadata</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tag</span> <span class="p">:</span><span class="nb">str</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">bytes</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Set or add metadata to model</span>

<span class="sd">        .. Note::</span>
<span class="sd">            :func:`~tflite_model.TfliteModel.save` must be called for changes to persist</span>

<span class="sd">        Args:</span>
<span class="sd">            tag (str): The key to use to lookup the metadata</span>
<span class="sd">            value (bytes): The metadata value as a binary blob to add to the .tflite</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">'Model not loaded'</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">tag</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">value</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">'Must provide valid tag and value arguments'</span><span class="p">)</span>


        <span class="n">buffer_field</span> <span class="o">=</span> <span class="n">_tflite_schema_fb</span><span class="o">.</span><span class="n">BufferT</span><span class="p">()</span>
        <span class="n">buffer_field</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">frombuffer</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>

        <span class="n">add_buffer</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">metadata</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">metadata</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Check if metadata has already been add to the model.</span>
            <span class="k">for</span> <span class="n">meta</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">metadata</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">meta</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">"utf-8"</span><span class="p">)</span> <span class="o">==</span> <span class="n">tag</span><span class="p">:</span>
                    <span class="n">add_buffer</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">buffers</span><span class="p">[</span><span class="n">meta</span><span class="o">.</span><span class="n">buffer</span><span class="p">]</span> <span class="o">=</span> <span class="n">buffer_field</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">add_buffer</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">buffers</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">buffers</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">buffers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">buffer_field</span><span class="p">)</span>
            <span class="c1"># Creates a new metadata field.</span>
            <span class="n">metadata_field</span> <span class="o">=</span> <span class="n">_tflite_schema_fb</span><span class="o">.</span><span class="n">MetadataT</span><span class="p">()</span>
            <span class="n">metadata_field</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">tag</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">'utf-8'</span><span class="p">)</span>
            <span class="n">metadata_field</span><span class="o">.</span><span class="n">buffer</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">buffers</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metadata_field</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">regenerate_flatbuffer</span><span class="p">()</span></div>


<div class="viewcode-block" id="TfliteModel.remove_metadata"><a class="viewcode-back" href="../../../../docs/python_api/tflite_model/model.html#mltk.core.TfliteModel.remove_metadata">[docs]</a>    <span class="k">def</span> <span class="nf">remove_metadata</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tag</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Remove model metadata with specified tag</span>

<span class="sd">        .. Note::</span>
<span class="sd">            :func:`~tflite_model.TfliteModel.save` must be called for changes to persist</span>

<span class="sd">        Args:</span>
<span class="sd">            tag (str): The key to use to lookup the metadata</span>

<span class="sd">        Return:</span>
<span class="sd">            True if the metadata was found and removed, False else</span>

<span class="sd">        """</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">'Model not loaded'</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">metadata</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="n">removed_metadata</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">for</span> <span class="n">meta</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">metadata</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">meta</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">"utf-8"</span><span class="p">)</span> <span class="o">==</span> <span class="n">tag</span><span class="p">:</span>
                <span class="n">removed_metadata</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">meta</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">buffers</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">meta</span><span class="o">.</span><span class="n">buffer</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">regenerate_flatbuffer</span><span class="p">()</span>
                <span class="k">break</span>

        <span class="k">return</span> <span class="n">removed_metadata</span></div>


<div class="viewcode-block" id="TfliteModel.save"><a class="viewcode-back" href="../../../../docs/python_api/tflite_model/model.html#mltk.core.TfliteModel.save">[docs]</a>    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Save flatbuffer data to file</span>
<span class="sd">        If output_path is specified then write to new file,</span>
<span class="sd">        otherwise overwrite existing file</span>
<span class="sd">        """</span>
        <span class="n">output_path</span> <span class="o">=</span> <span class="n">output_path</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">path</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">output_path</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">'No output path specified'</span><span class="p">)</span>

       <span class="c1"># Re-generate the underlying flatbuffer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regenerate_flatbuffer</span><span class="p">()</span>

        <span class="c1"># Create the model's output directory if necessary</span>
        <span class="n">out_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">output_path</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">out_dir</span><span class="p">:</span>
            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">out_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="s1">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_flatbuffer_data</span><span class="p">)</span></div>


<div class="viewcode-block" id="TfliteModel.regenerate_flatbuffer"><a class="viewcode-back" href="../../../../docs/python_api/tflite_model/model.html#mltk.core.TfliteModel.regenerate_flatbuffer">[docs]</a>    <span class="k">def</span> <span class="nf">regenerate_flatbuffer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Re-generate the underlying flatbuffer based on  the information cached in the local ModelT instance</span>

<span class="sd">        .. Note::</span>
<span class="sd">            :func:`~tflite_model.TfliteModel.save` must be called for changes to persist</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">'Model not loaded'</span><span class="p">)</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">flatbuffers</span><span class="o">.</span><span class="n">Builder</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">b</span><span class="o">.</span><span class="n">Finish</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">Pack</span><span class="p">(</span><span class="n">b</span><span class="p">),</span> <span class="n">TFLITE_FILE_IDENTIFIER</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_flatbuffer_data</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">Output</span><span class="p">()</span></div>


<div class="viewcode-block" id="TfliteModel.predict"><a class="viewcode-back" href="../../../../docs/python_api/tflite_model/model.html#mltk.core.TfliteModel.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">x</span><span class="p">:</span><span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Iterator</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]],</span>
        <span class="n">y_dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Invoke the TfLite interpreter with the given input sample and return the results</span>

<span class="sd">        If the model has a single input and output, the x data can one of:</span>

<span class="sd">        - A single sample as a numpy array</span>
<span class="sd">        - Iterable list of samples</span>
<span class="sd">        - Sample generator</span>

<span class="sd">        In this case, this API will manage converting</span>
<span class="sd">        the samples to the correct data type and adding the necessary batch dimension. The</span>
<span class="sd">        output value will either be list of model predictions or a single prediction corresponding to the input.</span>

<span class="sd">        If the model has multiple inputs and outputs, then the input data must be one of:</span>

<span class="sd">        - Python list of numpy arrays. One numpy array per model input. The numpy arrays must only contain the values for one sample.</span>
<span class="sd">          The input numpy arrays do NOT need to have the batch dimension. In this case, the output values will also not have the batch dimension.</span>
<span class="sd">        - Dictionary of one or more numpy arrays. The dictionary key should be an integer corresponding to the model input,</span>
<span class="sd">          and the value should be a numpy array. The input numpy arrays do NOT need to have the batch dimension.</span>
<span class="sd">          In this case, the output values will also not have the batch dimension.</span>

<span class="sd">        Args:</span>
<span class="sd">            x: The input samples(s) as a numpy array or data generator.</span>
<span class="sd">                If x is a numpy array then it must have the same shape as the model input</span>
<span class="sd">                or it must be a vector (i.e. batch) of samples having the same shape as the model input.</span>
<span class="sd">                The data type must either be the same as the model input's OR it must be a float32,</span>
<span class="sd">                in which case the input sample will automatically be quantized using the model input's</span>
<span class="sd">                quantizing scaler/zeropoint.</span>
<span class="sd">                If x is a generator, then each iteration must return a tuple: batch_x, batch_y</span>
<span class="sd">                batch_x must  be a vector (i.e. batch) of samples having the same shape as the model input</span>
<span class="sd">                batch_y is ignored.</span>
<span class="sd">            y_dtype: The return value's data type. By default, data type is None in which case the model output is directly returned.</span>
<span class="sd">                If y_dtype=np.float32 then the model output is de-quantized to float32 using the model's output</span>
<span class="sd">                quantization scaler/zeropoint (if necessary)</span>

<span class="sd">        Returns:</span>
<span class="sd">            Output of model inference, y. If x was a single sample, then y is a single result. Otherwise</span>
<span class="sd">            y is a vector (i.e. batch) of model results.</span>
<span class="sd">            If y_dtype is given, the y if automatically converted/de-quantized to the given dtype.</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_flatbuffer_data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">'Model not loaded'</span><span class="p">)</span>

        <span class="n">input0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_input_tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">input0_shape</span> <span class="o">=</span> <span class="n">input0</span><span class="o">.</span><span class="n">shape</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_inputs</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span><span class="nb">tuple</span><span class="p">)):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">x</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">'''</span>
<span class="s1">                        For multi-input models, the input data must be a list of numpy arrays</span>
<span class="s1">                    '''</span><span class="p">)</span>
                <span class="n">x</span> <span class="o">=</span> <span class="p">{</span><span class="n">index</span><span class="p">:</span> <span class="n">value</span> <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">x</span><span class="p">)}</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">x</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">'''</span>
<span class="s1">                        For multi-input models, the input data must be a dictionary of numpy arrays</span>
<span class="s1">                        with the keys corresponding to the model input index</span>
<span class="s1">                    '''</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">'''</span>
<span class="s1">                    For multi-input models, the input data must be a list of numpy arrays or</span>
<span class="s1">                    dictionary of numpy arrays with the keys corresponding to the model input index</span>
<span class="s1">                '''</span><span class="p">)</span>

            <span class="c1"># Set the input tensors</span>
            <span class="n">has_batch_dim</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">for</span> <span class="n">input_index</span><span class="p">,</span> <span class="n">x_i</span> <span class="ow">in</span> <span class="n">x</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">input_index</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="c1"># Check if the input sample has the batch dimension</span>
                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_i</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">input0_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
                        <span class="n">has_batch_dim</span> <span class="o">=</span> <span class="kc">False</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_allocate_tflite_interpreter</span><span class="p">(</span>
                            <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                            <span class="n">interpreter_kwargs</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'interpreter_kwargs'</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                        <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_allocate_tflite_interpreter</span><span class="p">(</span>
                            <span class="n">batch_size</span><span class="o">=</span><span class="n">x_i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                            <span class="n">interpreter_kwargs</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'interpreter_kwargs'</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                        <span class="p">)</span>

                <span class="c1"># Add the batch_size=1 if the input sample doesn't have a batch dim</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">has_batch_dim</span><span class="p">:</span>
                    <span class="n">x_i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">x_i</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

                <span class="c1"># If the input sample isn't the same as the model input dtype,</span>
                <span class="c1"># then we need to manually convert it first</span>
                <span class="c1"># NOTE: If the model input type is float32 then</span>
                <span class="c1">#       quantization is done automatically inside the model</span>
                <span class="n">x_i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantize_to_input_dtype</span><span class="p">(</span><span class="n">x_i</span><span class="p">,</span> <span class="n">input_index</span><span class="o">=</span><span class="n">input_index</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_interpreter</span><span class="o">.</span><span class="n">set_tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_input_tensor</span><span class="p">(</span><span class="n">input_index</span><span class="p">)</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">x_i</span><span class="p">)</span>

            <span class="c1"># Execute the model</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_interpreter</span><span class="o">.</span><span class="n">invoke</span><span class="p">()</span>

            <span class="c1"># Get the model results</span>
            <span class="n">y</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">outp</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">):</span>
                <span class="n">y_i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_interpreter</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="n">outp</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>

                <span class="c1"># If the input doesn't have a batch dim</span>
                <span class="c1"># then remove the dim from the output</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">has_batch_dim</span><span class="p">:</span>
                    <span class="n">y_i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">y_i</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">y_dtype</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">:</span>
                    <span class="c1"># Convert the output data type to float32 if necessary</span>
                    <span class="n">y_i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dequantize_output_to_float32</span><span class="p">(</span><span class="n">y_i</span><span class="p">,</span> <span class="n">output_index</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>

                <span class="n">y</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_i</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">y</span>


        <span class="c1"># This expects either</span>
        <span class="c1"># [n_samples, input_shape...]</span>
        <span class="c1"># OR</span>
        <span class="c1"># [input_shape ...]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="n">is_single_sample</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">input0_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
                <span class="n">is_single_sample</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="c1"># Add the batch dimension if we were only given a single sample</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_allocate_tflite_interpreter</span><span class="p">(</span>
                    <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">interpreter_kwargs</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'interpreter_kwargs'</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_allocate_tflite_interpreter</span><span class="p">(</span>
                    <span class="n">batch_size</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                    <span class="n">interpreter_kwargs</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'interpreter_kwargs'</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                <span class="p">)</span>

            <span class="c1"># If the input sample isn't the same as the model input dtype,</span>
            <span class="c1"># then we need to manually convert it first</span>
            <span class="c1"># NOTE: If the model input type is float32 then</span>
            <span class="c1">#       quantization is done automatically inside the model</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantize_to_input_dtype</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

            <span class="c1"># If the last dimension of the model's input shape is 1,</span>
            <span class="c1"># and the input data is missing this dimension</span>
            <span class="c1"># then automatically expand the dimension</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input0_shape</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="ow">and</span> <span class="n">input0_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

            <span class="c1"># Then set model input tensor</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_interpreter</span><span class="o">.</span><span class="n">set_tensor</span><span class="p">(</span><span class="n">input0</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
            <span class="c1"># Execute the model</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_interpreter</span><span class="o">.</span><span class="n">invoke</span><span class="p">()</span>

            <span class="c1"># Get the model results</span>
            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_interpreter</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_output_tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>

            <span class="c1"># Convert the output data type to float32 if necessary</span>
            <span class="c1"># NOTE: If the model output type is float32 then</span>
            <span class="c1">#       de-quantization is done automatically inside the model</span>

            <span class="k">if</span> <span class="n">y_dtype</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">:</span>
                <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dequantize_output_to_float32</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

            <span class="c1"># Remove the batch dimension if we were only given a single sample</span>
            <span class="k">if</span> <span class="n">is_single_sample</span><span class="p">:</span>
                <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">y</span>

        <span class="c1"># Else if we were given a data generator</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">n_samples</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">batch_results</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>
                <span class="n">batch_x</span> <span class="o">=</span> <span class="n">batch</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="k">else</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">_allocate_tflite_interpreter</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

                <span class="c1"># If the input sample isn't the same as the model input dtype,</span>
                <span class="c1"># then we need to manually convert it first</span>
                <span class="n">batch_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantize_to_input_dtype</span><span class="p">(</span><span class="n">batch_x</span><span class="p">)</span>

                <span class="c1"># If the last dimension of the model's input shape is 1,</span>
                <span class="c1"># and the batch data is missing this dimension</span>
                <span class="c1"># then automatically expand the dimension</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input0_shape</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="ow">and</span> <span class="n">input0_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">batch_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">batch_x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

                <span class="c1"># The set model input tensor</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_interpreter</span><span class="o">.</span><span class="n">set_tensor</span><span class="p">(</span><span class="n">input0</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">batch_x</span><span class="p">)</span>
                <span class="c1"># Execute the model</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_interpreter</span><span class="o">.</span><span class="n">invoke</span><span class="p">()</span>

                <span class="c1"># Get the model results</span>
                <span class="n">batch_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_interpreter</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_output_tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">y_dtype</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">:</span>
                    <span class="c1"># Convert the output data type to float32 if necessary</span>
                    <span class="n">batch_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dequantize_output_to_float32</span><span class="p">(</span><span class="n">batch_y</span><span class="p">)</span>

                <span class="n">batch_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_y</span><span class="p">)</span>
                <span class="n">n_samples</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_y</span><span class="p">)</span>

                <span class="c1"># If the generator specifies a "max_samples" property</span>
                <span class="c1"># then break out of the loop once the specified number of samples have been processed</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">'max_samples'</span><span class="p">)</span> <span class="ow">and</span> <span class="n">x</span><span class="o">.</span><span class="n">max_samples</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">n_samples</span> <span class="o">&gt;=</span> <span class="n">x</span><span class="o">.</span><span class="n">max_samples</span><span class="p">:</span>
                            <span class="k">break</span>
                <span class="k">except</span><span class="p">:</span>
                    <span class="k">pass</span>

            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_results</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">'No batch samples where generated by the data given data generator'</span><span class="p">)</span>

            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_results</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">output_shape</span> <span class="o">=</span> <span class="n">batch_results</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>

            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">'max_samples'</span><span class="p">)</span> <span class="ow">and</span> <span class="n">x</span><span class="o">.</span><span class="n">max_samples</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">n_samples</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">max_samples</span>

            <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="o">*</span><span class="n">output_shape</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">batch_y</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">batch_index</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batch_results</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">result_index</span><span class="p">,</span> <span class="n">result</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
                    <span class="n">index</span> <span class="o">=</span> <span class="n">batch_index</span> <span class="o">*</span> <span class="n">batch_size</span> <span class="o">+</span> <span class="n">result_index</span>
                    <span class="k">if</span> <span class="n">index</span> <span class="o">&gt;=</span> <span class="n">n_samples</span><span class="p">:</span>
                        <span class="k">break</span>
                    <span class="n">y</span><span class="p">[</span><span class="n">index</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">result</span>

            <span class="k">return</span> <span class="n">y</span></div>


<div class="viewcode-block" id="TfliteModel.quantize_to_input_dtype"><a class="viewcode-back" href="../../../../docs/python_api/tflite_model/model.html#mltk.core.TfliteModel.quantize_to_input_dtype">[docs]</a>    <span class="k">def</span> <span class="nf">quantize_to_input_dtype</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">input_index</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Quantize the input sample(s) to the model's input dtype (if necessary)"""</span>

        <span class="n">input_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_input_tensor</span><span class="p">(</span><span class="n">input_index</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">input_tensor</span><span class="o">.</span><span class="n">dtype</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x</span>

        <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">'The sample input must be float32 or the same dtype as the model input'</span><span class="p">)</span>

        <span class="c1"># Convert from float32 to the model input data type</span>
        <span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">/</span> <span class="n">input_tensor</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">scale</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="n">input_tensor</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">zeropoint</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">input_tensor</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span></div>


<div class="viewcode-block" id="TfliteModel.dequantize_output_to_float32"><a class="viewcode-back" href="../../../../docs/python_api/tflite_model/model.html#mltk.core.TfliteModel.dequantize_output_to_float32">[docs]</a>    <span class="k">def</span> <span class="nf">dequantize_output_to_float32</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">output_index</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""De-quantize the model output to float32 (if necessary)"""</span>
        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">y</span>

        <span class="n">output_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_output_tensor</span><span class="p">(</span><span class="n">output_index</span><span class="p">)</span>

        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">output_tensor</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">zeropoint</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="n">output_tensor</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">scale</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span></div>



    <span class="k">def</span> <span class="nf">_allocate_tflite_interpreter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">interpreter_kwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_interpreter</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_interpreter_batch_size</span> <span class="o">!=</span> <span class="n">batch_size</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
            <span class="k">except</span> <span class="ne">ModuleNotFoundError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ModuleNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s1">'You must first install the "tensorflow" Python package to run inference, err: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span> <span class="c1"># pylint: disable=raise-missing-from</span>

            <span class="n">interpreter_kwargs</span> <span class="o">=</span> <span class="n">interpreter_kwargs</span> <span class="ow">or</span> <span class="p">{}</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_interpreter_batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_interpreter</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">lite</span><span class="o">.</span><span class="n">Interpreter</span><span class="p">(</span>
                <span class="n">model_path</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_path</span><span class="p">,</span>
                <span class="o">**</span><span class="n">interpreter_kwargs</span>
            <span class="p">)</span>

            <span class="n">input_indices</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">inp</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">:</span>
                <span class="n">input_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
                <span class="n">new_input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">*</span><span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_interpreter</span><span class="o">.</span><span class="n">resize_tensor_input</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">new_input_shape</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">outp</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">outp</span><span class="o">.</span><span class="n">index</span> <span class="ow">in</span> <span class="n">input_indices</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="n">new_output_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">*</span><span class="n">outp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_interpreter</span><span class="o">.</span><span class="n">resize_tensor_input</span><span class="p">(</span><span class="n">outp</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">new_output_shape</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_interpreter</span><span class="o">.</span><span class="n">allocate_tensors</span><span class="p">()</span>


    <span class="k">def</span> <span class="nf">_load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="n">_tflite_schema_fb</span><span class="o">.</span><span class="n">ModelT</span><span class="o">.</span><span class="n">InitFromObj</span><span class="p">(</span><span class="n">_tflite_schema_fb</span><span class="o">.</span><span class="n">Model</span><span class="o">.</span><span class="n">GetRootAsModel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_flatbuffer_data</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
            <span class="n">subgraph_count</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">subgraphs</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span> <span class="c1"># pylint: disable=raise-missing-from</span>
                <span class="s1">'Failed to load .tflite model flatbuffer.</span><span class="se">\n</span><span class="s1">'</span>
                <span class="s1">'Ensure you have provided a valid .tflite model (i.e. ensure the binary data has not been corrupted)</span><span class="se">\n</span><span class="s1">'</span>
                <span class="sa">f</span><span class="s1">'Error details: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s1">'</span>
            <span class="p">)</span>

        <span class="n">schema_version</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">version</span>
        <span class="k">if</span> <span class="n">schema_version</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">'TF-Lite schema v3 is only supported'</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_selected_model_subgraph_index</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_selected_model_subgraph_index</span> <span class="o">&gt;=</span> <span class="n">subgraph_count</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_selected_model_subgraph_index</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_subgraphs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">fb_subgraph</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">subgraphs</span><span class="p">:</span>
            <span class="n">subgraph</span> <span class="o">=</span> <span class="n">_TfliteSubgraph</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_subgraphs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">subgraph</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">fb_tensor</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">fb_subgraph</span><span class="o">.</span><span class="n">tensors</span><span class="p">):</span>
                <span class="n">tensor</span> <span class="o">=</span> <span class="n">TfliteTensor</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="bp">self</span><span class="p">,</span> <span class="n">fb_tensor</span><span class="p">)</span>
                <span class="n">subgraph</span><span class="o">.</span><span class="n">tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">operator</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">fb_subgraph</span><span class="o">.</span><span class="n">operators</span><span class="p">):</span>
                <span class="n">layer</span> <span class="o">=</span> <span class="n">TfliteLayer</span><span class="o">.</span><span class="n">from_flatbuffer</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="bp">self</span><span class="p">,</span> <span class="n">operator</span><span class="p">)</span>
                <span class="n">subgraph</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span></div>



<span class="k">def</span> <span class="nf">_existing_path</span><span class="p">(</span><span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">cwd</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">cwd</span><span class="p">:</span>
        <span class="n">found_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">cwd</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s1">'</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">found_path</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">found_path</span>

    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">path</span>

    <span class="k">return</span> <span class="kc">None</span>

<span class="k">class</span> <span class="nc">_TfliteSubgraph</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">TfliteLayer</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tensors</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">TfliteTensor</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

</pre></div>

          </article>
        </div>
      </div>
      <a href="#" class="go-top"><i class="md-icon">arrow_upward</i>Back to Top</a>
    </main>
  </div>
  <footer class="md-footer">
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
          
          
        </a>
        
      </nav>
    </div>
    <div class="md-footer-meta md-typeset">
      <div class="md-footer-meta__inner md-grid">
        <div class="md-footer-copyright">
          <div class="md-footer-copyright__highlight">
              &#169; Copyright 2023, Silicon Labs.
              
          </div>
            Last updated on
              Sep 12, 2023.
            <br/>
            Created using
            <a href="http://www.sphinx-doc.org/">Sphinx</a> 5.3.0.
             and
            <a href="https://github.com/bashtage/sphinx-material/">Material for
              Sphinx</a>
        </div>
        <button id="survey-link" class="feedback-button">Feedback</button>
      </div>
    </div>
  </footer>
  <div class="privacy-banner">
    <div class="privacy-banner-wrapper">
      <p>
        <b>Important:</b> We use cookies only for functional and traffic analytics. <br />
        We DO NOT use cookies for any marketing purposes. By using our site you acknowledge you have read and understood our <a class="privacy-policy" href="https://www.silabs.com/about-us/legal/cookie-policy" target="_blank">Cookie Policy</a>.
      </p>
      <a class="privacy-banner-accept" href="#">Got it</a>
    </div>
</div>
  
<div class="survey-container" id="dlg-survey"> 
    <div class="close" id="dlg-survey-close"><i class="md-icon">close</i></div>
    <div class="msg">Please click the <b>submit</b> button at the end even if you do not answer all of the questions</div>
    <iframe id="iframe-survey" style="width: 100%; height: 100%;"></iframe>
</div>
  
  <script src="../../../../_static/javascripts/application.js"></script>
  <script>app.initialize({version: "1.0.4", url: {base: ".."}})</script>
  </body>
</html>