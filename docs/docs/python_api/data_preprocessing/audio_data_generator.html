
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width,initial-scale=1">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="title" content="Machine Learning Toolkit">
<meta name="description" content="A Python package with command-line utilities and scripts to aid the development of machine learning models for Silicon Lab's embedded platforms">
<meta name="keywords" content="machine learning, machine-learning, machinelearning, ml, ai, iot, Internet of things, aiot, tinyml, tensorflow, tensorflow-lite, tensorflow-lite-micro, keras-tensorflow, keras, tflite, embedded, embedded-systems, mcu, Microcontrollers, hardware, python, c++, cmake, keras, numpy, silabs, silicon labs">
<meta name="robots" content="index, follow">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="language" content="English">
<meta name="author" content="Silicon Labs">
  <meta name="lang:clipboard.copy" content="Copy to clipboard">
  <meta name="lang:clipboard.copied" content="Copied to clipboard">
  <meta name="lang:search.language" content="en">
  <meta name="lang:search.pipeline.stopwords" content="True">
  <meta name="lang:search.pipeline.trimmer" content="True">
  <meta name="lang:search.result.none" content="No matching documents">
  <meta name="lang:search.result.one" content="1 matching document">
  <meta name="lang:search.result.other" content="# matching documents">
  <meta name="lang:search.tokenizer" content="[\s\-]+">

  
    <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&display=fallback" rel="stylesheet">

    <style>
      body,
      input {
        font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif
      }

      code,
      kbd,
      pre {
        font-family: "Roboto Mono", "Courier New", Courier, monospace
      }
    </style>
  

  <link rel="stylesheet" href="../../../_static/stylesheets/application.css"/>
  <link rel="stylesheet" href="../../../_static/stylesheets/application-palette.css"/>
  <link rel="stylesheet" href="../../../_static/stylesheets/application-fixes.css"/>
  
  <link rel="stylesheet" href="../../../_static/fonts/material-icons.css"/>
  
  <meta name="theme-color" content="#3f51b5">
  <script src="../../../_static/javascripts/modernizr.js"></script>
  
<script async src="https://www.googletagmanager.com/gtag/js?id=G-HZ5MW943WF"></script>
<script>
    window.gTrackingId = 'G-HZ5MW943WF';
</script>
<meta name="google-site-verification" content="dsSsmnE2twOnfSAQk5zBBTrjMArsTJj809Bp-8mVlIw" />
  
  
    <title>ParallelAudioDataGenerator &#8212; MLTK 0.16.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/material.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/custom.css" />
    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/sphinx_highlight.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/design-tabs.js"></script>
    <script src="../../../_static/js/custom.js"></script>
    <script src="../../../_static/js/apitoc.js"></script>
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="ParallelProcessParams" href="audio_data_generator_params.html" />
    <link rel="prev" title="ParallelProcessParams" href="image_data_generator_params.html" />
  
   

  </head>
  <body dir=ltr
        data-md-color-primary=red data-md-color-accent=light-blue>
  
  <svg class="md-svg">
    <defs data-children-count="0">
      
      <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
      
    </defs>
  </svg>
  
  <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer">
  <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search">
  <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
  <a href="#docs/python_api/data_preprocessing/audio_data_generator" tabindex="1" class="md-skip"> Skip to content </a>
  <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex navheader">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../../../index.html" title="MLTK 0.16.0 documentation"
           class="md-header-nav__button md-logo">
          
              <img src="../../../_static/logo.png"
                   alt="MLTK 0.16.0 documentation logo">
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          <span class="md-header-nav__topic">Machine Learning Toolkit</span>
          <span class="md-header-nav__topic"> ParallelAudioDataGenerator </span>
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
        
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" action="../../../search.html" method="get" name="search">
      <input type="text" class="md-search__input" name="q" placeholder=""Search""
             autocapitalize="off" autocomplete="off" spellcheck="false"
             data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>

      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            <a href="https://github.com/siliconlabs/mltk" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    MLTK Github Repository
  </div>
</a>
          </div>
        </div>
      
      
    </div>
  </nav>
</header>

  
  <div class="md-container">
    
    
    
  <nav class="md-tabs" data-md-component="tabs">
    <div class="md-tabs__inner md-grid">
      <ul class="md-tabs__list">
            
            <li class="md-tabs__item"><a href="https://docs.silabs.com/gecko-platform/latest/machine-learning/tensorflow/overview" class="md-tabs__link">Gecko SDK Documentation</a></li>
            
            <li class="md-tabs__item"><a href="https://github.com/tensorflow/tflite-micro" class="md-tabs__link">Tensorflow-Lite Micro Repository</a></li>
            
            <li class="md-tabs__item"><a href="https://www.tensorflow.org/learn" class="md-tabs__link">Tensorflow Documentation</a></li>
          <li class="md-tabs__item"><a href="../index.html" class="md-tabs__link">API Reference</a></li>
          <li class="md-tabs__item"><a href="index.html" class="md-tabs__link">Data Preprocessing</a></li>
      </ul>
    </div>
  </nav>
    <main class="md-main">
      <div class="md-main__inner md-grid" data-md-component="container">
        
          <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../../../index.html" title="MLTK 0.16.0 documentation" class="md-nav__button md-logo">
      
        <img src="../../../_static/logo.png" alt=" logo" width="48" height="48">
      
    </a>
    <a href="../../../index.html"
       title="MLTK 0.16.0 documentation">Machine Learning Toolkit</a>
  </label>
    <div class="md-nav__source">
      <a href="https://github.com/siliconlabs/mltk" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    MLTK Github Repository
  </div>
</a>
    </div>
  
  

  
  <ul class="md-nav__list">
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Basics</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../overview.html" class="md-nav__link">Overview</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../why_mltk.html" class="md-nav__link">Why MLTK?</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../installation.html" class="md-nav__link">Installation</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../command_line/index.html" class="md-nav__link">Command-Line</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../guides/index.html" class="md-nav__link">Modeling Guides</a>
      
    
    </li>
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Usage</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../tutorials.html" class="md-nav__link">Tutorials</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../examples.html" class="md-nav__link">API Examples</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../index.html" class="md-nav__link">API Reference</a>
      <ul class="md-nav__list"> 
    <li class="md-nav__item">
    
    
      <a href="../operations/index.html" class="md-nav__link">Model Operations</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../mltk_model/index.html" class="md-nav__link">MLTK Model</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../tflite_micro_model/index.html" class="md-nav__link">Tensorflow-Lite Micro Model</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../tflite_model/index.html" class="md-nav__link">Tensorflow-Lite Model</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../keras_model.html" class="md-nav__link">Keras Model</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="index.html" class="md-nav__link">Data Preprocessing</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../utils/index.html" class="md-nav__link">Utilities</a>
      
    
    </li></ul>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../models/index.html" class="md-nav__link">Reference Models</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../datasets/index.html" class="md-nav__link">Reference Datasets</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../cpp_development/index.html" class="md-nav__link">C++ Development</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../cpp_development/examples/index.html" class="md-nav__link">C++ Examples</a>
      
    
    </li>
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Audio Related</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../audio/keyword_spotting_overview.html" class="md-nav__link">Keyword Spotting Overview</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../audio/audio_feature_generator.html" class="md-nav__link">Audio Feature Generator</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../audio/audio_utilities.html" class="md-nav__link">Audio Utilities</a>
      
    
    </li>
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Other Information</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../faq/index.html" class="md-nav__link">Frequently Asked Questions</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../other/quick_reference.html" class="md-nav__link">Quick Reference</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../other/supported_hardware.html" class="md-nav__link">Supported Hardware</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../guides/notebook_examples_guide.html" class="md-nav__link">Notebook Examples Guide</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../other/settings_file.html" class="md-nav__link">Settings File</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../other/environment_variables.html" class="md-nav__link">Environment Variables</a>
      
    
    </li>
  </ul>
  

</nav>
              </div>
            </div>
          </div>
          <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                
<nav class="md-nav md-nav--secondary">
    <label class="md-nav__title" for="__toc">Contents</label>
  <ul class="md-nav__list" data-md-scrollfix="" id="localtoc">
        <li class="md-nav__item"><a href="#docs-python-api-data-preprocessing-audio-data-generator--page-root" class="md-nav__link">ParallelAudioDataGenerator</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">ParallelAudioDataGenerator</span></code></a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.__init__" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">ParallelAudioDataGenerator.__init__()</span></code></a>
        </li>
        <li class="md-nav__item"><a href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.sample_shape" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">ParallelAudioDataGenerator.sample_shape</span></code></a>
        </li>
        <li class="md-nav__item"><a href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.sample_length" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">ParallelAudioDataGenerator.sample_length</span></code></a>
        </li>
        <li class="md-nav__item"><a href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.sample_length_ms" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">ParallelAudioDataGenerator.sample_length_ms</span></code></a>
        </li>
        <li class="md-nav__item"><a href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.sample_rate_hz" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">ParallelAudioDataGenerator.sample_rate_hz</span></code></a>
        </li>
        <li class="md-nav__item"><a href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.flow_from_directory" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">ParallelAudioDataGenerator.flow_from_directory()</span></code></a>
        </li>
        <li class="md-nav__item"><a href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.default_transform" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">ParallelAudioDataGenerator.default_transform</span></code></a>
        </li>
        <li class="md-nav__item"><a href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.get_random_transform" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">ParallelAudioDataGenerator.get_random_transform()</span></code></a>
        </li>
        <li class="md-nav__item"><a href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.adjust_length" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">ParallelAudioDataGenerator.adjust_length()</span></code></a>
        </li>
        <li class="md-nav__item"><a href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.apply_transform" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">ParallelAudioDataGenerator.apply_transform()</span></code></a>
        </li>
        <li class="md-nav__item"><a href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.apply_frontend" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">ParallelAudioDataGenerator.apply_frontend()</span></code></a>
        </li>
        <li class="md-nav__item"><a href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.standardize" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">ParallelAudioDataGenerator.standardize()</span></code></a>
        </li></ul>
            </nav>
        </li></ul>
            </nav>
        </li>
      <script type="text/javascript" src=../../../_static/js/apitoc.js></script>
  </ul>
</nav>
              </div>
            </div>
          </div>
        
        <div class="md-content">

          
          <div class="breadcrumbs md-typeset">
            <ul class="breadcrumb">
              <li></li>
              <li><a href="../../../index.html"><i class="md-icon">home</i></a></li>
                <li><a href="../index.html" >API Reference</a></li>
                <li><a href="index.html" accesskey="U">Data Preprocessing</a></li>

              <li class="activate"><a>ParallelAudioDataGenerator</a></li>
            </ul>
          </div>
          

          <article class="md-content__inner md-typeset" role="main">
            
  <section id="parallelaudiodatagenerator">
<h1 id="docs-python-api-data-preprocessing-audio-data-generator--page-root">ParallelAudioDataGenerator<a class="headerlink" href="#docs-python-api-data-preprocessing-audio-data-generator--page-root" title="Permalink to this heading">¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">ParallelAudioDataGenerator</span></span><a class="reference internal" href="../../../_modules/mltk/core/preprocess/audio/parallel_generator/parallel_generator.html#ParallelAudioDataGenerator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Parallel Audio Data Generator</p>
<p>This class as a similar functionality to the <a class="reference external" href="https://keras.io/preprocessing/image">Keras ImageDataGenerator</a></p>
<p>Except, instead of processing image files it processes audio files.</p>
<p>Additionally, batch samples are asynchronously processed using the Python
‘multiprocessing’ package. This allows for efficient use of multi-core systems
as future batch samples can be concurrently processed while processed batches may be
used for training.</p>
<p>This class works as follows:</p>
<ol class="arabic simple">
<li><p>Class instantiated with parameters (see below)</p></li>
<li><p><a class="reference internal" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.flow_from_directory" title="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.flow_from_directory"><code class="xref py py-meth docutils literal notranslate"><span class="pre">flow_from_directory()</span></code></a> called which lists each classes’ samples in the specified directory</p></li>
<li><p>The return value of <a class="reference internal" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.flow_from_directory" title="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.flow_from_directory"><code class="xref py py-meth docutils literal notranslate"><span class="pre">flow_from_directory()</span></code></a> is a ‘generator’ which should be given to a model fit() method</p></li>
<li><dl class="simple">
<dt>During fitting, batches of samples are concurrently processed using the following sequence:</dt><dd><p>a0. If get_batch_function() is given, then call this function an skip the rest of these steps
a. Read sample raw audio file
b. If supplied, call noaug_preprocessing_function()
c. Generate random transform parameters based on parameters from step 1)
d. Trim silence from raw audio sample based on <code class="docutils literal notranslate"><span class="pre">trim_threshold_db</span></code>
e. Pad zeros before and after trimmed audio based on <code class="docutils literal notranslate"><span class="pre">sample_length_seconds</span></code> and <code class="docutils literal notranslate"><span class="pre">offset_range</span></code>
f. Augment padded audio based on randomly generated transform parameters from part c)
g. If supplied, call preprocessing_function()
h. If <code class="docutils literal notranslate"><span class="pre">frontend_enabled=True</span></code>, pass augmented audio through <a class="reference internal" href="audio_feature_generator.html#mltk.core.preprocess.audio.audio_feature_generator.AudioFeatureGenerator" title="mltk.core.preprocess.audio.audio_feature_generator.AudioFeatureGenerator"><code class="xref py py-class docutils literal notranslate"><span class="pre">mltk.core.preprocess.audio.audio_feature_generator.AudioFeatureGenerator</span></code></a> and return spectrogram as 2D array
i. If supplied, call postprocessing_function()
j. If <code class="docutils literal notranslate"><span class="pre">frontend_enabled=True</span></code>, normalize based on <code class="docutils literal notranslate"><span class="pre">samplewise_center</span></code>, <code class="docutils literal notranslate"><span class="pre">samplewise_std_normalization</span></code>, and <code class="docutils literal notranslate"><span class="pre">rescale</span></code></p>
</dd>
</dl>
</li>
</ol>
<p class="rubric">Notes</p>
<ul class="simple">
<li><p>If <code class="docutils literal notranslate"><span class="pre">_unknown_</span></code> is added as a class to <a class="reference internal" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.flow_from_directory" title="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.flow_from_directory"><code class="xref py py-meth docutils literal notranslate"><span class="pre">flow_from_directory()</span></code></a>, then the generator will automatically
add an ‘unknown’ class to the generated batches.
Unused classes in the dataset directory will be randomly selected and used as an ‘unknown’ class.
The other augmentation parameters will be applied to the ‘unknown’ samples.
Use the <code class="docutils literal notranslate"><span class="pre">unknown_class_percentage</span></code> setting to control the size of this class.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">_silence_</span></code> is added as a class to <a class="reference internal" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.flow_from_directory" title="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.flow_from_directory"><code class="xref py py-meth docutils literal notranslate"><span class="pre">flow_from_directory()</span></code></a>, then the generator will automatically
add ‘silence’ samples is all zeros with the background noise augmentations added.
Use the <code class="docutils literal notranslate"><span class="pre">silence_class_percentage</span></code> setting to control the size of this class.</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cores</strong> – The number of CPU cores to use for spawned audio processing batch processes.
This number can be either an integer, which specifies the exact number
of CPU cores, or it can be a float &lt; 1.0. The float is the percentage
of CPU cores to use for processing.
A large number of CPU cores will consume more system memory.</p></li>
<li><p><strong>debug</strong> – If true then use the Python threading library instead of multiprocessing
This is useful for debugging as it allows for single-stepping in the generator threads
and callback functions</p></li>
<li><p><strong>max_batches_pending</strong> – This is the number of processed batches to queue.
A larger number can improving training times at the expense of
increased system memory usage.</p></li>
<li><p><strong>get_batch_function</strong> – <p>function that should return the transformed batch.
If this is omitted, then iterator.get_batches_of_transformed_samples() is used
This function should have the following signature:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_batches_of_transformed_samples</span><span class="p">(</span>
   <span class="n">batch_index</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span>
   <span class="n">filenames</span><span class="p">:</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
   <span class="n">classes</span><span class="p">:</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
   <span class="n">params</span><span class="p">:</span><span class="n">ParallelProcessParams</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]:</span>
    <span class="o">...</span>
    <span class="k">return</span> <span class="n">batch_index</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_y</span><span class="p">)</span>
</pre></div>
</div>
</p></li>
<li><p><strong>noaug_preprocessing_function</strong> – <p>function that will be applied on each input.
The function will run before any augmentation is done on the audio sample.
The ‘x’ argument is of the shape [sample_length] and is a float32 scaled between (-1,1).
See <a class="reference external" href="https://librosa.org/doc/main/generated/librosa.load.html">https://librosa.org/doc/main/generated/librosa.load.html</a>
The function should take at least two arguments:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">my_processing_func</span><span class="p">(</span>
    <span class="n">params</span><span class="p">:</span> <span class="n">ParallelProcessParams</span><span class="p">,</span>
    <span class="n">x</span> <span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">class_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">filename</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">batch_index</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">batch_class_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span>
    <span class="n">batch_filenames</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span>
 <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="o">...</span>
    <span class="k">return</span> <span class="n">processed_x</span>
</pre></div>
</div>
</p></li>
<li><p><strong>preprocessing_function</strong> – <p>function that will be applied on each input.
The function will run after the audio is augmented but before it does through the AudioFeatureGenerator (if enabled).
The ‘x’ argument is of the shape [sample_length] and is a float32 scaled between [-1,1].
See <a class="reference external" href="https://librosa.org/doc/main/generated/librosa.load.html">librosa.load()</a>
The function should take at least two arguments, and return the processed sample:.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">my_processing_func</span><span class="p">(</span>
    <span class="n">params</span><span class="p">:</span> <span class="n">ParallelProcessParams</span><span class="p">,</span>
    <span class="n">x</span> <span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">class_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">filename</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">batch_index</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">batch_class_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span>
    <span class="n">batch_filenames</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span>
 <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="o">...</span>
    <span class="k">return</span> <span class="n">processed_x</span>
</pre></div>
</div>
</p></li>
<li><p><strong>postprocessing_function</strong> – <p>function that will be applied on each input.
The function will run after the audio is passed through the AudioFeatureGenerator (if enabled).
So the ‘x’ argument is a spectrogram of the shape: [height, width, 1].
The function should take at least two arguments and return the processed sample [height, width, 1]:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">my_processing_func</span><span class="p">(</span>
    <span class="n">params</span><span class="p">:</span> <span class="n">ParallelProcessParams</span><span class="p">,</span>
    <span class="n">x</span> <span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">class_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">filename</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">batch_index</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">batch_class_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span>
    <span class="n">batch_filenames</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span>
 <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="o">...</span>
    <span class="k">return</span> <span class="n">processed_x</span>
</pre></div>
</div>
</p></li>
<li><p><strong>samplewise_center</strong> – Center each sample’s processed data about its norm</p></li>
<li><p><strong>samplewise_std_normalization</strong> – Divide processed sample data by its STD</p></li>
<li><p><strong>samplewise_normalize_range</strong> – Normalize the input by the values in this range
For instance, if samplewise_normalize_range=(0,1), then each input will be scaled to values between 0 and 1
Note that this normalization is applied after all other enabled normalizations</p></li>
<li><p><strong>rescale</strong> – Divide processed sample data by value</p></li>
<li><p><strong>validation_split</strong> – Percentage of sample data to use for validation</p></li>
<li><p><strong>validation_augmentation_enabled</strong> – If True, then augmentations will be applied to
validation data. If False, then no augmentations will be applied to validation data.</p></li>
<li><p><strong>dtype</strong> – Output data type for the x samples
Default: float32</p></li>
<li><p><strong>frontend_dtype</strong> – <p>Output data format of the audio frontend. If omitted then default to the <code class="docutils literal notranslate"><span class="pre">dtype</span></code> argument.
This is only used if <code class="docutils literal notranslate"><span class="pre">frontend_enabled=True</span></code>.</p>
<ul>
<li><p><strong>uint16:*</strong> This the raw value generated by the internal AudioFeatureGenerator library</p></li>
<li><p><strong>float32:</strong> This is the uint16 value directly casted to a float32</p></li>
<li><p><strong>int8:*</strong> This is the int8 value generated by the TFLM “micro features” library.</p></li>
</ul>
<p>Refer to <a class="reference internal" href="audio_feature_generator.html#mltk.core.preprocess.audio.audio_feature_generator.AudioFeatureGenerator" title="mltk.core.preprocess.audio.audio_feature_generator.AudioFeatureGenerator"><code class="xref py py-class docutils literal notranslate"><span class="pre">mltk.core.preprocess.audio.audio_feature_generator.AudioFeatureGenerator</span></code></a> for more details.</p>
</p></li>
<li><p><strong>trim_threshold_db</strong> – Use to trim silence from samples; the threshold (in decibels) below reference to consider as silence</p></li>
<li><p><strong>noise_colors</strong> – <p>List of noise colors to randomly add to samples, possible options:</p>
<ul>
<li><p>[‘white’, ‘brown’, ‘blue’, ‘pink’, ‘violet’]</p></li>
<li><p>OR ‘all’ to use all</p></li>
<li><p>OR ‘none’ to use none</p></li>
</ul>
</p></li>
<li><p><strong>noise_color_range</strong> – Tuple (min, max) for randomly selecting noise color’s loudness, 0.0 no noise, 1.0 100% noise</p></li>
<li><p><strong>speed_range</strong> – Tuple (min, max) for randomly augmenting audio’s speed, &lt; 1.0 slow down, &gt; 1.0 speed up</p></li>
<li><p><strong>pitch_range</strong> – Tuple (min, max) for randomly augmenting audio’s pitch, &lt; 0 lower pitch, &gt; 0 higher pitch
This can either be an integer or float. An integer represents the number of semitone steps.
A float is converted to semitone steps &lt;float&gt;*12, so for example, a range of (-.5,.5) is converted to (-6,6)</p></li>
<li><p><strong>vtlp_range</strong> – Tuple (min, max) for randomly augmenting audio’s vocal tract length perturbation</p></li>
<li><p><strong>loudness_range</strong> – Tuple (min, max) for randomly augmenting audio’s volume, &lt; 1.0 decrease loudness, &gt; 1.0 increase loudness</p></li>
<li><p><strong>bg_noise_range</strong> – Tuple (min, max) for randomly selecting background noise’s loudness, &lt; 1.0 decrease loudness, &gt; 1.0 increase loudness</p></li>
<li><p><strong>bg_noise_dir</strong> – Path to directory containing background noise audio files. A bg noise file will be randomly selected and cropped then applied to samples.
.. note:: If noise_colors is also supplied then either a bg_noise or noise_color will randomly be applied to each sample</p></li>
<li><p><strong>offset_range</strong> – <p>Tuple (min, max) for randomly selecting the offset of where to pad a sample to @ref sample_length_seconds.
For instance, if offset_range=(0.0, 1.0), then</p>
<ul>
<li><p>trimmed_audio     = trim(raw_audio, trim_threshold_db) # Trim silence</p></li>
<li><p>required_padding  = (sample_length_seconds * sample_rate) - len(trimmed_audio)</p></li>
<li><p>pad_upto_index    = required_padding * random.uniform(offset_range[0], offset_range[1])</p></li>
<li><p>padded_audio      = concat(zeros * pad_upto_index, trimmed_audio, zeros * (required_padding - pad_upto_index))</p></li>
</ul>
</p></li>
<li><p><strong>unknown_class_percentage</strong> – If an <code class="docutils literal notranslate"><span class="pre">_unknown_</span></code> class is added to the class list, then ‘unknown’ class samples will automatically
be added to batches. This specifies the percentage of of samples to generate relative the smallest number
of samples of other classes. For instance, if another class has 1000 samples and unknown_class_percentage=0.8,
then the number of ‘unknown’ class samples generated will be 800.</p></li>
<li><p><strong>silence_class_percentage</strong> – If a <code class="docutils literal notranslate"><span class="pre">_silence_</span></code> class is added to the class list, then ‘silence’ class samples will automatically
be added to batches. This specifies the percentage of of samples to generate relative the smallest number
of samples of other classes. For instance, if another class has 1000 samples and silence_class_percentage=0.8,
then the number of ‘silence’ class samples generated will be 800.</p></li>
<li><p><strong>disable_random_transforms</strong> – Disable random data augmentations</p></li>
<li><p><strong>frontend</strong> – AudioFeatureGenerator settings, see <code class="xref py py-class docutils literal notranslate"><span class="pre">mltk.core.preprocess.audio.audio_feature_generator.AudioFeatureGeneratorettings</span></code> for more details</p></li>
<li><p><strong>frontend_enabled</strong> – By default, the frontend is enabled. After augmenting audio sample, pass it through the AudioFeatureGenerator and
return the generated spectrogram.
If disabled, after augmenting audio sample, return the 1D sample. In this case it is recommended to use the <code class="docutils literal notranslate"><span class="pre">postprocessing_function</span></code>
callback to convert the samples to the required shape and data type.
NOTE: You must also specify the <code class="docutils literal notranslate"><span class="pre">sample_shape</span></code> parameter if <code class="docutils literal notranslate"><span class="pre">frontend_enabled=False</span></code></p></li>
<li><p><strong>sample_shape</strong> – The shape of the generated sample. This is only used/required if <code class="docutils literal notranslate"><span class="pre">frontend_enabled=False</span></code></p></li>
<li><p><strong>disable_gpu_in_subprocesses</strong> – Disable GPU usage in spawned subprocesses, default: true</p></li>
<li><p><strong>add_channel_dimension</strong> – If true and <code class="docutils literal notranslate"><span class="pre">frontend_enabled=True</span></code>, then automatically convert
generated sample shape from [height, width] to [height, width, 1].
If false, then generated sample shape is [height, width].</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Properties</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.default_transform" title="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.default_transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">default_transform</span></code></a></p></td>
<td><p>Retrun the default augmentations transform settings</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.sample_length" title="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.sample_length"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sample_length</span></code></a></p></td>
<td><p>Return the length of the audio sample as the number of individual ADC samples</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.sample_length_ms" title="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.sample_length_ms"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sample_length_ms</span></code></a></p></td>
<td><p>Return the AudioFeatureGeneratorSettings.sample_length_ms value</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.sample_rate_hz" title="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.sample_rate_hz"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sample_rate_hz</span></code></a></p></td>
<td><p>Return the AudioFeatureGeneratorSettings.sample_rate_hz value</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.sample_shape" title="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.sample_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sample_shape</span></code></a></p></td>
<td><p>The shape of the sample as a tuple</p></td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.__init__" title="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.__init__"><code class="xref py py-obj docutils literal notranslate"><span class="pre">__init__</span></code></a></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.adjust_length" title="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.adjust_length"><code class="xref py py-obj docutils literal notranslate"><span class="pre">adjust_length</span></code></a></p></td>
<td><p>Adjust the audio sample length to fit the sample_length_seconds parameter This will pad with zeros or crop the input sample as necessary</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.apply_frontend" title="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.apply_frontend"><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply_frontend</span></code></a></p></td>
<td><p>Send the audio sample through the AudioFeatureGenerator and return the generated spectrogram</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.apply_transform" title="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.apply_transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply_transform</span></code></a></p></td>
<td><p>Apply the given transform parameters to the input audio sample</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.flow_from_directory" title="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.flow_from_directory"><code class="xref py py-obj docutils literal notranslate"><span class="pre">flow_from_directory</span></code></a></p></td>
<td><p>Create the ParallelAudioGenerator with the given dataset directory</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.get_random_transform" title="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.get_random_transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_random_transform</span></code></a></p></td>
<td><p>Generate random augmentation settings based on the configeration parameters</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.standardize" title="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.standardize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">standardize</span></code></a></p></td>
<td><p>Applies the normalization configuration in-place to a batch of inputs.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cores</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.25</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_batches_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">get_batch_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noaug_preprocessing_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preprocessing_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">postprocessing_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">samplewise_center</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">samplewise_std_normalization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">samplewise_normalize_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rescale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validation_split</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validation_augmentation_enabled</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'float32'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frontend_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trim_threshold_db</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_colors</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_color_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">speed_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pitch_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vtlp_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loudness_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bg_noise_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bg_noise_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offset_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unknown_class_percentage</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">silence_class_percentage</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disable_random_transforms</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frontend_settings</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frontend_enabled</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disable_gpu_in_subprocesses</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_channel_dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mltk/core/preprocess/audio/parallel_generator/parallel_generator.html#ParallelAudioDataGenerator.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>frontend_settings</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="audio_feature_generator_settings.html#mltk.core.preprocess.audio.audio_feature_generator.AudioFeatureGeneratorSettings" title="mltk.core.preprocess.audio.audio_feature_generator.audio_feature_generator_settings.AudioFeatureGeneratorSettings"><em>AudioFeatureGeneratorSettings</em></a><em>]</em>) – </p>
</dd>
</dl>
</dd></dl>
<dl class="py property">
<dt class="sig sig-object py" id="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.sample_shape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">sample_shape</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">tuple</span></em><a class="headerlink" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.sample_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>The shape of the sample as a tuple</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py property">
<dt class="sig sig-object py" id="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.sample_length">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">sample_length</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.sample_length" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the length of the audio sample as the number of individual ADC samples</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py property">
<dt class="sig sig-object py" id="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.sample_length_ms">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">sample_length_ms</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.sample_length_ms" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the AudioFeatureGeneratorSettings.sample_length_ms value</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py property">
<dt class="sig sig-object py" id="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.sample_rate_hz">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">sample_rate_hz</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.sample_rate_hz" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the AudioFeatureGeneratorSettings.sample_rate_hz value</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.flow_from_directory">
<span class="sig-name descname"><span class="pre">flow_from_directory</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">directory</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'categorical'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle_index_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">follow_links</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_samples_per_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">list_valid_filenames_in_directory_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_counts</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mltk/core/preprocess/audio/parallel_generator/parallel_generator.html#ParallelAudioDataGenerator.flow_from_directory"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.flow_from_directory" title="Permalink to this definition">¶</a></dt>
<dd><p>Create the ParallelAudioGenerator with the given dataset directory</p>
<p>Takes the path to a directory &amp; generates batches of augmented data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>directory</strong> – string, path to the target directory. It should contain one subdirectory per class.
Any PNG, JPG, BMP, PPM or TIF images inside each of the subdirectories directory tree will be included in the generator.</p></li>
<li><p><strong>classes</strong> – <p>Required, list of class subdirectories (e.g. [‘dogs’, ‘cats’])</p>
<ul>
<li><p>If <code class="docutils literal notranslate"><span class="pre">_unknown_</span></code> is added as a class then the generator will automatically add an ‘unknown’ class to the generated batches.
Unused classes in the dataset directory will be randomly selected and used as an ‘unknown’ class.
The other augmentation parameters will be applied to the ‘unknown’ samples.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">_silence_</span></code> is added as a class then the generator will automatically add ‘silence’ samples with all zeros
with the background noise augmentations added.</p></li>
</ul>
</p></li>
<li><p><strong>class_mode</strong> – <p>One of “categorical”, “binary”, “sparse”, “input”, or None.
Default: “categorical”. Determines the type of label arrays that are returned:</p>
<ul>
<li><p><strong>categorical</strong> will be 2D one-hot encoded labels,</p></li>
<li><p><strong>binary</strong> will be 1D binary labels, “sparse” will be 1D integer labels,</p></li>
<li><p><strong>input</strong> will be images identical to input images (mainly used to work with autoencoders).</p></li>
<li><p><strong>None</strong> no labels are returned (the generator will only yield batches of image data, which is useful to use with model.predict()).</p></li>
</ul>
<p>Please note that in case of class_mode None, the data still needs to reside in a subdirectory of directory for it to work correctly.</p>
</p></li>
<li><p><strong>batch_size</strong> – Size of the batches of data (default: 32).</p></li>
<li><p><strong>shuffle</strong> – Whether to shuffle the data (default: True) If set to False, sorts the data in alphanumeric order.</p></li>
<li><p><strong>shuffle_index_dir</strong> – If given, the dataset directory will be shuffled the first time it is processed and
and an index file containing the shuffled file names is generated at the directory specified
by <code class="docutils literal notranslate"><span class="pre">shuffle_index_dir</span></code>. The index file is reused to maintain the shuffled order for subsequent processing.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, then the dataset samples are sorted alphabetically and saved to an index file in the dataset directory.
The alphabetical index file is used for subsequent processing.
Default: <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>seed</strong> – Optional random seed for shuffling and transformations.</p></li>
<li><p><strong>follow_links</strong> – Whether to follow symlinks inside class subdirectories (default: False).</p></li>
<li><p><strong>subset</strong> – Subset of data (“training” or “validation”) if validation_split is set in ParallelAudioDataGenerator.</p></li>
<li><p><strong>max_samples_per_class</strong> – The maximum number of samples to use for a given class. If <code class="docutils literal notranslate"><span class="pre">-1</span></code> then use all available samples.</p></li>
<li><p><strong>list_valid_filenames_in_directory_function</strong> – <p>This is a custom function called for each class,
that should return a list of valid file names for the given class.
It has the following function signature:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">list_valid_filenames_in_directory</span><span class="p">(</span>
        <span class="n">base_directory</span><span class="p">:</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">search_class</span><span class="p">:</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">white_list_formats</span><span class="p">:</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">split</span><span class="p">:</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span><span class="nb">float</span><span class="p">],</span>
        <span class="n">follow_links</span><span class="p">:</span><span class="nb">bool</span><span class="p">,</span>
        <span class="n">shuffle_index_directory</span><span class="p">:</span><span class="nb">str</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span>
    <span class="o">...</span>
    <span class="k">return</span> <span class="n">search_class</span><span class="p">,</span> <span class="n">filenames</span>
</pre></div>
</div>
</p></li>
<li><p><strong>class_counts</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>int</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A DirectoryIterator yielding tuples of (x, y) where x is a numpy array containing a batch of images with
shape (batch_size, target_size, channels) and y is a numpy array of corresponding labels.</p>
</dd>
</dl>
</dd></dl>
<dl class="py property">
<dt class="sig sig-object py" id="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.default_transform">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">default_transform</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">dict</span></em><a class="headerlink" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.default_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrun the default augmentations transform settings</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.get_random_transform">
<span class="sig-name descname"><span class="pre">get_random_transform</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mltk/core/preprocess/audio/parallel_generator/parallel_generator.html#ParallelAudioDataGenerator.get_random_transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.get_random_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate random augmentation settings based on the configeration parameters</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.adjust_length">
<span class="sig-name descname"><span class="pre">adjust_length</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">orignal_sr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">whole_sample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mltk/core/preprocess/audio/parallel_generator/parallel_generator.html#ParallelAudioDataGenerator.adjust_length"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.adjust_length" title="Permalink to this definition">¶</a></dt>
<dd><p>Adjust the audio sample length to fit the sample_length_seconds parameter
This will pad with zeros or crop the input sample as necessary</p>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.apply_transform">
<span class="sig-name descname"><span class="pre">apply_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">orignal_sr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">whole_sample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mltk/core/preprocess/audio/parallel_generator/parallel_generator.html#ParallelAudioDataGenerator.apply_transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.apply_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply the given transform parameters to the input audio sample</p>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.apply_frontend">
<span class="sig-name descname"><span class="pre">apply_frontend</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype=&lt;class</span> <span class="pre">'numpy.float32'&gt;</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mltk/core/preprocess/audio/parallel_generator/parallel_generator.html#ParallelAudioDataGenerator.apply_frontend"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.apply_frontend" title="Permalink to this definition">¶</a></dt>
<dd><p>Send the audio sample through the AudioFeatureGenerator and return the generated spectrogram</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.standardize">
<span class="sig-name descname"><span class="pre">standardize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mltk/core/preprocess/audio/parallel_generator/parallel_generator.html#ParallelAudioDataGenerator.standardize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.standardize" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the normalization configuration in-place to a batch of inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sample</strong> – Input sample to normalize</p></li>
<li><p><strong>rescale</strong> – <code class="docutils literal notranslate"><span class="pre">sample</span> <span class="pre">*=</span> <span class="pre">rescale</span></code></p></li>
<li><p><strong>samplewise_center</strong> – <code class="docutils literal notranslate"><span class="pre">sample</span> <span class="pre">-=</span> <span class="pre">np.mean(sample,</span> <span class="pre">keepdims=True)</span></code></p></li>
<li><p><strong>samplewise_std_normalization</strong> – <code class="docutils literal notranslate"><span class="pre">sample</span> <span class="pre">/=</span> <span class="pre">(np.std(sample,</span> <span class="pre">keepdims=True)</span> <span class="pre">+</span> <span class="pre">1e-6)</span></code></p></li>
<li><p><strong>samplewise_normalize_range</strong> – <code class="docutils literal notranslate"><span class="pre">sample</span> <span class="pre">=</span> <span class="pre">diff</span> <span class="pre">*</span> <span class="pre">(sample</span> <span class="pre">-</span> <span class="pre">np.min(sample))</span> <span class="pre">/</span> <span class="pre">np.ptp(sample)</span> <span class="pre">+</span> <span class="pre">lower</span></code></p></li>
<li><p><strong>dtype</strong> – The output dtype, if not dtype if given then sample is converted to float32</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The normalized value of sample</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</section>


          </article>
        </div>
      </div>
      <a href="#" class="go-top"><i class="md-icon">arrow_upward</i>Back to Top</a>
    </main>
  </div>
  <footer class="md-footer">
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
          
            <a href="image_data_generator_params.html" title="ParallelProcessParams"
               class="md-flex md-footer-nav__link md-footer-nav__link--prev"
               rel="prev">
              <div class="md-flex__cell md-flex__cell--shrink">
                <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
              </div>
              <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
                <span class="md-flex__ellipsis">
                  <span
                      class="md-footer-nav__direction"> Previous </span> ParallelProcessParams </span>
              </div>
            </a>
          
          
            <a href="audio_data_generator_params.html" title="ParallelProcessParams"
               class="md-flex md-footer-nav__link md-footer-nav__link--next"
               rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title"><span
                class="md-flex__ellipsis"> <span
                class="md-footer-nav__direction"> Next </span> ParallelProcessParams </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink"><i
                class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          
        </a>
        
      </nav>
    </div>
    <div class="md-footer-meta md-typeset">
      <div class="md-footer-meta__inner md-grid">
        <div class="md-footer-copyright">
          <div class="md-footer-copyright__highlight">
              &#169; Copyright 2023, Silicon Labs.
              
          </div>
            Last updated on
              Mar 30, 2023.
            <br/>
            Created using
            <a href="http://www.sphinx-doc.org/">Sphinx</a> 5.3.0.
             and
            <a href="https://github.com/bashtage/sphinx-material/">Material for
              Sphinx</a>
        </div>
        <button id="survey-link" class="feedback-button">Feedback</button>
      </div>
    </div>
  </footer>
  <div class="privacy-banner">
    <div class="privacy-banner-wrapper">
      <p>
        <b>Important:</b> We use cookies only for functional and traffic analytics. <br />
        We DO NOT use cookies for any marketing purposes. By using our site you acknowledge you have read and understood our <a class="privacy-policy" href="https://www.silabs.com/about-us/legal/cookie-policy" target="_blank">Cookie Policy</a>.
      </p>
      <a class="privacy-banner-accept" href="#">Got it</a>
    </div>
</div>
  
<div class="survey-container" id="dlg-survey"> 
    <div class="close" id="dlg-survey-close"><i class="md-icon">close</i></div>
    <div class="msg">Please click the <b>submit</b> button at the end even if you do not answer all of the questions</div>
    <iframe id="iframe-survey" style="width: 100%; height: 100%;"></iframe>
</div>
  
  <script src="../../../_static/javascripts/application.js"></script>
  <script>app.initialize({version: "1.0.4", url: {base: ".."}})</script>
  </body>
</html>