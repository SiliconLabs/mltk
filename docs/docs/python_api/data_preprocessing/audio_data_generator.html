
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width,initial-scale=1">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="title" content="Machine Learning Toolkit">
<meta name="description" content="A Python package with command-line utilities and scripts to aid the development of machine learning models for Silicon Lab's embedded platforms">
<meta name="keywords" content="machine learning, machine-learning, machinelearning, ml, ai, iot, Internet of things, aiot, tinyml, tensorflow, tensorflow-lite, tensorflow-lite-micro, keras-tensorflow, keras, tflite, embedded, embedded-systems, mcu, Microcontrollers, hardware, python, c++, cmake, keras, numpy, silabs, silicon labs">
<meta name="robots" content="index, follow">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="language" content="English">
<meta name="author" content="Silicon Labs">
  <meta name="lang:clipboard.copy" content="Copy to clipboard">
  <meta name="lang:clipboard.copied" content="Copied to clipboard">
  <meta name="lang:search.language" content="en">
  <meta name="lang:search.pipeline.stopwords" content="True">
  <meta name="lang:search.pipeline.trimmer" content="True">
  <meta name="lang:search.result.none" content="No matching documents">
  <meta name="lang:search.result.one" content="1 matching document">
  <meta name="lang:search.result.other" content="# matching documents">
  <meta name="lang:search.tokenizer" content="[\s\-]+">

  
    <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&display=fallback" rel="stylesheet">

    <style>
      body,
      input {
        font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif
      }

      code,
      kbd,
      pre {
        font-family: "Roboto Mono", "Courier New", Courier, monospace
      }
    </style>
  

  <link rel="stylesheet" href="../../../_static/stylesheets/application.css"/>
  <link rel="stylesheet" href="../../../_static/stylesheets/application-palette.css"/>
  <link rel="stylesheet" href="../../../_static/stylesheets/application-fixes.css"/>
  
  <link rel="stylesheet" href="../../../_static/fonts/material-icons.css"/>
  
  <meta name="theme-color" content="#3f51b5">
  <script src="../../../_static/javascripts/modernizr.js"></script>
  
<script async src="https://www.googletagmanager.com/gtag/js?id=G-HZ5MW943WF"></script>
<script>
    window.gTrackingId = 'G-HZ5MW943WF';
</script>
<meta name="google-site-verification" content="dsSsmnE2twOnfSAQk5zBBTrjMArsTJj809Bp-8mVlIw" />
  
  
    <title>Audio Data Generator &#8212; MLTK 0.10.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/material.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-variables.63bdf2d2865d068e5434884f20825da9.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/custom.css" />
    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/js/custom.js"></script>
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="AudioFeatureGenerator" href="audio_feature_generator.html" />
    <link rel="prev" title="Image Data Generator" href="image_data_generator.html" />
  
   

  </head>
  <body dir=ltr
        data-md-color-primary=red data-md-color-accent=light-blue>
  
  <svg class="md-svg">
    <defs data-children-count="0">
      
      <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
      
    </defs>
  </svg>
  
  <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer">
  <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search">
  <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
  <a href="#docs/python_api/data_preprocessing/audio_data_generator" tabindex="1" class="md-skip"> Skip to content </a>
  <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex navheader">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../../../index.html" title="MLTK 0.10.0 documentation"
           class="md-header-nav__button md-logo">
          
              <img src="../../../_static/logo.png"
                   alt="MLTK 0.10.0 documentation logo">
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          <span class="md-header-nav__topic">Machine Learning Toolkit</span>
          <span class="md-header-nav__topic"> Audio Data Generator </span>
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
        
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" action="../../../search.html" method="get" name="search">
      <input type="text" class="md-search__input" name="q" placeholder="Search"
             autocapitalize="off" autocomplete="off" spellcheck="false"
             data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>

      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            <a href="https://github.com/siliconlabs/mltk" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    MLTK Github Repository
  </div>
</a>
          </div>
        </div>
      
      
    </div>
  </nav>
</header>

  
  <div class="md-container">
    
    
    
  <nav class="md-tabs" data-md-component="tabs">
    <div class="md-tabs__inner md-grid">
      <ul class="md-tabs__list">
            
            <li class="md-tabs__item"><a href="https://docs.silabs.com/gecko-platform/latest/machine-learning/tensorflow/overview" class="md-tabs__link">Gecko SDK Documentation</a></li>
            
            <li class="md-tabs__item"><a href="https://github.com/tensorflow/tflite-micro" class="md-tabs__link">Tensorflow-Lite Micro Repository</a></li>
            
            <li class="md-tabs__item"><a href="https://www.tensorflow.org/learn" class="md-tabs__link">Tensorflow Documentation</a></li>
          <li class="md-tabs__item"><a href="../index.html" class="md-tabs__link">API Reference</a></li>
          <li class="md-tabs__item"><a href="index.html" class="md-tabs__link">Data Preprocessing</a></li>
      </ul>
    </div>
  </nav>
    <main class="md-main">
      <div class="md-main__inner md-grid" data-md-component="container">
        
          <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../../../index.html" title="MLTK 0.10.0 documentation" class="md-nav__button md-logo">
      
        <img src="../../../_static/logo.png" alt=" logo" width="48" height="48">
      
    </a>
    <a href="../../../index.html"
       title="MLTK 0.10.0 documentation">Machine Learning Toolkit</a>
  </label>
    <div class="md-nav__source">
      <a href="https://github.com/siliconlabs/mltk" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    MLTK Github Repository
  </div>
</a>
    </div>
  
  

  
  <ul class="md-nav__list">
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Basics</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../overview.html" class="md-nav__link">Overview</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../why_mltk.html" class="md-nav__link">Why MLTK?</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../installation.html" class="md-nav__link">Installation</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../command_line.html" class="md-nav__link">Command-Line</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../guides/index.html" class="md-nav__link">Modeling Guides</a>
      
    
    </li>
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Usage</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../tutorials.html" class="md-nav__link">Tutorials</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../examples.html" class="md-nav__link">API Examples</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../index.html" class="md-nav__link">API Reference</a>
      <ul class="md-nav__list"> 
    <li class="md-nav__item">
    
    
      <a href="../operations.html" class="md-nav__link">Model Operations</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../core/types.html" class="md-nav__link">Model Object Types</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../core/utilities.html" class="md-nav__link">Model Utilities</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../core/dictionary.fbs.html" class="md-nav__link">TfliteModelParameters Flatbuffer Schema</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="index.html" class="md-nav__link">Data Preprocessing</a>
      
    
    </li></ul>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../models/index.html" class="md-nav__link">Reference Models</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../datasets/index.html" class="md-nav__link">Reference Datasets</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../cpp_development/index.html" class="md-nav__link">C++ Development</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../cpp_development/examples/index.html" class="md-nav__link">C++ Examples</a>
      
    
    </li>
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Audio Related</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../audio/keyword_spotting_overview.html" class="md-nav__link">Keyword Spotting Overview</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../audio/audio_feature_generator.html" class="md-nav__link">Audio Feature Generator</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../audio/audio_utilities.html" class="md-nav__link">Audio Utilities</a>
      
    
    </li>
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Other Information</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../faq/index.html" class="md-nav__link">Frequently Asked Questions</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../other/quick_reference.html" class="md-nav__link">Quick Reference</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../other/supported_hardware.html" class="md-nav__link">Supported Hardware</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../guides/notebook_examples_guide.html" class="md-nav__link">Notebook Examples Guide</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../other/settings_file.html" class="md-nav__link">Settings File</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../other/environment_variables.html" class="md-nav__link">Environment Variables</a>
      
    
    </li>
  </ul>
  

</nav>
              </div>
            </div>
          </div>
          <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                
<nav class="md-nav md-nav--secondary">
    <label class="md-nav__title" for="__toc">Contents</label>
  <ul class="md-nav__list" data-md-scrollfix="">
        <li class="md-nav__item"><a href="#docs-python-api-data-preprocessing-audio-data-generator--page-root" class="md-nav__link">Audio Data Generator</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#parallelprocessparams" class="md-nav__link">ParallelProcessParams</a>
        </li></ul>
            </nav>
        </li>
    
<li class="md-nav__item"><a class="md-nav__extra_link" href="../../../_sources/docs/python_api/data_preprocessing/audio_data_generator.md.txt">Show Source</a> </li>

<li id="searchbox" class="md-nav__item"></li>

  </ul>
</nav>
              </div>
            </div>
          </div>
        
        <div class="md-content">

          
          <div class="breadcrumbs md-typeset">
            <ul class="breadcrumb">
              <li></li>
              <li><a href="../../../index.html"><i class="md-icon">home</i></a></li>
                <li class="active"><a href="../index.html" >API Reference</a></li>
                <li class="active"><a href="index.html" accesskey="U">Data Preprocessing</a></li>
            </ul>
          </div>
          

          <article class="md-content__inner md-typeset" role="main">
            
  <section id="audio-data-generator">
<h1 id="docs-python-api-data-preprocessing-audio-data-generator--page-root">Audio Data Generator<a class="headerlink" href="#docs-python-api-data-preprocessing-audio-data-generator--page-root" title="Permalink to this headline">¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mltk.core.preprocess.audio.parallel_generator.</span></span><span class="sig-name descname"><span class="pre">ParallelAudioDataGenerator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cores</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.25</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_batches_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">get_batch_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noaug_preprocessing_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preprocessing_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">postprocessing_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">samplewise_center</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">samplewise_std_normalization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">samplewise_normalize_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rescale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validation_split</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validation_augmentation_enabled</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'float32'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frontend_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trim_threshold_db</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_colors</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_color_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">speed_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pitch_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vtlp_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loudness_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bg_noise_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bg_noise_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offset_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unknown_class_percentage</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">silence_class_percentage</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disable_random_transforms</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frontend_settings</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frontend_enabled</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disable_gpu_in_subprocesses</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_channel_dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mltk/core/preprocess/audio/parallel_generator/parallel_generator.html#ParallelAudioDataGenerator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Parallel Audio Data Generator</p>
<p>This class as a similar functionality to the <a class="reference external" href="https://keras.io/preprocessing/image">Keras ImageDataGenerator</a></p>
<p>Except, instead of processing image files it processes audio files.</p>
<p>Additionally, batch samples are asynchronously processed using the Python
‘multiprocessing’ package. This allows for efficient use of multi-core systems
as future batch samples can be concurrently processed while processed batches may be
used for training.</p>
<p>This class works as follows:</p>
<ol class="arabic simple">
<li><p>Class instantiated with parameters (see below)</p></li>
<li><p><a class="reference internal" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.flow_from_directory" title="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.flow_from_directory"><code class="xref py py-meth docutils literal notranslate"><span class="pre">flow_from_directory()</span></code></a> called which lists each classes’ samples in the specified directory</p></li>
<li><p>The return value of <a class="reference internal" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.flow_from_directory" title="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.flow_from_directory"><code class="xref py py-meth docutils literal notranslate"><span class="pre">flow_from_directory()</span></code></a> is a ‘generator’ which should be given to a model fit() method</p></li>
<li><dl class="simple">
<dt>During fitting, batches of samples are concurrently processed using the following sequence:</dt><dd><p>a0. If get_batch_function() is given, then call this function an skip the rest of these steps
a. Read sample raw audio file
b. If supplied, call noaug_preprocessing_function()
c. Generate random transform parameters based on parameters from step 1)
d. Trim silence from raw audio sample based on <code class="docutils literal notranslate"><span class="pre">trim_threshold_db</span></code>
e. Pad zeros before and after trimmed audio based on <code class="docutils literal notranslate"><span class="pre">sample_length_seconds</span></code> and <code class="docutils literal notranslate"><span class="pre">offset_range</span></code>
f. Augment padded audio based on randomly generated transform parameters from part c)
g. If supplied, call preprocessing_function()
h. If <code class="docutils literal notranslate"><span class="pre">frontend_enabled=True</span></code>, pass augmented audio through <a class="reference internal" href="audio_feature_generator.html#mltk.core.preprocess.audio.audio_feature_generator.AudioFeatureGenerator" title="mltk.core.preprocess.audio.audio_feature_generator.AudioFeatureGenerator"><code class="xref py py-class docutils literal notranslate"><span class="pre">mltk.core.preprocess.audio.audio_feature_generator.AudioFeatureGenerator</span></code></a> and return spectrogram as 2D array
i. If supplied, call postprocessing_function()
j. If <code class="docutils literal notranslate"><span class="pre">frontend_enabled=True</span></code>, normalize based on <code class="docutils literal notranslate"><span class="pre">samplewise_center</span></code>, <code class="docutils literal notranslate"><span class="pre">samplewise_std_normalization</span></code>, and <code class="docutils literal notranslate"><span class="pre">rescale</span></code></p>
</dd>
</dl>
</li>
</ol>
<p class="rubric">Notes</p>
<ul class="simple">
<li><p>If <code class="docutils literal notranslate"><span class="pre">_unknown_</span></code> is added as a class to <a class="reference internal" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.flow_from_directory" title="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.flow_from_directory"><code class="xref py py-meth docutils literal notranslate"><span class="pre">flow_from_directory()</span></code></a>, then the generator will automatically
add an ‘unknown’ class to the generated batches.
Unused classes in the dataset directory will be randomly selected and used as an ‘unknown’ class.
The other augmentation parameters will be applied to the ‘unknown’ samples.
Use the <code class="docutils literal notranslate"><span class="pre">unknown_class_percentage</span></code> setting to control the size of this class.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">_silence_</span></code> is added as a class to <a class="reference internal" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.flow_from_directory" title="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.flow_from_directory"><code class="xref py py-meth docutils literal notranslate"><span class="pre">flow_from_directory()</span></code></a>, then the generator will automatically
add ‘silence’ samples is all zeros with the background noise augmentations added.
Use the <code class="docutils literal notranslate"><span class="pre">silence_class_percentage</span></code> setting to control the size of this class.</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cores</strong> – The number of CPU cores to use for spawned audio processing batch processes.
This number can be either an integer, which specifies the exact number
of CPU cores, or it can be a float &lt; 1.0. The float is the percentage
of CPU cores to use for processing.
A large number of CPU cores will consume more system memory.</p></li>
<li><p><strong>debug</strong> – If true then use the Python threading library instead of multiprocessing
This is useful for debugging as it allows for single-stepping in the generator threads
and callback functions</p></li>
<li><p><strong>max_batches_pending</strong> – This is the number of processed batches to queue.
A larger number can improving training times at the expense of
increased system memory usage.</p></li>
<li><p><strong>get_batch_function</strong> – <p>function that should return the transformed batch.
If this is omitted, then iterator.get_batches_of_transformed_samples() is used
This function should have the following signature:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_batches_of_transformed_samples</span><span class="p">(</span>
   <span class="n">batch_index</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span>
   <span class="n">filenames</span><span class="p">:</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
   <span class="n">classes</span><span class="p">:</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
   <span class="n">params</span><span class="p">:</span><span class="n">ParallelProcessParams</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]:</span>
    <span class="o">...</span>
    <span class="k">return</span> <span class="n">batch_index</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_y</span><span class="p">)</span>
</pre></div>
</div>
</p></li>
<li><p><strong>noaug_preprocessing_function</strong> – <p>function that will be applied on each input.
The function will run before any augmentation is done on the audio sample.
The ‘x’ argument is of the shape [sample_length] and is a float32 scaled between (-1,1).
See <a class="reference external" href="https://librosa.org/doc/main/generated/librosa.load.html">https://librosa.org/doc/main/generated/librosa.load.html</a>
The function should take at least two arguments:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">my_processing_func</span><span class="p">(</span>
    <span class="n">params</span><span class="p">:</span> <span class="n">ParallelProcessParams</span><span class="p">,</span>
    <span class="n">x</span> <span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">class_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">filename</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">batch_index</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">batch_class_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span>
    <span class="n">batch_filenames</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span>
 <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="o">...</span>
    <span class="k">return</span> <span class="n">processed_x</span>
</pre></div>
</div>
</p></li>
<li><p><strong>preprocessing_function</strong> – <p>function that will be applied on each input.
The function will run after the audio is augmented but before it does through the AudioFeatureGenerator (if enabled).
The ‘x’ argument is of the shape [sample_length] and is a float32 scaled between [-1,1].
See <a class="reference external" href="https://librosa.org/doc/main/generated/librosa.load.html">librosa.load()</a>
The function should take at least two arguments, and return the processed sample:.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">my_processing_func</span><span class="p">(</span>
    <span class="n">params</span><span class="p">:</span> <span class="n">ParallelProcessParams</span><span class="p">,</span>
    <span class="n">x</span> <span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">class_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">filename</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">batch_index</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">batch_class_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span>
    <span class="n">batch_filenames</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span>
 <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="o">...</span>
    <span class="k">return</span> <span class="n">processed_x</span>
</pre></div>
</div>
</p></li>
<li><p><strong>postprocessing_function</strong> – <p>function that will be applied on each input.
The function will run after the audio is passed through the AudioFeatureGenerator (if enabled).
So the ‘x’ argument is a spectrogram of the shape: [height, width, 1].
The function should take at least two arguments and return the processed sample [height, width, 1]:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">my_processing_func</span><span class="p">(</span>
    <span class="n">params</span><span class="p">:</span> <span class="n">ParallelProcessParams</span><span class="p">,</span>
    <span class="n">x</span> <span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">class_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">filename</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">batch_index</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">batch_class_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span>
    <span class="n">batch_filenames</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span>
 <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="o">...</span>
    <span class="k">return</span> <span class="n">processed_x</span>
</pre></div>
</div>
</p></li>
<li><p><strong>samplewise_center</strong> – Center each sample’s processed data about its norm</p></li>
<li><p><strong>samplewise_std_normalization</strong> – Divide processed sample data by its STD</p></li>
<li><p><strong>samplewise_normalize_range</strong> – Normalize the input by the values in this range
For instance, if samplewise_normalize_range=(0,1), then each input will be scaled to values between 0 and 1
Note that this normalization is applied after all other enabled normalizations</p></li>
<li><p><strong>rescale</strong> – Divide processed sample data by value</p></li>
<li><p><strong>validation_split</strong> – Percentage of sample data to use for validation</p></li>
<li><p><strong>validation_augmentation_enabled</strong> – If True, then augmentations will be applied to
validation data. If False, then no augmentations will be applied to validation data.</p></li>
<li><p><strong>dtype</strong> – Output data type for the x samples
Default: float32</p></li>
<li><p><strong>frontend_dtype</strong> – <p>Output data format of the audio frontend. If omitted then default to the <code class="docutils literal notranslate"><span class="pre">dtype</span></code> argument.
This is only used if <code class="docutils literal notranslate"><span class="pre">frontend_enabled=True</span></code>.</p>
<ul>
<li><p><strong>uint16:*</strong> This the raw value generated by the internal AudioFeatureGenerator library</p></li>
<li><p><strong>float32:</strong> This is the uint16 value directly casted to a float32</p></li>
<li><p><strong>int8:*</strong> This is the int8 value generated by the TFLM “micro features” library.</p></li>
</ul>
<p>Refer to <a class="reference internal" href="audio_feature_generator.html#mltk.core.preprocess.audio.audio_feature_generator.AudioFeatureGenerator" title="mltk.core.preprocess.audio.audio_feature_generator.AudioFeatureGenerator"><code class="xref py py-class docutils literal notranslate"><span class="pre">mltk.core.preprocess.audio.audio_feature_generator.AudioFeatureGenerator</span></code></a> for more details.</p>
</p></li>
<li><p><strong>trim_threshold_db</strong> – Use to trim silence from samples; the threshold (in decibels) below reference to consider as silence</p></li>
<li><p><strong>noise_colors</strong> – <p>List of noise colors to randomly add to samples, possible options:</p>
<ul>
<li><p>[‘white’, ‘brown’, ‘blue’, ‘pink’, ‘violet’]</p></li>
<li><p>OR ‘all’ to use all</p></li>
<li><p>OR ‘none’ to use none</p></li>
</ul>
</p></li>
<li><p><strong>noise_color_range</strong> – Tuple (min, max) for randomly selecting noise color’s loudness, 0.0 no noise, 1.0 100% noise</p></li>
<li><p><strong>speed_range</strong> – Tuple (min, max) for randomly augmenting audio’s speed, &lt; 1.0 slow down, &gt; 1.0 speed up</p></li>
<li><p><strong>pitch_range</strong> – Tuple (min, max) for randomly augmenting audio’s pitch, &lt; 0 lower pitch, &gt; 0 higher pitch
This can either be an integer or float. An integer represents the number of semitone steps.
A float is converted to semitone steps &lt;float&gt;*12, so for example, a range of (-.5,.5) is converted to (-6,6)</p></li>
<li><p><strong>vtlp_range</strong> – Tuple (min, max) for randomly augmenting audio’s vocal tract length perturbation</p></li>
<li><p><strong>loudness_range</strong> – Tuple (min, max) for randomly augmenting audio’s volume, &lt; 1.0 decrease loudness, &gt; 1.0 increase loudness</p></li>
<li><p><strong>bg_noise_range</strong> – Tuple (min, max) for randomly selecting background noise’s loudness, &lt; 1.0 decrease loudness, &gt; 1.0 increase loudness</p></li>
<li><p><strong>bg_noise_dir</strong> – Path to directory containing background noise audio files. A bg noise file will be randomly selected and cropped then applied to samples.
.. note:: If noise_colors is also supplied then either a bg_noise or noise_color will randomly be applied to each sample</p></li>
<li><p><strong>offset_range</strong> – <p>Tuple (min, max) for randomly selecting the offset of where to pad a sample to @ref sample_length_seconds.
For instance, if offset_range=(0.0, 1.0), then</p>
<ul>
<li><p>trimmed_audio     = trim(raw_audio, trim_threshold_db) # Trim silence</p></li>
<li><p>required_padding  = (sample_length_seconds * sample_rate) - len(trimmed_audio)</p></li>
<li><p>pad_upto_index    = required_padding * random.uniform(offset_range[0], offset_range[1])</p></li>
<li><p>padded_audio      = concat(zeros * pad_upto_index, trimmed_audio, zeros * (required_padding - pad_upto_index))</p></li>
</ul>
</p></li>
<li><p><strong>unknown_class_percentage</strong> – If an <code class="docutils literal notranslate"><span class="pre">_unknown_</span></code> class is added to the class list, then ‘unknown’ class samples will automatically
be added to batches. This specifies the percentage of of samples to generate relative the smallest number
of samples of other classes. For instance, if another class has 1000 samples and unknown_class_percentage=0.8,
then the number of ‘unknown’ class samples generated will be 800.</p></li>
<li><p><strong>silence_class_percentage</strong> – If a <code class="docutils literal notranslate"><span class="pre">_silence_</span></code> class is added to the class list, then ‘silence’ class samples will automatically
be added to batches. This specifies the percentage of of samples to generate relative the smallest number
of samples of other classes. For instance, if another class has 1000 samples and silence_class_percentage=0.8,
then the number of ‘silence’ class samples generated will be 800.</p></li>
<li><p><strong>disable_random_transforms</strong> – Disable random data augmentations</p></li>
<li><p><strong>frontend</strong> – AudioFeatureGenerator settings, see <code class="xref py py-class docutils literal notranslate"><span class="pre">mltk.core.preprocess.audio.audio_feature_generator.AudioFeatureGeneratorettings</span></code> for more details</p></li>
<li><p><strong>frontend_enabled</strong> – By default, the frontend is enabled. After augmenting audio sample, pass it through the AudioFeatureGenerator and
return the generated spectrogram.
If disabled, after augmenting audio sample, return the 1D sample. In this case it is recommended to use the <code class="docutils literal notranslate"><span class="pre">postprocessing_function</span></code>
callback to convert the samples to the required shape and data type.
NOTE: You must also specify the <code class="docutils literal notranslate"><span class="pre">sample_shape</span></code> parameter if <code class="docutils literal notranslate"><span class="pre">frontend_enabled=False</span></code></p></li>
<li><p><strong>sample_shape</strong> – The shape of the generated sample. This is only used/required if <code class="docutils literal notranslate"><span class="pre">frontend_enabled=False</span></code></p></li>
<li><p><strong>disable_gpu_in_subprocesses</strong> – Disable GPU usage in spawned subprocesses, default: true</p></li>
<li><p><strong>add_channel_dimension</strong> – If true and <code class="docutils literal notranslate"><span class="pre">frontend_enabled=True</span></code>, then automatically convert
generated sample shape from [height, width] to [height, width, 1].
If false, then generated sample shape is [height, width].</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.sample_length">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">sample_length</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.sample_length" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the length of the audio sample as the number of individual ADC samples</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py property">
<dt class="sig sig-object py" id="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.sample_length_ms">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">sample_length_ms</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.sample_length_ms" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the AudioFeatureGeneratorSettings.sample_length_ms value</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py property">
<dt class="sig sig-object py" id="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.sample_rate_hz">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">sample_rate_hz</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.sample_rate_hz" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the AudioFeatureGeneratorSettings.sample_rate_hz value</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.flow_from_directory">
<span class="sig-name descname"><span class="pre">flow_from_directory</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">directory</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'categorical'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle_index_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">follow_links</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_samples_per_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">list_valid_filenames_in_directory_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mltk/core/preprocess/audio/parallel_generator/parallel_generator.html#ParallelAudioDataGenerator.flow_from_directory"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.flow_from_directory" title="Permalink to this definition">¶</a></dt>
<dd><p>Create the ParallelAudioGenerator with the given dataset directory</p>
<p>Takes the path to a directory &amp; generates batches of augmented data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>directory</strong> – string, path to the target directory. It should contain one subdirectory per class.
Any PNG, JPG, BMP, PPM or TIF images inside each of the subdirectories directory tree will be included in the generator.</p></li>
<li><p><strong>classes</strong> – <p>Required, list of class subdirectories (e.g. [‘dogs’, ‘cats’])</p>
<ul>
<li><p>If <code class="docutils literal notranslate"><span class="pre">_unknown_</span></code> is added as a class then the generator will automatically add an ‘unknown’ class to the generated batches.
Unused classes in the dataset directory will be randomly selected and used as an ‘unknown’ class.
The other augmentation parameters will be applied to the ‘unknown’ samples.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">_silence_</span></code> is added as a class then the generator will automatically add ‘silence’ samples with all zeros
with the background noise augmentations added.</p></li>
</ul>
</p></li>
<li><p><strong>class_mode</strong> – <p>One of “categorical”, “binary”, “sparse”, “input”, or None.
Default: “categorical”. Determines the type of label arrays that are returned:</p>
<ul>
<li><p><strong>categorical</strong> will be 2D one-hot encoded labels,</p></li>
<li><p><strong>binary</strong> will be 1D binary labels, “sparse” will be 1D integer labels,</p></li>
<li><p><strong>input</strong> will be images identical to input images (mainly used to work with autoencoders).</p></li>
<li><p><strong>None</strong> no labels are returned (the generator will only yield batches of image data, which is useful to use with model.predict()).</p></li>
</ul>
<p>Please note that in case of class_mode None, the data still needs to reside in a subdirectory of directory for it to work correctly.</p>
</p></li>
<li><p><strong>batch_size</strong> – Size of the batches of data (default: 32).</p></li>
<li><p><strong>shuffle</strong> – Whether to shuffle the data (default: True) If set to False, sorts the data in alphanumeric order.</p></li>
<li><p><strong>shuffle_index_dir</strong> – If given, the dataset directory will be shuffled the first time it is processed and
and an index file containing the shuffled file names is generated at the directory specified
by <code class="docutils literal notranslate"><span class="pre">shuffle_index_dir</span></code>. The index file is reused to maintain the shuffled order for subsequent processing.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, then the dataset samples are sorted alphabetically and saved to an index file in the dataset directory.
The alphabetical index file is used for subsequent processing.
Default: <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>seed</strong> – Optional random seed for shuffling and transformations.</p></li>
<li><p><strong>follow_links</strong> – Whether to follow symlinks inside class subdirectories (default: False).</p></li>
<li><p><strong>subset</strong> – Subset of data (“training” or “validation”) if validation_split is set in ParallelAudioDataGenerator.</p></li>
<li><p><strong>max_samples_per_class</strong> – The maximum number of samples to use for a given class. If <code class="docutils literal notranslate"><span class="pre">-1</span></code> then use all available samples.</p></li>
<li><p><strong>list_valid_filenames_in_directory_function</strong> – <p>This is a custom function called for each class,
that should return a list of valid file names for the given class.
It has the following function signature:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">list_valid_filenames_in_directory</span><span class="p">(</span>
        <span class="n">base_directory</span><span class="p">:</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">search_class</span><span class="p">:</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">white_list_formats</span><span class="p">:</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">split</span><span class="p">:</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">follow_links</span><span class="p">:</span><span class="nb">bool</span><span class="p">,</span>
        <span class="n">shuffle_index_directory</span><span class="p">:</span><span class="nb">str</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span>
    <span class="o">...</span>
    <span class="k">return</span> <span class="n">search_class</span><span class="p">,</span> <span class="n">filenames</span>
</pre></div>
</div>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A DirectoryIterator yielding tuples of (x, y) where x is a numpy array containing a batch of images with
shape (batch_size, <a href="#id1"><span class="problematic" id="id2">*</span></a>target_size, channels) and y is a numpy array of corresponding labels.</p>
</dd>
</dl>
</dd></dl>
<dl class="py property">
<dt class="sig sig-object py" id="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.default_transform">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">default_transform</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">dict</span></em><a class="headerlink" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.default_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrun the default augmentations transform settings</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.get_random_transform">
<span class="sig-name descname"><span class="pre">get_random_transform</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mltk/core/preprocess/audio/parallel_generator/parallel_generator.html#ParallelAudioDataGenerator.get_random_transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.get_random_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate random augmentation settings based on the configeration parameters</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.adjust_length">
<span class="sig-name descname"><span class="pre">adjust_length</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">orignal_sr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">whole_sample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mltk/core/preprocess/audio/parallel_generator/parallel_generator.html#ParallelAudioDataGenerator.adjust_length"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.adjust_length" title="Permalink to this definition">¶</a></dt>
<dd><p>Adjust the audio sample length to fit the sample_length_seconds parameter
This will pad with zeros or crop the input sample as necessary</p>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.apply_transform">
<span class="sig-name descname"><span class="pre">apply_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">orignal_sr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">whole_sample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mltk/core/preprocess/audio/parallel_generator/parallel_generator.html#ParallelAudioDataGenerator.apply_transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.apply_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply the given transform parameters to the input audio sample</p>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.apply_frontend">
<span class="sig-name descname"><span class="pre">apply_frontend</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype=&lt;class</span> <span class="pre">'numpy.float32'&gt;</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mltk/core/preprocess/audio/parallel_generator/parallel_generator.html#ParallelAudioDataGenerator.apply_frontend"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.apply_frontend" title="Permalink to this definition">¶</a></dt>
<dd><p>Send the audio sample through the AudioFeatureGenerator and return the generated spectrogram</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.standardize">
<span class="sig-name descname"><span class="pre">standardize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mltk/core/preprocess/audio/parallel_generator/parallel_generator.html#ParallelAudioDataGenerator.standardize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.standardize" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the normalization configuration in-place to a batch of inputs.</p>
<p><code class="docutils literal notranslate"><span class="pre">x</span></code> is changed in-place since the function is mainly used internally
to standarize images and feed them to your network. If a copy of <code class="docutils literal notranslate"><span class="pre">x</span></code>
would be created instead it would have a significant performance cost.
If you want to apply this method without changing the input in-place
you can call the method creating a copy before:</p>
<p>standarize(np.copy(x))</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.x">
<span class="sig-name descname"><span class="pre">x</span></span><a class="headerlink" href="#mltk.core.preprocess.audio.parallel_generator.ParallelAudioDataGenerator.x" title="Permalink to this definition">¶</a></dt>
<dd><p>Batch of inputs to be normalized.</p>
</dd></dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The inputs, normalized.</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<section id="parallelprocessparams">
<h2 id="parallelprocessparams">ParallelProcessParams<a class="headerlink" href="#parallelprocessparams" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="mltk.core.preprocess.audio.parallel_generator.ParallelProcessParams">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mltk.core.preprocess.audio.parallel_generator.</span></span><span class="sig-name descname"><span class="pre">ParallelProcessParams</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">audio_data_generator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_rate</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_length_ms</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_to_dir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_prefix</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_format</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frontend_dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">directory</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_mode</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">get_batch_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noaug_preprocessing_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preprocessing_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">postprocessing_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frontend_enabled</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_channel_dimension</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mltk/core/preprocess/audio/parallel_generator/iterator.html#ParallelProcessParams"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mltk.core.preprocess.audio.parallel_generator.ParallelProcessParams" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds methods related to getting batches from filenames</p>
<p>It includes the logic to transform image files to batches.</p>
</dd></dl>
</section>
</section>


          </article>
        </div>
      </div>
    </main>
  </div>
  <footer class="md-footer">
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
          
            <a href="image_data_generator.html" title="Image Data Generator"
               class="md-flex md-footer-nav__link md-footer-nav__link--prev"
               rel="prev">
              <div class="md-flex__cell md-flex__cell--shrink">
                <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
              </div>
              <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
                <span class="md-flex__ellipsis">
                  <span
                      class="md-footer-nav__direction"> Previous </span> Image Data Generator </span>
              </div>
            </a>
          
          
            <a href="audio_feature_generator.html" title="AudioFeatureGenerator"
               class="md-flex md-footer-nav__link md-footer-nav__link--next"
               rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title"><span
                class="md-flex__ellipsis"> <span
                class="md-footer-nav__direction"> Next </span> AudioFeatureGenerator </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink"><i
                class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          
        </a>
        
      </nav>
    </div>
    <div class="md-footer-meta md-typeset">
      <div class="md-footer-meta__inner md-grid">
        <div class="md-footer-copyright">
          <div class="md-footer-copyright__highlight">
              &#169; Copyright 2022, Silicon Labs.
              
          </div>
            Last updated on
              Aug 22, 2022.
            <br/>
            Created using
            <a href="http://www.sphinx-doc.org/">Sphinx</a> 4.5.0.
             and
            <a href="https://github.com/bashtage/sphinx-material/">Material for
              Sphinx</a>
        </div>
        <div class="survey-link" id="dlg-survey-link"> 
    <div>We need your feedback!</div>
    <div>
        Please take this short <a id="survey-link">survey<i class="md-icon pulse">chevron_right</i></a>
    </div>
</div>
      </div>
    </div>
  </footer>
  <div class="privacy-banner">
    <div class="privacy-banner-wrapper">
      <p>
        <b>Important:</b> This site uses cookies to improve user experience and stores information on your computer. 
        By continuing to use our site, you consent to our <a class="privacy-policy" href="https://www.silabs.com/about-us/legal/cookie-policy" target="_blank">Cookie Policy</a>. 
        If you do not want to enable cookies, review our policy and learn how they can be disabled. Note that disabling cookies will disable some features of the site.
      </p>
      <a class="privacy-banner-accept" href="#">Accept</a>
    </div>
</div>
  
<div class="survey-container" id="dlg-survey"> 
    <div class="close" id="dlg-survey-close"><i class="md-icon">close</i></div>
    <iframe id="iframe-survey" style="width: 100%; height: 100%;"></iframe>
</div>
  
  <script src="../../../_static/javascripts/application.js"></script>
  <script>app.initialize({version: "1.0.4", url: {base: ".."}})</script>
  </body>
</html>