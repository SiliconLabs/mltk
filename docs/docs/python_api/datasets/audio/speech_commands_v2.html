
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width,initial-scale=1">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="title" content="Machine Learning Toolkit">
<meta name="description" content="A Python package with command-line utilities and scripts to aid the development of machine learning models for Silicon Lab's embedded platforms">
<meta name="keywords" content="machine learning, machine-learning, machinelearning, ml, ai, iot, Internet of things, aiot, tinyml, tensorflow, tensorflow-lite, tensorflow-lite-micro, keras-tensorflow, keras, tflite, embedded, embedded-systems, mcu, Microcontrollers, hardware, python, c++, cmake, keras, numpy, silabs, silicon labs">
<meta name="robots" content="index, follow">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="language" content="English">
<meta name="author" content="Silicon Labs">
  <meta name="lang:clipboard.copy" content="Copy to clipboard">
  <meta name="lang:clipboard.copied" content="Copied to clipboard">
  <meta name="lang:search.language" content="en">
  <meta name="lang:search.pipeline.stopwords" content="True">
  <meta name="lang:search.pipeline.trimmer" content="True">
  <meta name="lang:search.result.none" content="No matching documents">
  <meta name="lang:search.result.one" content="1 matching document">
  <meta name="lang:search.result.other" content="# matching documents">
  <meta name="lang:search.tokenizer" content="[\s\-]+">

  
    <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&display=fallback" rel="stylesheet">

    <style>
      body,
      input {
        font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif
      }

      code,
      kbd,
      pre {
        font-family: "Roboto Mono", "Courier New", Courier, monospace
      }
    </style>
  

  <link rel="stylesheet" href="../../../../_static/stylesheets/application.css"/>
  <link rel="stylesheet" href="../../../../_static/stylesheets/application-palette.css"/>
  <link rel="stylesheet" href="../../../../_static/stylesheets/application-fixes.css"/>
  
  <link rel="stylesheet" href="../../../../_static/fonts/material-icons.css"/>
  
  <meta name="theme-color" content="#3f51b5">
  <script src="../../../../_static/javascripts/modernizr.js"></script>
  
<script async src="https://www.googletagmanager.com/gtag/js?id=G-HZ5MW943WF"></script>
<script>
    window.gTrackingId = 'G-HZ5MW943WF';
</script>
<meta name="google-site-verification" content="dsSsmnE2twOnfSAQk5zBBTrjMArsTJj809Bp-8mVlIw" />
  
  
    <title>mltk.datasets.audio.speech_commands.speech_commands_v2 &#8212; MLTK 0.17.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/material.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/css/custom.css" />
    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/sphinx_highlight.js"></script>
    <script src="../../../../_static/clipboard.min.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script src="../../../../_static/design-tabs.js"></script>
    <script src="../../../../_static/js/custom.js"></script>
    <script src="../../../../_static/js/apitoc.js"></script>
    <link rel="shortcut icon" href="../../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="mltk.datasets.audio.direction_commands" href="direction_commands.html" />
    <link rel="prev" title="Reference Datasets" href="../index.html" />
  
   

  </head>
  <body dir=ltr
        data-md-color-primary=red data-md-color-accent=light-blue>
  
  <svg class="md-svg">
    <defs data-children-count="0">
      
      <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
      
    </defs>
  </svg>
  
  <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer">
  <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search">
  <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
  <a href="#docs/python_api/datasets/audio/speech_commands_v2" tabindex="1" class="md-skip"> Skip to content </a>
  <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex navheader">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../../../../index.html" title="MLTK 0.17.0 documentation"
           class="md-header-nav__button md-logo">
          
              <img src="../../../../_static/logo.png"
                   alt="MLTK 0.17.0 documentation logo">
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          <span class="md-header-nav__topic">Machine Learning Toolkit</span>
          <span class="md-header-nav__topic"> mltk.datasets.audio.speech_commands.speech_commands_v2 </span>
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
        
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" action="../../../../search.html" method="get" name="search">
      <input type="text" class="md-search__input" name="q" placeholder=""Search""
             autocapitalize="off" autocomplete="off" spellcheck="false"
             data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>

      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            <a href="https://github.com/siliconlabs/mltk" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    MLTK Github Repository
  </div>
</a>
          </div>
        </div>
      
      
    </div>
  </nav>
</header>

  
  <div class="md-container">
    
    
    
  <nav class="md-tabs" data-md-component="tabs">
    <div class="md-tabs__inner md-grid">
      <ul class="md-tabs__list">
            
            <li class="md-tabs__item"><a href="https://docs.silabs.com/gecko-platform/latest/machine-learning/tensorflow/overview" class="md-tabs__link">Gecko SDK Documentation</a></li>
            
            <li class="md-tabs__item"><a href="https://github.com/tensorflow/tflite-micro" class="md-tabs__link">Tensorflow-Lite Micro Repository</a></li>
            
            <li class="md-tabs__item"><a href="https://www.tensorflow.org/learn" class="md-tabs__link">Tensorflow Documentation</a></li>
          <li class="md-tabs__item"><a href="../index.html" class="md-tabs__link">Reference Datasets</a></li>
      </ul>
    </div>
  </nav>
    <main class="md-main">
      <div class="md-main__inner md-grid" data-md-component="container">
        
          <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../../../../index.html" title="MLTK 0.17.0 documentation" class="md-nav__button md-logo">
      
        <img src="../../../../_static/logo.png" alt=" logo" width="48" height="48">
      
    </a>
    <a href="../../../../index.html"
       title="MLTK 0.17.0 documentation">Machine Learning Toolkit</a>
  </label>
    <div class="md-nav__source">
      <a href="https://github.com/siliconlabs/mltk" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    MLTK Github Repository
  </div>
</a>
    </div>
  
  

  
  <ul class="md-nav__list">
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Basics</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../overview.html" class="md-nav__link">Overview</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../why_mltk.html" class="md-nav__link">Why MLTK?</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../installation.html" class="md-nav__link">Installation</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../command_line/index.html" class="md-nav__link">Command-Line</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../guides/index.html" class="md-nav__link">Modeling Guides</a>
      
    
    </li>
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Usage</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../tutorials.html" class="md-nav__link">Tutorials</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../examples.html" class="md-nav__link">API Examples</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../index.html" class="md-nav__link">API Reference</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../models/index.html" class="md-nav__link">Reference Models</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../index.html" class="md-nav__link">Reference Datasets</a>
      <ul class="md-nav__list"> 
    <li class="md-nav__item">
    
    
      <a href="../index.html#audio-datasets" class="md-nav__link">Audio Datasets</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../index.html#image-datasets" class="md-nav__link">Image Datasets</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../index.html#accelerometer-datasets" class="md-nav__link">Accelerometer Datasets</a>
      
    
    </li></ul>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../cpp_development/index.html" class="md-nav__link">C++ Development</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../cpp_development/examples/index.html" class="md-nav__link">C++ Examples</a>
      
    
    </li>
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Audio Related</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../audio/keyword_spotting_overview.html" class="md-nav__link">Keyword Spotting Overview</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../audio/audio_feature_generator.html" class="md-nav__link">Audio Feature Generator</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../audio/audio_utilities.html" class="md-nav__link">Audio Utilities</a>
      
    
    </li>
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Other Information</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../faq/index.html" class="md-nav__link">Frequently Asked Questions</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../other/quick_reference.html" class="md-nav__link">Quick Reference</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../other/supported_hardware.html" class="md-nav__link">Supported Hardware</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../guides/notebook_examples_guide.html" class="md-nav__link">Notebook Examples Guide</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../other/settings_file.html" class="md-nav__link">Settings File</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../other/environment_variables.html" class="md-nav__link">Environment Variables</a>
      
    
    </li>
  </ul>
  

</nav>
              </div>
            </div>
          </div>
          <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                
<nav class="md-nav md-nav--secondary">
    <label class="md-nav__title" for="__toc">Contents</label>
  <ul class="md-nav__list" data-md-scrollfix="" id="localtoc">
        <li class="md-nav__item"><a href="#docs-python-api-datasets-audio-speech-commands-v2--page-root" class="md-nav__link">mltk.datasets.audio.speech_commands.speech_commands_v2</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#google-speech-commands-v2" class="md-nav__link">Google Speech Commands v2</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#history" class="md-nav__link">History</a>
        </li>
        <li class="md-nav__item"><a href="#collection" class="md-nav__link">Collection</a>
        </li>
        <li class="md-nav__item"><a href="#organization" class="md-nav__link">Organization</a>
        </li>
        <li class="md-nav__item"><a href="#processing" class="md-nav__link">Processing</a>
        </li>
        <li class="md-nav__item"><a href="#background-noise" class="md-nav__link">Background Noise</a>
        </li>
        <li class="md-nav__item"><a href="#citations" class="md-nav__link">Citations</a>
        </li>
        <li class="md-nav__item"><a href="#credits" class="md-nav__link">Credits</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#mltk.datasets.audio.speech_commands.speech_commands_v2.DOWNLOAD_URL" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">DOWNLOAD_URL</span></code></a>
        </li>
        <li class="md-nav__item"><a href="#mltk.datasets.audio.speech_commands.speech_commands_v2.VERIFY_SHA1" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">VERIFY_SHA1</span></code></a>
        </li>
        <li class="md-nav__item"><a href="#mltk.datasets.audio.speech_commands.speech_commands_v2.CLASSES" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">CLASSES</span></code></a>
        </li>
        <li class="md-nav__item"><a href="#mltk.datasets.audio.speech_commands.speech_commands_v2.load_data" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">load_data()</span></code></a>
        </li>
        <li class="md-nav__item"><a href="#mltk.datasets.audio.speech_commands.speech_commands_v2.load_clean_data" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">load_clean_data()</span></code></a>
        </li>
        <li class="md-nav__item"><a href="#mltk.datasets.audio.speech_commands.speech_commands_v2.list_valid_filenames_in_directory" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">list_valid_filenames_in_directory()</span></code></a>
        </li></ul>
            </nav>
        </li>
      <script type="text/javascript" src=../../../../_static/js/apitoc.js></script>
  </ul>
</nav>
              </div>
            </div>
          </div>
        
        <div class="md-content">

          
          <div class="breadcrumbs md-typeset">
            <ul class="breadcrumb">
              <li></li>
              <li><a href="../../../../index.html"><i class="md-icon">home</i></a></li>
                <li><a href="../index.html" accesskey="U">Reference Datasets</a></li>

              <li class="activate"><a>mltk.datasets.audio.speech_commands.speech_commands_v2</a></li>
            </ul>
          </div>
          

          <article class="md-content__inner md-typeset" role="main">
            
  <section id="module-mltk.datasets.audio.speech_commands.speech_commands_v2">
<span id="mltk-datasets-audio-speech-commands-speech-commands-v2"></span><h1 id="docs-python-api-datasets-audio-speech-commands-v2--page-root">mltk.datasets.audio.speech_commands.speech_commands_v2<a class="headerlink" href="#docs-python-api-datasets-audio-speech-commands-v2--page-root" title="Permalink to this heading">¶</a></h1>
<section id="google-speech-commands-v2">
<h2 id="google-speech-commands-v2">Google Speech Commands v2<a class="headerlink" href="#google-speech-commands-v2" title="Permalink to this heading">¶</a></h2>
<p><a class="reference external" href="https://www.tensorflow.org/datasets/catalog/speech_commands">https://www.tensorflow.org/datasets/catalog/speech_commands</a></p>
<p>This is a set of one-second .wav audio files, each containing a single spoken
English word. These words are from a small set of commands, and are spoken by a
variety of different speakers. The audio files are organized into folders based
on the word they contain, and this data set is designed to help train simple
machine learning models. This dataset is covered in more detail at
<a class="reference external" href="https://arxiv.org/abs/1804.03209">https://arxiv.org/abs/1804.03209</a>.</p>
<p>It’s licensed under the <a class="reference external" href="https://creativecommons.org/licenses/by/4.0/">Creative Commons BY 4.0
license</a>. See the LICENSE
file in this folder for full details. Its original location was at
<a class="reference external" href="http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz">http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz</a>.</p>
<section id="history">
<h3 id="history">History<a class="headerlink" href="#history" title="Permalink to this heading">¶</a></h3>
<p>Version 0.01 of the data set was released on August 3rd 2017 and contained
64,727 audio files.</p>
<p>This is version 0.02 of the data set containing 105,829 audio files, released on
April 11th 2018.</p>
</section>
<section id="collection">
<h3 id="collection">Collection<a class="headerlink" href="#collection" title="Permalink to this heading">¶</a></h3>
<p>The audio files were collected using crowdsourcing, see
<a class="reference external" href="https://github.com/petewarden/extract_loudest_section">aiyprojects.withgoogle.com/open_speech_recording</a>
for some of the open source audio collection code we used (and please consider
contributing to enlarge this data set). The goal was to gather examples of
people speaking single-word commands, rather than conversational sentences, so
they were prompted for individual words over the course of a five minute
session. Twenty core command words were recorded, with most speakers saying each
of them five times. The core words are “Yes”, “No”, “Up”, “Down”, “Left”,
“Right”, “On”, “Off”, “Stop”, “Go”, “Zero”, “One”, “Two”, “Three”, “Four”,
“Five”, “Six”, “Seven”, “Eight”, and “Nine”. To help distinguish unrecognized
words, there are also ten auxiliary words, which most speakers only said once.
These include “Bed”, “Bird”, “Cat”, “Dog”, “Happy”, “House”, “Marvin”, “Sheila”,
“Tree”, and “Wow”.</p>
</section>
<section id="organization">
<h3 id="organization">Organization<a class="headerlink" href="#organization" title="Permalink to this heading">¶</a></h3>
<p>The files are organized into folders, with each directory name labelling the
word that is spoken in all the contained audio files. No details were kept of
any of the participants age, gender, or location, and random ids were assigned
to each individual. These ids are stable though, and encoded in each file name
as the first part before the underscore. If a participant contributed multiple
utterances of the same word, these are distinguished by the number at the end of
the file name. For example, the file path <cite>happy/3cfc6b3a_nohash_2.wav</cite>
indicates that the word spoken was “happy”, the speaker’s id was “3cfc6b3a”, and
this is the third utterance of that word by this speaker in the data set. The
‘nohash’ section is to ensure that all the utterances by a single speaker are
sorted into the same training partition, to keep very similar repetitions from
giving unrealistically optimistic evaluation scores.</p>
</section>
<section id="processing">
<h3 id="processing">Processing<a class="headerlink" href="#processing" title="Permalink to this heading">¶</a></h3>
<p>The original audio files were collected in uncontrolled locations by people
around the world. We requested that they do the recording in a closed room for
privacy reasons, but didn’t stipulate any quality requirements. This was by
design, since we wanted examples of the sort of speech data that we’re likely to
encounter in consumer and robotics applications, where we don’t have much
control over the recording equipment or environment. The data was captured in a
variety of formats, for example Ogg Vorbis encoding for the web app, and then
converted to a 16-bit little-endian PCM-encoded WAVE file at a 16000 sample
rate. The audio was then trimmed to a one second length to align most
utterances, using the
<a class="reference external" href="https://github.com/petewarden/extract_loudest_section">extract_loudest_section</a>
tool. The audio files were then screened for silence or incorrect words, and
arranged into folders by label.</p>
</section>
<section id="background-noise">
<h3 id="background-noise">Background Noise<a class="headerlink" href="#background-noise" title="Permalink to this heading">¶</a></h3>
<p>To help train networks to cope with noisy environments, it can be helpful to mix
in realistic background audio. The <cite>_background_noise_</cite> folder contains a set of
longer audio clips that are either recordings or mathematical simulations of
noise. For more details, see the <cite>_background_noise_/README.md</cite>.</p>
</section>
<section id="citations">
<h3 id="citations">Citations<a class="headerlink" href="#citations" title="Permalink to this heading">¶</a></h3>
<p>If you use the Speech Commands dataset in your work, please cite it as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@article</span><span class="p">{</span><span class="n">speechcommandsv2</span><span class="p">,</span>
  <span class="n">author</span> <span class="o">=</span> <span class="p">{{</span><span class="n">Warden</span><span class="p">},</span> <span class="n">P</span><span class="o">.</span><span class="p">},</span>
    <span class="n">title</span> <span class="o">=</span> <span class="s2">"{Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition}"</span><span class="p">,</span>
  <span class="n">journal</span> <span class="o">=</span> <span class="p">{</span><span class="n">ArXiv</span> <span class="n">e</span><span class="o">-</span><span class="n">prints</span><span class="p">},</span>
<span class="n">archivePrefix</span> <span class="o">=</span> <span class="s2">"arXiv"</span><span class="p">,</span>
  <span class="n">eprint</span> <span class="o">=</span> <span class="p">{</span><span class="mf">1804.03209</span><span class="p">},</span>
<span class="n">primaryClass</span> <span class="o">=</span> <span class="s2">"cs.CL"</span><span class="p">,</span>
<span class="n">keywords</span> <span class="o">=</span> <span class="p">{</span><span class="n">Computer</span> <span class="n">Science</span> <span class="o">-</span> <span class="n">Computation</span> <span class="ow">and</span> <span class="n">Language</span><span class="p">,</span> <span class="n">Computer</span> <span class="n">Science</span> <span class="o">-</span> <span class="n">Human</span><span class="o">-</span><span class="n">Computer</span> <span class="n">Interaction</span><span class="p">},</span>
    <span class="n">year</span> <span class="o">=</span> <span class="mi">2018</span><span class="p">,</span>
    <span class="n">month</span> <span class="o">=</span> <span class="n">apr</span><span class="p">,</span>
    <span class="n">url</span> <span class="o">=</span> <span class="p">{</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">arxiv</span><span class="o">.</span><span class="n">org</span><span class="o">/</span><span class="nb">abs</span><span class="o">/</span><span class="mf">1804.03209</span><span class="p">},</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="credits">
<h3 id="credits">Credits<a class="headerlink" href="#credits" title="Permalink to this heading">¶</a></h3>
<p>Massive thanks are due to everyone who donated recordings to this data set, I’m
very grateful. I also couldn’t have put this together without the help and
support of Billy Rutledge, Rajat Monga, Raziel Alvarez, Brad Krueger, Barbara
Petit, Gursheesh Kour, and all the AIY and TensorFlow teams.</p>
<p>Pete Warden, <a class="reference external" href="mailto:petewarden%40google.com">petewarden<span>@</span>google<span>.</span>com</a></p>
</section>
</section>
<p class="rubric">Variables</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mltk.datasets.audio.speech_commands.speech_commands_v2.DOWNLOAD_URL" title="mltk.datasets.audio.speech_commands.speech_commands_v2.DOWNLOAD_URL"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DOWNLOAD_URL</span></code></a></p></td>
<td><p>The public download URL</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mltk.datasets.audio.speech_commands.speech_commands_v2.VERIFY_SHA1" title="mltk.datasets.audio.speech_commands.speech_commands_v2.VERIFY_SHA1"><code class="xref py py-obj docutils literal notranslate"><span class="pre">VERIFY_SHA1</span></code></a></p></td>
<td><p>The SHA1 hash of the dataset archive</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mltk.datasets.audio.speech_commands.speech_commands_v2.CLASSES" title="mltk.datasets.audio.speech_commands.speech_commands_v2.CLASSES"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CLASSES</span></code></a></p></td>
<td><p>The class label supported by this dataset</p></td>
</tr>
</tbody>
</table>
<p class="rubric">Functions</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mltk.datasets.audio.speech_commands.speech_commands_v2.list_valid_filenames_in_directory" title="mltk.datasets.audio.speech_commands.speech_commands_v2.list_valid_filenames_in_directory"><code class="xref py py-obj docutils literal notranslate"><span class="pre">list_valid_filenames_in_directory</span></code></a>(...)</p></td>
<td><p>Return a list of valid file names for the given class</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mltk.datasets.audio.speech_commands.speech_commands_v2.load_clean_data" title="mltk.datasets.audio.speech_commands.speech_commands_v2.load_clean_data"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_clean_data</span></code></a>([dest_dir, dest_subdir, ...])</p></td>
<td><p>Load the data and remove all "invalid samples".</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mltk.datasets.audio.speech_commands.speech_commands_v2.load_data" title="mltk.datasets.audio.speech_commands.speech_commands_v2.load_data"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_data</span></code></a>([dest_dir, dest_subdir, ...])</p></td>
<td><p>Download and extract the Google Speech commands dataset v2, and return the directory path to the extracted dataset</p></td>
</tr>
</tbody>
</table>
<dl class="py data">
<dt class="sig sig-object py" id="mltk.datasets.audio.speech_commands.speech_commands_v2.DOWNLOAD_URL">
<span class="sig-name descname"><span class="pre">DOWNLOAD_URL</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz'</span></em><a class="headerlink" href="#mltk.datasets.audio.speech_commands.speech_commands_v2.DOWNLOAD_URL" title="Permalink to this definition">¶</a></dt>
<dd><p>The public download URL</p>
</dd></dl>
<dl class="py data">
<dt class="sig sig-object py" id="mltk.datasets.audio.speech_commands.speech_commands_v2.VERIFY_SHA1">
<span class="sig-name descname"><span class="pre">VERIFY_SHA1</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'4264eb9753e38eef2ec1d15dfac8441f09751ca9'</span></em><a class="headerlink" href="#mltk.datasets.audio.speech_commands.speech_commands_v2.VERIFY_SHA1" title="Permalink to this definition">¶</a></dt>
<dd><p>The SHA1 hash of the dataset archive</p>
</dd></dl>
<dl class="py data">
<dt class="sig sig-object py" id="mltk.datasets.audio.speech_commands.speech_commands_v2.CLASSES">
<span class="sig-name descname"><span class="pre">CLASSES</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">['Yes',</span> <span class="pre">'No',</span> <span class="pre">'Up',</span> <span class="pre">'Down',</span> <span class="pre">'Left',</span> <span class="pre">'Right',</span> <span class="pre">'On',</span> <span class="pre">'Off',</span> <span class="pre">'Stop',</span> <span class="pre">'Go',</span> <span class="pre">'Zero',</span> <span class="pre">'One',</span> <span class="pre">'Two',</span> <span class="pre">'Three',</span> <span class="pre">'Four',</span> <span class="pre">'Five',</span> <span class="pre">'Six',</span> <span class="pre">'Seven',</span> <span class="pre">'Eight',</span> <span class="pre">'Nine',</span> <span class="pre">'Bed',</span> <span class="pre">'Bird',</span> <span class="pre">'Cat',</span> <span class="pre">'Dog',</span> <span class="pre">'Happy',</span> <span class="pre">'House',</span> <span class="pre">'Marvin',</span> <span class="pre">'Sheila',</span> <span class="pre">'Tree',</span> <span class="pre">'Wow']</span></em><a class="headerlink" href="#mltk.datasets.audio.speech_commands.speech_commands_v2.CLASSES" title="Permalink to this definition">¶</a></dt>
<dd><p>The class label supported by this dataset</p>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="mltk.datasets.audio.speech_commands.speech_commands_v2.load_data">
<span class="sig-name descname"><span class="pre">load_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dest_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dest_subdir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'datasets/speech_commands/v2'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clean_dest_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/mltk/datasets/audio/speech_commands/speech_commands_v2.html#load_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mltk.datasets.audio.speech_commands.speech_commands_v2.load_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Download and extract the Google Speech commands dataset v2,
and return the directory path to the extracted dataset</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dest_dir</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – Absolute path of where the dataset should be extracted.
If omitted, defaults to MLTK_CACHE_DIR/&lt;dest_subdir&gt;/ OR ~/.mltk/&lt;dest_subdir&gt;/</p></li>
<li><p><strong>dest_subdir</strong> – Sub-directory of where the dataset should be extracted, only used if <code class="docutils literal notranslate"><span class="pre">dest_dir</span></code> is omitted
default: datasets/speech_commands/v2</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Directory path of extracted dataset</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="mltk.datasets.audio.speech_commands.speech_commands_v2.load_clean_data">
<span class="sig-name descname"><span class="pre">load_clean_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dest_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dest_subdir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'datasets/speech_commands/v2_cleaned'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clean_in_place</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clean_dest_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/mltk/datasets/audio/speech_commands/speech_commands_v2.html#load_clean_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mltk.datasets.audio.speech_commands.speech_commands_v2.load_clean_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Load the data and remove all “invalid samples”. That are samples that were manually determined to not be valid.
These samples are specified in invalid_samples.py</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dest_dir</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – Absolute path of where the dataset should be extracted and cleaned.
If omitted, defaults to MLTK_CACHE_DIR/&lt;dest_subdir&gt;/ OR ~/.mltk/&lt;dest_subdir&gt;</p></li>
<li><p><strong>dest_subdir</strong> – Sub-directory of where the dataset should be extracted and cleaned,
default: datasets/speech_commands/v2_cleaned</p></li>
<li><p><strong>clean_in_place</strong> – If true then the extracted dataset is cleaned in-place,
If false then the cleaned samples are copied to &lt;dest_dir&gt;/&lt;dest_subdir&gt;/_cleaned</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Directory path of extracted and cleaned dataset</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="mltk.datasets.audio.speech_commands.speech_commands_v2.list_valid_filenames_in_directory">
<span class="sig-name descname"><span class="pre">list_valid_filenames_in_directory</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">base_directory</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">search_class</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">white_list_formats</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">split</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">follow_links</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle_index_directory</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/mltk/datasets/audio/speech_commands/speech_commands_v2.html#list_valid_filenames_in_directory"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mltk.datasets.audio.speech_commands.speech_commands_v2.list_valid_filenames_in_directory" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a list of valid file names for the given class</p>
<p>Per the dataset README.md:</p>
<p>We want to keep files in the same training, validation, or testing sets even
if new ones are added over time. This makes it less likely that testing
samples will accidentally be reused in training when long runs are restarted
for example. To keep this stability, a hash of the filename is taken and used
to determine which set it should belong to. This determination only depends on
the name and the set proportions, so it won’t change as other files are added.</p>
<p>It’s also useful to associate particular files as related (for example words
spoken by the same person), so anything after ‘_nohash_’ in a filename is
ignored for set determination. This ensures that ‘bobby_nohash_0.wav’ and
‘bobby_nohash_1.wav’ are always in the same set, for example.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]]</p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>base_directory</strong> (<em>str</em>) – </p></li>
<li><p><strong>search_class</strong> (<em>str</em>) – </p></li>
<li><p><strong>white_list_formats</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – </p></li>
<li><p><strong>split</strong> (<em>float</em>) – </p></li>
<li><p><strong>follow_links</strong> (<em>bool</em>) – </p></li>
<li><p><strong>shuffle_index_directory</strong> (<em>str</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>
</section>


          </article>
        </div>
      </div>
      <a href="#" class="go-top"><i class="md-icon">arrow_upward</i>Back to Top</a>
    </main>
  </div>
  <footer class="md-footer">
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
          
            <a href="../index.html" title="Reference Datasets"
               class="md-flex md-footer-nav__link md-footer-nav__link--prev"
               rel="prev">
              <div class="md-flex__cell md-flex__cell--shrink">
                <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
              </div>
              <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
                <span class="md-flex__ellipsis">
                  <span
                      class="md-footer-nav__direction"> Previous </span> Reference Datasets </span>
              </div>
            </a>
          
          
            <a href="direction_commands.html" title="mltk.datasets.audio.direction_commands"
               class="md-flex md-footer-nav__link md-footer-nav__link--next"
               rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title"><span
                class="md-flex__ellipsis"> <span
                class="md-footer-nav__direction"> Next </span> mltk.datasets.audio.direction_commands </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink"><i
                class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          
        </a>
        
      </nav>
    </div>
    <div class="md-footer-meta md-typeset">
      <div class="md-footer-meta__inner md-grid">
        <div class="md-footer-copyright">
          <div class="md-footer-copyright__highlight">
              &#169; Copyright 2023, Silicon Labs.
              
          </div>
            Last updated on
              Jun 19, 2023.
            <br/>
            Created using
            <a href="http://www.sphinx-doc.org/">Sphinx</a> 5.3.0.
             and
            <a href="https://github.com/bashtage/sphinx-material/">Material for
              Sphinx</a>
        </div>
        <button id="survey-link" class="feedback-button">Feedback</button>
      </div>
    </div>
  </footer>
  <div class="privacy-banner">
    <div class="privacy-banner-wrapper">
      <p>
        <b>Important:</b> We use cookies only for functional and traffic analytics. <br />
        We DO NOT use cookies for any marketing purposes. By using our site you acknowledge you have read and understood our <a class="privacy-policy" href="https://www.silabs.com/about-us/legal/cookie-policy" target="_blank">Cookie Policy</a>.
      </p>
      <a class="privacy-banner-accept" href="#">Got it</a>
    </div>
</div>
  
<div class="survey-container" id="dlg-survey"> 
    <div class="close" id="dlg-survey-close"><i class="md-icon">close</i></div>
    <div class="msg">Please click the <b>submit</b> button at the end even if you do not answer all of the questions</div>
    <iframe id="iframe-survey" style="width: 100%; height: 100%;"></iframe>
</div>
  
  <script src="../../../../_static/javascripts/application.js"></script>
  <script>app.initialize({version: "1.0.4", url: {base: ".."}})</script>
  </body>
</html>