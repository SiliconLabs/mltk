
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width,initial-scale=1">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="title" content="Machine Learning Toolkit">
<meta name="description" content="A Python package with command-line utilities and scripts to aid the development of machine learning models for Silicon Lab's embedded platforms">
<meta name="keywords" content="machine learning, machine-learning, machinelearning, ml, ai, iot, Internet of things, aiot, tinyml, tensorflow, tensorflow-lite, tensorflow-lite-micro, keras-tensorflow, keras, tflite, embedded, embedded-systems, mcu, Microcontrollers, hardware, python, c++, cmake, keras, numpy, silabs, silicon labs">
<meta name="robots" content="index, follow">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="language" content="English">
<meta name="author" content="Silicon Labs">
  <meta name="lang:clipboard.copy" content="Copy to clipboard">
  <meta name="lang:clipboard.copied" content="Copied to clipboard">
  <meta name="lang:search.language" content="en">
  <meta name="lang:search.pipeline.stopwords" content="True">
  <meta name="lang:search.pipeline.trimmer" content="True">
  <meta name="lang:search.result.none" content="No matching documents">
  <meta name="lang:search.result.one" content="1 matching document">
  <meta name="lang:search.result.other" content="# matching documents">
  <meta name="lang:search.tokenizer" content="[\s\-]+">

  
    <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&display=fallback" rel="stylesheet">

    <style>
      body,
      input {
        font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif
      }

      code,
      kbd,
      pre {
        font-family: "Roboto Mono", "Courier New", Courier, monospace
      }
    </style>
  

  <link rel="stylesheet" href="../../_static/stylesheets/application.css"/>
  <link rel="stylesheet" href="../../_static/stylesheets/application-palette.css"/>
  <link rel="stylesheet" href="../../_static/stylesheets/application-fixes.css"/>
  
  <link rel="stylesheet" href="../../_static/fonts/material-icons.css"/>
  
  <meta name="theme-color" content="#3f51b5">
  <script src="../../_static/javascripts/modernizr.js"></script>
  
<script async src="https://www.googletagmanager.com/gtag/js?id=G-HZ5MW943WF"></script>
<script>
    window.gTrackingId = 'G-HZ5MW943WF';
</script>
<meta name="google-site-verification" content="dsSsmnE2twOnfSAQk5zBBTrjMArsTJj809Bp-8mVlIw" />
  
  
    <title>classify_audio &#8212; MLTK 0.15.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/material.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/design-tabs.js"></script>
    <script src="../../_static/js/custom.js"></script>
    <script src="../../_static/js/apitoc.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="classify_image" href="classify_image.html" />
    <link rel="prev" title="view_audio" href="view_audio.html" />
  
   

  </head>
  <body dir=ltr
        data-md-color-primary=red data-md-color-accent=light-blue>
  
  <svg class="md-svg">
    <defs data-children-count="0">
      
      <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
      
    </defs>
  </svg>
  
  <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer">
  <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search">
  <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
  <a href="#docs/command_line/classify_audio" tabindex="1" class="md-skip"> Skip to content </a>
  <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex navheader">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../../index.html" title="MLTK 0.15.0 documentation"
           class="md-header-nav__button md-logo">
          
              <img src="../../_static/logo.png"
                   alt="MLTK 0.15.0 documentation logo">
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          <span class="md-header-nav__topic">Machine Learning Toolkit</span>
          <span class="md-header-nav__topic"> classify_audio </span>
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
        
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" action="../../search.html" method="get" name="search">
      <input type="text" class="md-search__input" name="q" placeholder=""Search""
             autocapitalize="off" autocomplete="off" spellcheck="false"
             data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>

      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            <a href="https://github.com/siliconlabs/mltk" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    MLTK Github Repository
  </div>
</a>
          </div>
        </div>
      
      
    </div>
  </nav>
</header>

  
  <div class="md-container">
    
    
    
  <nav class="md-tabs" data-md-component="tabs">
    <div class="md-tabs__inner md-grid">
      <ul class="md-tabs__list">
            
            <li class="md-tabs__item"><a href="https://docs.silabs.com/gecko-platform/latest/machine-learning/tensorflow/overview" class="md-tabs__link">Gecko SDK Documentation</a></li>
            
            <li class="md-tabs__item"><a href="https://github.com/tensorflow/tflite-micro" class="md-tabs__link">Tensorflow-Lite Micro Repository</a></li>
            
            <li class="md-tabs__item"><a href="https://www.tensorflow.org/learn" class="md-tabs__link">Tensorflow Documentation</a></li>
          <li class="md-tabs__item"><a href="index.html" class="md-tabs__link">Command-Line</a></li>
      </ul>
    </div>
  </nav>
    <main class="md-main">
      <div class="md-main__inner md-grid" data-md-component="container">
        
          <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../../index.html" title="MLTK 0.15.0 documentation" class="md-nav__button md-logo">
      
        <img src="../../_static/logo.png" alt=" logo" width="48" height="48">
      
    </a>
    <a href="../../index.html"
       title="MLTK 0.15.0 documentation">Machine Learning Toolkit</a>
  </label>
    <div class="md-nav__source">
      <a href="https://github.com/siliconlabs/mltk" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    MLTK Github Repository
  </div>
</a>
    </div>
  
  

  
  <ul class="md-nav__list">
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Basics</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../overview.html" class="md-nav__link">Overview</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../why_mltk.html" class="md-nav__link">Why MLTK?</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../installation.html" class="md-nav__link">Installation</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="index.html" class="md-nav__link">Command-Line</a>
      <ul class="md-nav__list"> 
    <li class="md-nav__item">
    
    
      <a href="index.html#command-basics" class="md-nav__link">Command Basics</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="index.html#supported-operations" class="md-nav__link">Supported Operations</a>
      
    
    </li></ul>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../guides/index.html" class="md-nav__link">Modeling Guides</a>
      
    
    </li>
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Usage</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../tutorials.html" class="md-nav__link">Tutorials</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../examples.html" class="md-nav__link">API Examples</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../python_api/index.html" class="md-nav__link">API Reference</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../python_api/models/index.html" class="md-nav__link">Reference Models</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../python_api/datasets/index.html" class="md-nav__link">Reference Datasets</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../cpp_development/index.html" class="md-nav__link">C++ Development</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../cpp_development/examples/index.html" class="md-nav__link">C++ Examples</a>
      
    
    </li>
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Audio Related</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../audio/keyword_spotting_overview.html" class="md-nav__link">Keyword Spotting Overview</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../audio/audio_feature_generator.html" class="md-nav__link">Audio Feature Generator</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../audio/audio_utilities.html" class="md-nav__link">Audio Utilities</a>
      
    
    </li>
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Other Information</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../faq/index.html" class="md-nav__link">Frequently Asked Questions</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../other/quick_reference.html" class="md-nav__link">Quick Reference</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../other/supported_hardware.html" class="md-nav__link">Supported Hardware</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../guides/notebook_examples_guide.html" class="md-nav__link">Notebook Examples Guide</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../other/settings_file.html" class="md-nav__link">Settings File</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../other/environment_variables.html" class="md-nav__link">Environment Variables</a>
      
    
    </li>
  </ul>
  

</nav>
              </div>
            </div>
          </div>
          <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                
<nav class="md-nav md-nav--secondary">
    <label class="md-nav__title" for="__toc">Contents</label>
  <ul class="md-nav__list" data-md-scrollfix="" id="localtoc">
        <li class="md-nav__item"><a href="#docs-command-line-classify-audio--page-root" class="md-nav__link">classify_audio</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#additional-documentation" class="md-nav__link">Additional Documentation</a>
        </li>
        <li class="md-nav__item"><a href="#usage" class="md-nav__link">Usage</a>
        </li></ul>
            </nav>
        </li>
      <script type="text/javascript" src=../../_static/js/apitoc.js></script>
  </ul>
</nav>
              </div>
            </div>
          </div>
        
        <div class="md-content">

          
          <div class="breadcrumbs md-typeset">
            <ul class="breadcrumb">
              <li></li>
              <li><a href="../../index.html"><i class="md-icon">home</i></a></li>
                <li><a href="index.html" accesskey="U">Command-Line</a></li>

              <li class="activate"><a>classify_audio</a></li>
            </ul>
          </div>
          

          <article class="md-content__inner md-typeset" role="main">
            
  <section id="classify-audio">
<h1 id="docs-command-line-classify-audio--page-root">classify_audio<a class="headerlink" href="#docs-command-line-classify-audio--page-root" title="Permalink to this heading">¶</a></h1>
<p>Classify real-time audio from a development board’s or PC’s microphone.</p>
<section id="additional-documentation">
<h2 id="additional-documentation">Additional Documentation<a class="headerlink" href="#additional-documentation" title="Permalink to this heading">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="../../docs/audio/audio_utilities.html">Audio Utilities</a></p></li>
<li><p><a class="reference external" href="../../docs/cpp_development/examples/audio_classifier.html">Audio Classifier App</a></p></li>
</ul>
</section>
<section id="usage">
<h2 id="usage">Usage<a class="headerlink" href="#usage" title="Permalink to this heading">¶</a></h2>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>                                                                                                                                                                                                                                                                                               
 Usage: mltk classify_audio [OPTIONS] &lt;model&gt;                                                                                                                                                                                                                                                  
                                                                                                                                                                                                                                                                                               
 Classify keywords/events detected in a microphone's streaming audio                                                                                                                                                                                                                           
 NOTE: This command is experimental. Use at your own risk!                                                                                                                                                                                                                                     
 This command runs an audio classification application on either the local PC OR                                                                                                                                                                                                               
 on an embedded target. The audio classification application loads the given                                                                                                                                                                                                                   
 audio classification ML model (e.g. Keyword Spotting) and streams real-time audio                                                                                                                                                                                                             
 from the local PC's/embedded target's microphone into the ML model.                                                                                                                                                                                                                           
                                                                                                                                                                                                                                                                                               
 System Dataflow:                                                                                                                                                                                                                                                                              
 Microphone -&gt; AudioFeatureGenerator -&gt; ML Model -&gt; Command Recognizer -&gt; Local Terminal                                                                                                                                                                                                       
                                                                                                                                                                                                                                                                                               
 Refer to the mltk.models.tflite_micro.tflite_micro_speech model for a reference on how to train                                                                                                                                                                                               
 an ML model that works the audio classification application.                                                                                                                                                                                                                                  
                                                                                                                                                                                                                                                                                               
 For more details see:                                                                                                                                                                                                                                                                         
 https://siliconlabs.github.io/mltk/docs/audio/audio_utilities                                                                                                                                                                                                                                 
                                                                                                                                                                                                                                                                                               
 ----------                                                                                                                                                                                                                                                                                    
  Examples                                                                                                                                                                                                                                                                                     
 ----------                                                                                                                                                                                                                                                                                    
                                                                                                                                                                                                                                                                                               
 # Classify audio on local PC using tflite_micro_speech model                                                                                                                                                                                                                                  
 # Simulate the audio loop latency to be 200ms                                                                                                                                                                                                                                                 
 # i.e. If the app was running on an embedded target, it would take 200ms per audio loop                                                                                                                                                                                                       
 # Also enable verbose logs                                                                                                                                                                                                                                                                    
 mltk classify_audio tflite_micro_speech --latency 200 --verbose                                                                                                                                                                                                                               
                                                                                                                                                                                                                                                                                               
 # Classify audio on an embedded target using model: ~/workspace/my_model.tflite                                                                                                                                                                                                               
 # and the following classifier settings:                                                                                                                                                                                                                                                      
 # - Set the averaging window to 1200ms (i.e. drop samples older than &lt;now&gt; minus window)                                                                                                                                                                                                      
 # - Set the minimum sample count to 3 (i.e. must have at last 3 samples before classifying)                                                                                                                                                                                                   
 # - Set the threshold to 175 (i.e. the average of the inference results within the averaging window must be at least 175 of 255)                                                                                                                                                              
 # - Set the suppression to 750ms (i.e. Once a keyword is detected, wait 750ms before detecting more keywords)                                                                                                                                                                                 
 # i.e. If the app was running on an embedded target, it would take 200ms per audio loop                                                                                                                                                                                                       
 mltk classify_audio /home/john/my_model.tflite --device --window 1200ms --count 3 --threshold 175 --suppression 750                                                                                                                                                                           
                                                                                                                                                                                                                                                                                               
 # Classify audio and also dump the captured raw audio and spectrograms                                                                                                                                                                                                                        
 mltk classify_audio tflite_micro_speech --dump-audio --dump-spectrograms                                                                                                                                                                                                                      
                                                                                                                                                                                                                                                                                               
 Arguments 
 *    model      &lt;model&gt;  On of the following:                                                   [default: None] [required]                                                                                                                                                                  
                          - MLTK model name                                                                                                                                                                                                                                                  
                          - Path to .tflite file                                                                                                                                                                                                                                             
                          - Path to model archive file (.mltk.zip)                                                                                                                                                                                                                           
                          NOTE: The model must have been previously trained for keyword spotting                                                                                                                                                                                             

 Options 
 --accelerator            -a      &lt;name&gt;            Name of accelerator to use while executing the audio classification ML model.                              [default: None]                                                                                                               
                                                    If omitted, then use the reference kernels                                                                                                                                                                                               
                                                    NOTE: It is recommended to NOT use an accelerator if running on the PC since the HW simulator can be slow.                                                                                                                               
 --device                 -d                        If provided, then run the keyword spotting model on an embedded device, otherwise use the PC's local microphone.                                                                                                                         
                                                    If this option is provided, then the device must be locally connected                                                                                                                                                                    
 --port                           &lt;port&gt;            Serial COM port of a locally connected embedded device.                  [default: None]                                                                                                                                                 
                                                    This is only used with the --device option.                                                                                                                                                                                              
                                                    'If omitted, then attempt to automatically determine the serial COM port                                                                                                                                                                 
 --verbose                -v                        Enable verbose console logs                                                                                                                                                                                                              
 --window_duration        -w      &lt;duration ms&gt;     Controls the smoothing. Drop all inference results that are older than &lt;now&gt; minus window_duration.                       [default: None]                                                                                                
                                                    Longer durations (in milliseconds) will give a higher confidence that the results are correct, but may miss some commands                                                                                                                
 --count                  -c      &lt;count&gt;           The *minimum* number of inference results to average when calculating the detection value. Set to 0 to disable averaging [default: None]                                                                                                 
 --threshold              -t      &lt;threshold&gt;       Minimum averaged model output threshold for a class to be considered detected, 0-255. Higher values increase precision at the cost of recall [default: None]                                                                             
 --suppression            -s      &lt;suppression ms&gt;  Amount of milliseconds to wait after a keyword is detected before detecting new keywords [default: None]                                                                                                                                 
 --latency                -l      &lt;latency ms&gt;      This the amount of time in milliseconds between processing loops [default: None]                                                                                                                                                         
 --microphone             -m      &lt;name&gt;            For non-embedded, this specifies the name of the PC microphone to use [default: None]                                                                                                                                                    
 --volume                 -u      &lt;volume gain&gt;     Set the volume gain scaler (i.e. amplitude) to apply to the microphone data. If 0 or omitted, no scaler is applied [default: None]                                                                                                       
 --dump-audio             -x                        Dump the raw microphone and generate a corresponding .wav file                                                                                                                                                                           
 --dump-raw-spectrograms  -w                        Dump the raw (i.e. unquantized) generated spectrograms to .jpg images and .mp4 video                                                                                                                                                     
 --dump-spectrograms      -z                        Dump the quantized generated spectrograms to .jpg images and .mp4 video                                                                                                                                                                  
 --sensitivity            -i      FLOAT             Sensitivity of the activity indicator LED. Much less than 1.0 has higher sensitivity [default: None]                                                                                                                                     
 --app                            &lt;path&gt;            By default, the audio_classifier app is automatically downloaded.                                                             [default: None]                                                                                            
                                                    This option allows for overriding with a custom built app.                                                                                                                                                                               
                                                    Alternatively, if using the --device option, set this option to "none" to NOT program the audio_classifier app to the device.                                                                                                            
                                                    In this case, ONLY the .tflite will be programmed and the existing audio_classifier app will be re-used.                                                                                                                                 
 --test                                             Run as a unit test                                                                                                                                                                                                                       
 --help                                             Show this message and exit.                                                                                                                                                                                                              
</pre></div>
</div>
</section>
</section>


          </article>
        </div>
      </div>
      <a href="#" class="go-top"><i class="md-icon">arrow_upward</i>Back to Top</a>
    </main>
  </div>
  <footer class="md-footer">
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
          
            <a href="view_audio.html" title="view_audio"
               class="md-flex md-footer-nav__link md-footer-nav__link--prev"
               rel="prev">
              <div class="md-flex__cell md-flex__cell--shrink">
                <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
              </div>
              <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
                <span class="md-flex__ellipsis">
                  <span
                      class="md-footer-nav__direction"> Previous </span> view_audio </span>
              </div>
            </a>
          
          
            <a href="classify_image.html" title="classify_image"
               class="md-flex md-footer-nav__link md-footer-nav__link--next"
               rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title"><span
                class="md-flex__ellipsis"> <span
                class="md-footer-nav__direction"> Next </span> classify_image </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink"><i
                class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          
        </a>
        
      </nav>
    </div>
    <div class="md-footer-meta md-typeset">
      <div class="md-footer-meta__inner md-grid">
        <div class="md-footer-copyright">
          <div class="md-footer-copyright__highlight">
              &#169; Copyright 2023, Silicon Labs.
              
          </div>
            Last updated on
              Mar 01, 2023.
            <br/>
            Created using
            <a href="http://www.sphinx-doc.org/">Sphinx</a> 5.3.0.
             and
            <a href="https://github.com/bashtage/sphinx-material/">Material for
              Sphinx</a>
        </div>
        <button id="survey-link" class="feedback-button">Feedback</button>
      </div>
    </div>
  </footer>
  <div class="privacy-banner">
    <div class="privacy-banner-wrapper">
      <p>
        <b>Important:</b> We use cookies only for functional and traffic analytics. <br />
        We DO NOT use cookies for any marketing purposes. By using our site you acknowledge you have read and understood our <a class="privacy-policy" href="https://www.silabs.com/about-us/legal/cookie-policy" target="_blank">Cookie Policy</a>.
      </p>
      <a class="privacy-banner-accept" href="#">Got it</a>
    </div>
</div>
  
<div class="survey-container" id="dlg-survey"> 
    <div class="close" id="dlg-survey-close"><i class="md-icon">close</i></div>
    <div class="msg">Please click the <b>submit</b> button at the end even if you do not answer all of the questions</div>
    <iframe id="iframe-survey" style="width: 100%; height: 100%;"></iframe>
</div>
  
  <script src="../../_static/javascripts/application.js"></script>
  <script>app.initialize({version: "1.0.4", url: {base: ".."}})</script>
  </body>
</html>