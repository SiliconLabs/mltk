__NOTE:__ Refer to the [online documentation](https://siliconlabs.github.io/mltk) to properly view this file
# quantize
 Quantize a trained model to reduce its memory footprint.

## Additional Documentation

- [Model Profiler Guide](../guides/model_quantization.md)
- [quantize_model API](https://siliconlabs.github.io/mltk/docs/python_api/operations/quantize.html)


## Usage

```{include} ./quantize_cli_help.md
```