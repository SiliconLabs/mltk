{

 "cells": [

  {

   "attachments": {},

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "# Synthetic Audio Dataset Generation\n",

    "\n",

    "This tutorial describes how to use Text-to-Speech (TTS) features of the:\n",

    "- [Google Cloud Platform (GCP)](https://cloud.google.com/text-to-speech)\n",

    "- [Microsoft (Azure)](https://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/text-to-speech)\n",

    "- [Amazon Web Services (AWS)](https://aws.amazon.com/polly)\n",

    "\n",

    "clouds to generate synthetic keyword audio datasets.\n",

    "\n",

    "With this, [keyword spotting](../../docs/audio/keyword_spotting_overview.md) machine learning models may be trained to detected custom keywords.\n",

    "\n",

    "In this tutorial, we use the [AudioDatasetGenerator](../../docs/python_api/utils/audio_dataset_generator/index.md) Python package to generate a synthetic \"Alexa\" dataset."

   ]

  },

  {

   "attachments": {},

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "## Quick Links\n",

    "\n",

    "- [GitHub Source](https://github.com/SiliconLabs/mltk/blob/master/mltk/tutorials/synthetic_audio_dataset_generation.ipynb) - View this tutorial on Github\n",

    "- [Run on Colab](https://colab.research.google.com/github/siliconlabs/mltk/blob/master/mltk/tutorials/synthetic_audio_dataset_generation.ipynb) - Run this tutorial on Google Colab\n",

    "- [AudioDatasetGenerator API Reference](../../docs/python_api/utils/audio_dataset_generator/index.md) - View the Python API reference\n",

    "- [Alexa Dataset Generation Example](https://github.com/siliconlabs/mltk/blob/master/mltk/utils/audio_dataset_generator/examples/alexa_dataset_generator.py) - View the example Python script to generate an \"Alexa\" dataset\n",

    "  "

   ]

  },

  {

   "attachments": {},

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "## Content\n",

    "\n",

    "This tutorial is divided into the following sections:\n",

    "- [Basic overview](#overview)\n",

    "- [Google Cloud setup](#google-cloud-platform-gcp-setup)\n",

    "- [Microsoft Cloud setup](#microsoft-azure-setup)\n",

    "- [Amazon Cloud setup](#amazon-web-services-aws-setup)\n",

    "- [Example script for generating an \"Alexa\" dataset](#alexa-example)"

   ]

  },

  {

   "attachments": {},

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "## Overview\n",

    "\n",

    "A quality keyword spotting dataset should have the following characteristics:  \n",

    "- __Lots of samples__ - At least 3k+ samples for each keyword (10-100k+ is recommended)\n",

    "- __Lots of different voices__ - The more people speaking the keywords the better as this will help account of different accents \n",

    "- __Same voice, different pronunciations__ - The same speaker saying the keyword in different ways (e.g. fast, slow, \"happy\", \"sad\", \"excited\", etc.)\n",

    "- __Lots of negative samples__ - Words that are not the keyword(s) but sound similar or would be commonly heard in the field\n",

    "\n",

    "All of these characterisitics help to make a _representative_ dataset, and the more representative the dataset (i.e. the more similar the data is to what would be heard in the field) the better the machine learning model will likely perform.\n",

    "\n",

    "### Recording real people\n",

    "\n",

    "Ideally, the dataset would be generated by recording 5-50k+ different people saying the keyword(s) as this would help to make the most representative dataset.\n",

    "While 3rd-party services are available to aid with dataset generation they can be expensive ($20k+).\n",

    "\n",

    "__Pros__  \n",

    "- More representative samples\n",

    "\n",

    "__Cons__  \n",

    "- Expensive (time and money)\n",

    "- Harder to generate \"negative\" samples (harder to record non-keywords)\n",

    "- More data cleaning required (need to verify audio samples as humans make errors)\n",

    "\n",

    "### Synthetic generation\n",

    "\n",

    "An alternative approach is to synthetically generate the audio samples using Text-to-Speech (TTS) services.\n",

    "Cloud services like [Google Cloud Platform (GCP)](https://cloud.google.com/text-to-speech), [Microsoft (Azure)](https://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/text-to-speech), and [Amazon Web Services (AWS)](https://aws.amazon.com/polly)\n",

    "allow for converting written text to audio samples. While these services are primarily intended for converting long strings of text they also work for single words.\n",

    "\n",

    "A major concern with this approach is that the generated audio samples would not be representative (i.e. they would sound too \"robotic\"), however, in many cases the audio generated by these TTS services sounds realistic thanks to [new AI techniques](https://ai.googleblog.com/2017/12/tacotron-2-generating-human-like-speech.html).\n",

    "\n",

    "\n",

    "__Pros__  \n",

    "- Less expensive (time and money)\n",

    "- Easier to generate \"negative\" samples\n",

    "- Little or no data cleaning required\n",

    "\n",

    "__Cons__  \n",

    "- Less representative samples (limited by the number of \"voices\" offered by the TTS services)"

   ]

  },

  {

   "attachments": {},

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "### Note about synthetic augmentations\n",

    "\n",

    "Many of the TTS services allow for augmenting the audio by adjusting the \"pitch\" or \"speaking rate\". While this can help to increase the number of audio samples, these augmentations should be used sparingly as they do not fundamentally change the underlying audio. As such, a large number of samples with small increments in the augmentation settings will likely not help the machine learning model to generalize (in fact, they could cause the ML model to over fit the data)."

   ]

  },

  {

   "attachments": {},

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "### Note about languages\n",

    "\n",

    "Each TTS service supports numerous different languages.\n",

    "While there are exceptions, it has been found that English keywords generated with different languages are still valid (e.g. English text generated with a Russian \"voice\" still sounds like a valid English audio sample with a Russian accent).\n",

    "This is very useful as it allows for generating keywords with different accents and thus allows for generating a more representative dataset.\n",

    "\n",

    "When using different languages, it is recommended to spot check the generated audio samples to ensure they're valid."

   ]

  },

  {

   "attachments": {},

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "### Note about the \"negative\" class\n",

    "\n",

    "Training a machine learning model to detect a one or more keywords is (relatively) easy.\n",

    "The hard part is training a machine learning model to reliably detect the keywords _and_ reject everything else.\n",

    "\n",

    "For example, consider a \"smart\" trashcan whose lid opens with the keyword \"open\" and closes with the keyword \"close\".\n",

    "The trashcan should only react to those two keywords and ignore all other words and sounds (i.e. it should have a low false-positive rate).\n",

    "For this application, a low false-positive rate is critical otherwise the trashcan lid would be constantly opening/closing while having a conversation next to it.\n",

    "\n",

    "Training an ML model to trigger on the \"open\" and \"close\" keywords is fairly simple.\n",

    "The hard part is getting the ML model to ignore everything else (e.g. words like \"opening\", \"closet\", etc.).\n",

    "\n",

    "To help solve this problem, the dataset should have a large \"negative\" class -- it should have lots of samples that sound similar to the keywords.\n",

    "Generating the negative samples is fairly trivial with synthetic dataset generation as it is just a matter of supplying the negative keywords to the generation script.\n"

   ]

  },

  {

   "attachments": {},

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "### Note about cost\n",

    "\n",

    "While using the cloud TTS services is relatively cheap, __they are NOT FREE!__\n",

    "\n",

    "These services typically charge per character that is sent to the generation request.\n",

    "The TTS services usually offer a certain number of free characters per month and then charge once the limit is exceeded.\n",

    "\n",

    "For instance, consider the [Google Text-to-Speech pricing table](https://cloud.google.com/text-to-speech/pricing)  (as of January 2023, see their website for the latest prices):\n",

    "\n",

    "| Feature                                    | Free per month            | Price after free usage limit is reached                            |\n",

    "|--------------------------------------------|---------------------------|--------------------------------------------------------------------|\n",

    "| Standard (non-WaveNet, non-Neural2) voices | 0 to 4 million characters | $0.000004 USD per character ($4.00 USD per 1 million characters)   |\n",

    "| WaveNet voices                             | 0 to 1 million characters | $0.000016 USD per character  ($16.00 USD per 1 million characters) |\n",

    "| Neural2 voices                             | 0 to 1 million characters | $0.000016 USD per character ($16.00 USD per 1 million characters)  |\n",

    "\n",

    "Even with this pricing, a lot of keyword audio samples may be generated for very little money.\n",

    "\n",

    "__NOTE:__ The number of characters sent is not only dependent on the length of the keyword but also on the audio markup language.\n",

    "\n",

    "For instance, the following is an example request sent to the Microsoft cloud:\n",

    "\n",

    "```xml\n",

    "<speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"en-US\">\n",

    "    <voice name=\"en-US-JennyNeural\">\n",

    "        <mstts:express-as style=\"cheerful\">\n",

    "            <prosody rate=\"fast\" pitch=\"medium\">\n",

    "                open\n",

    "            </prosody>\n",

    "        </mstts:express-as>\n",

    "    </voice>\n",

    "</speak>\n",

    "```\n",

    "\n",

    "All of the characters in the request (minus the whitespace) contribute to the character count.\n",

    "\n",

    "To help determine the character counts, the MLTK features the API: [AudioDatasetGenerator.count_characters](https://siliconlabs.github.io/mltk/docs/python_api/utils/audio_dataset_generator/generator.html#mltk.utils.audio_dataset_generator.AudioDatasetGenerator.count_characters)"

   ]

  },

  {

   "attachments": {},

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "## Google Cloud Platform (GCP) Setup\n",

    "\n",

    "From [Google Cloud Platform Text-to-Speech](https://cloud.google.com/text-to-speech):  \n",

    "> Convert text into natural-sounding speech using an API powered by the best of Google’s AI technologies. \n",

    "\n",

    "### Features\n",

    "- Choose from [220+ voices across 40+ languages and variants](https://cloud.google.com/text-to-speech/docs/voices)\n",

    "- New customers get $300 in free credits to spend on Text-to-Speech\n",

    "\n",

    "### Quick Links  \n",

    "- [Installation Instructions](https://codelabs.developers.google.com/codelabs/cloud-text-speech-python3)\n",

    "- [Live Demo](https://cloud.google.com/text-to-speech#section-2)\n",

    "- [Pricing](https://cloud.google.com/text-to-speech/pricing)\n",

    "- [Quotas](https://cloud.google.com/text-to-speech/quotas)\n",

    "- [Python API Docs](https://cloud.google.com/python/docs/reference/texttospeech/latest/google.cloud.texttospeech_v1beta1.services.text_to_speech.TextToSpeechClient)"

   ]

  },

  {

   "attachments": {},

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "## Microsoft Azure Setup\n",

    "\n",

    "From [Microsoft Azure Text-to-Speech](https://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/text-to-speech):\n",

    "\n",

    "> Text-to-speech enables your applications, tools, or devices to convert text into humanlike synthesized speech. The text-to-speech capability is also known as speech synthesis. Use humanlike prebuilt neural voices out of the box, or create a custom neural voice that's unique to your product or brand. \n",

    "\n",

    "\n",

    "### Features\n",

    "- For a full list of supported voices, languages, and locales, see Language and voice support for the [Speech service](https://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/language-support?tabs=stt-tts)\n",

    "- New customers get $200 in free credits to spend on Text-to-Speech\n",

    "\n",

    "### Quick Links\n",

    "- [Installation Instructions](https://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/get-started-text-to-speech?pivots=programming-language-python)\n",

    "- [Live Demo](https://azure.microsoft.com/en-us/products/cognitive-services/text-to-speech/#features)\n",

    "- [Pricing](https://azure.microsoft.com/en-us/pricing/details/cognitive-services/speech-services)\n",

    "- [Quotas](https://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/speech-services-quotas-and-limits)\n",

    "- [Python API Docs](https://learn.microsoft.com/en-us/python/api/azure-cognitiveservices-speech/azure.cognitiveservices.speech.speechsynthesizer?view=azure-python)"

   ]

  },

  {

   "attachments": {},

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "## Amazon Web Services (AWS) Setup\n",

    "\n",

    "From [Amazon Polly](https://docs.aws.amazon.com/polly/latest/dg/what-is.html)\n",

    "\n",

    "> Amazon Polly is a cloud service that converts text into lifelike speech. You can use Amazon Polly to develop applications that increase engagement and accessibility. Amazon Polly supports multiple languages and includes a variety of lifelike voices, so you can build speech-enabled applications that work in multiple locations and use the ideal voice for your customers. With Amazon Polly, you only pay for the text you synthesize. \n",

    "\n",

    "\n",

    "### Quick Links\n",

    "- [Installation Instructions](https://docs.aws.amazon.com/polly/latest/dg/get-started-what-next.html)\n",

    "- [Live Demo](https://us-east-1.console.aws.amazon.com/polly/home/SynthesizeSpeech)\n",

    "- [Pricing](https://aws.amazon.com/polly/pricing)\n",

    "- [Quotas](https://docs.aws.amazon.com/general/latest/gr/pol.html)\n",

    "- [Python API Docs](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/polly.html)"

   ]

  },

  {

   "attachments": {},

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "## Alexa Example\n",

    "\n",

    "The MLTK features the Python package: [AudioDatasetGenerator](../../docs/python_api/utils/audio_dataset_generator/index.md) which allows for generating a synthetic keyword dataset using the Google, Microsoft, and Amazon clouds.\n",

    "\n",

    "The Python script: [alexa_dataset_generator.py](https://github.com/siliconlabs/mltk/blob/master/mltk/utils/audio_dataset_generator/examples/alexa_dataset_generator.py) demonstrates how to use this Python package to generate a synthetic \"Alexa\" dataset. \n",

    "\n",

    "The following provides more details about this script.\n",

    "\n",

    "__NOTE:__ Click [HERE](https://colab.research.google.com/github/siliconlabs/mltk/blob/master/mltk/tutorials/synthetic_audio_dataset_generation.ipynb) to execute the following code in your web-browser"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": null,

   "metadata": {},

   "outputs": [],

   "source": [

    "# Install the MLTK Python package into the local Notebook environment\n",

    "%pip install silabs-mltk --upgrade"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 1,

   "metadata": {},

   "outputs": [],

   "source": [

    "# Import the necessary Python packages\n",

    "import os\n",

    "import json\n",

    "import tqdm\n",

    "import tempfile\n",

    "from mltk.utils.audio_dataset_generator import (\n",

    "    AudioDatasetGenerator,\n",

    "    Keyword,\n",

    "    Augmentation,\n",

    "    VoiceRate,\n",

    "    VoicePitch\n",

    ")"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 2,

   "metadata": {},

   "outputs": [],

   "source": [

    "# NOTE: The following credentials are provided as an example.\n",

    "#       You must generate your own credentials to run this example\n",

    "\n",

    "###################################################################################################\n",

    "# Configure your Azure credentials\n",

    "# See: https://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/get-started-text-to-speech?pivots=programming-language-python\n",

    "os.environ['SPEECH_KEY'] = 'e8699507e7c04a4cb8afdba62986987c'\n",

    "os.environ['SPEECH_REGION'] = 'westus2'"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 3,

   "metadata": {},

   "outputs": [],

   "source": [

    "###################################################################################################\n",

    "# Configure your Google credentials\n",

    "# See: https://codelabs.developers.google.com/codelabs/cloud-text-speech-python3\n",

    "\n",

    "# NOTE: The \"serivce account\" JSON was copied into this Python script for demonstration purposes.\n",

    "#       You could also just set GOOGLE_APPLICATION_CREDENTIALS to point to your service account .json file and\n",

    "#       and remove the following.\n",

    "#\n",

    "#       If you do copy and paste into this script, be sure that the \"private_key\" is on a single line, e.g.:\n",

    "#       \"private_key_id\": ...,\n",

    "#       \"private_key\": \"-----BEGIN PRIVATE KEY---- ....\",\n",

    "#       \"client_email\":  ...,\n",

    "#\n",

    "#       NOT:\n",

    "#\n",

    "#       \"private_key\": \"-----BEGIN PRIVATE KEY--- ...\n",

    "#       NEB6Y5ZODG2DYJmM+JdAHcNaPRD9/hAMRG3jl2jisVZO ...\n",

    "#       03aEXJYOEWTbLWfPYxpNQyz4wKBgQDD+yVYWCrbXEECn ...\n",

    "#       ... -----END PRIVATE KEY-----\\n\",\n",

    "#       \"client_email\": ...,\n",

    "#       \"client_id\": ...,\n",

    "#\n",

    "gcp_service_account_json_path = f'{tempfile.gettempdir()}/gcp_key.json'\n",

    "gcp_service_account_json = \"\"\"\n",

    "{\n",

    "  \"type\": \"service_account\",\n",

    "  \"project_id\": \"strange-firefly-374023\",\n",

    "  \"private_key_id\": \"8e074b2dc4da026810d6b728e1588e79a745a08c\",\n",

    "  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQCuQ4FpO6IlIB78\\nmHYRHb1Ei2PCEgtthRlXbQwE6RsWppTtopQVpLSBXs30FRarpd6d4hgqeL46gC2d\\nCRHH8oMrgKMB4pAGzHCEfJd/XjKckNsyIPLTqGBjAu3pT/wMukIHdYiYzDD6qjr3\\nuGghP8HkT1gXgcGdFkpLWVoj9b3M6b5/3cVgBthciycCCYkHqnFOn6MTEe6OFMPZ\\nWXY3FrEwyWjIWIIIvPbQaNoIJs92Gb+FFGsG2Ta63TgsZmBvVHjtd3A98EwmvwSz\\nbIPXjqh5qLh3YCHdGT42MqBXrInN11kMyOC56A2Ic4mvrQ3I8oAPOs2L6ugLwX9J\\nS6Sq5JW1AgMBAAECggEAT7pS2vKNnK61fpvCaNJSZangWkonMFRU48rgVN7RpetQ\\n9+gKGFziuM3HLIT5ek7JKzLmG4higCFkvRQJLpGlsaGI8rPVcUbXs8XNCljujvM3\\nVhf9ARln/+S3NKeDic8tpnv/oujI/+YiVHPqMEwbSXmDtD2Jd3VbSF34/7rOu5Dz\\n56bGmBbNEB6Y5ZODG2DYJmM+JdAHcNaPRD9/hAMRG3jl2jisVZOgrleNelkZnrPe\\n9t0uWqIv5EJItoVBZd+EzADFfjfTDrKfWv1QixeMiak1aTbs5bHKNK5ecYFFMpms\\nCIVgp3wRxq7nFrJkTnWdJzeAFjQw4CKWLmN4xc2FgQKBgQDjobnxjGO7GQ1pfEiQ\\nVsSuWJiXy63trU6jwrrhR1B9XUPh6VivH2dZ4lPfPywER9LX6oMTn6AIzihTPq1I\\n19eskH0H6hwBw2yDzWgHZRMHB9xs5Ys+HiBKWrZ9NW77uWH1D9g/EJcN6A2ZL2ig\\nK03aEXJYOEWTbLWfPYxpNQyz4wKBgQDD+yVYWCrbXEECnA0fohw8wIRo6dS6G84M\\nMCzkr0YooxPb8zrIIm+mv7PAcCElaSz4LZbC2Hcb1mvV9p6o2IEUHqNgabWLFWiD\\ng7CC7rm4qEE87p5U4oBUhPCiuZpA3UeAqBhxMWd1oXw5rJVXenNe+7G4JZKxERU/\\nQIf7cw6zhwKBgBy5dctjWdpsSOL8yfNc36jYiTjufN43Nms30XlIFIIdWMmTNpuy\\nrMoM42SShi1sGtEgSLYbOIij6zbF+/vrMM4X1Y9AHZSjYngnXW9Bc+s5NLmRJccK\\n6iw30jtumLivJgtUmocqwsUAeWbRMrSzgjl4ZiN3xl/aIfkcPTGxfg7dAoGAVz6b\\njmuZkJPOIRJFSVrKhUUS7P2DhOJR5N0hbyCT9A09DwKFnYiu+aWHqNiB+PyMV2M8\\nJTtmMs9OrC6gzPus4r8M7iPA/Myn/TwHvRH3PbwxZqW3eIRoqrePxHEpuUyIwz6R\\nuvpKW3RrL+WjihDqAVO89wRK/GZldgYNQyQiXEsCgYEAj+8nsq1UGod7SqfPiA/n\\n3Wur4A+UYT8/nuaTK2WW/GTBC+eDDjRE1lZ3f/UQGTSXLSV7T1mw4a7EKrkFl36P\\nLnVeFBTB3UCd8JJ0LPBtOqru9I8ns+a4FqOPMljoYElGtyT1Oy+vxfwYA7cmRz/d\\n49bE21meuV3pRV1QWrrteEM=\\n-----END PRIVATE KEY-----\\n\",\n",

    "  \"client_email\": \"my-tts-sa@strange-firefly-374023.iam.gserviceaccount.com\",\n",

    "  \"client_id\": \"109154742213348109867\",\n",

    "  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",

    "  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",

    "  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",

    "  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/my-tts-sa%40strange-firefly-374023.iam.gserviceaccount.com\"\n",

    "}\n",

    "\"\"\"\n",

    "gcp_service_account_json = gcp_service_account_json.strip().replace(',\\n', ',').replace('\\n', '\\\\n').replace('{\\\\n', '{\\n').replace('\\\\n}', '\\n}')\n",

    "\n",

    "with open(gcp_service_account_json_path, 'w') as f:\n",

    "    f.write(gcp_service_account_json)\n",

    "\n",

    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = gcp_service_account_json_path\n",

    "with open(os.environ['GOOGLE_APPLICATION_CREDENTIALS'], 'r') as f:\n",

    "    credentials = json.load(f)\n",

    "os.environ['PROJECT_ID'] = credentials['project_id']"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 4,

   "metadata": {},

   "outputs": [],

   "source": [

    "###################################################################################################\n",

    "# Configure your AWS credentials\n",

    "# See: https://docs.aws.amazon.com/polly/latest/dg/get-started-what-next.html\n",

    "os.environ['AWS_ACCESS_KEY_ID'] = 'AKIATZWWZR5TWBUNF6IX'\n",

    "os.environ['AWS_SECRET_ACCESS_KEY'] = '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'\n",

    "os.environ['AWS_DEFAULT_REGION'] = 'us-west-2'"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 5,

   "metadata": {},

   "outputs": [],

   "source": [

    "###################################################################################################\n",

    "# Define the directory where the dataset will be generated\n",

    "OUT_DIR = f'{tempfile.gettempdir()}/alexa_dataset'.replace('\\\\', '/')"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 6,

   "metadata": {},

   "outputs": [],

   "source": [

    "###################################################################################################\n",

    "# Define the keywords and corresponding aliases to generate\n",

    "# For the _unknown_ class (e.g. negative class), we want words that sound similar to \"alexa\".\n",

    "# NOTE: If the base word starts with an underscore, it is not included in the generation list.\n",

    "# So the generation list will be:\n",

    "# alexa, ehlexa, eelexa, aalexa\n",

    "# ah, aag, a, o, uh, ...\n",

    "#\n",

    "# The dataset will have the directory structure:\n",

    "# $TEMP/alexa_dataset/alexa/sample1.wav\n",

    "# $TEMP/alexa_dataset/alexa/sample2.wav\n",

    "# $TEMP/alexa_dataset/alexa/...\n",

    "# $TEMP/alexa_dataset/_unknown_/sample1.wav\n",

    "# $TEMP/alexa_dataset/_unknown_/sample2.wav\n",

    "# $TEMP/alexa_dataset/_unknown_/...\n",

    "KEYWORDS = [\n",

    "    Keyword('alexa',\n",

    "        max_count=100, # In practice, the max count should be much larger (e.g. 10000)\n",

    "        aliases=('ehlexa', 'eelexa', 'aalexa')\n",

    "    ),\n",

    "    Keyword('_unknown_',\n",

    "        max_count=200, # In practice, the max count should be much larger (e.g. 20000)\n",

    "        aliases=(\n",

    "        'ah', 'aah', 'a', 'o', 'uh', 'ee', 'aww', 'ala',\n",

    "        'alex', 'lex', 'lexa', 'lexus', 'alexus', 'exus', 'exa',\n",

    "        'alert', 'alec', 'alef', 'alee', 'ales', 'ale',\n",

    "        'aleph', 'alefs', 'alevin', 'alegar', 'alexia',\n",

    "        'alexin', 'alexine', 'alencon', 'alexias',\n",

    "        'aleuron', 'alembic', 'alice', 'aleeyah'\n",

    "    ))\n",

    "]"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 7,

   "metadata": {},

   "outputs": [],

   "source": [

    "###################################################################################################\n",

    "# Define the augmentations to apply the keywords\n",

    "AUGMENTATIONS = [\n",

    "    Augmentation(rate=VoiceRate.xslow, pitch=VoicePitch.low),\n",

    "    Augmentation(rate=VoiceRate.xslow, pitch=VoicePitch.medium),\n",

    "    Augmentation(rate=VoiceRate.xslow, pitch=VoicePitch.high),\n",

    "    Augmentation(rate=VoiceRate.medium, pitch=VoicePitch.low),\n",

    "    Augmentation(rate=VoiceRate.medium, pitch=VoicePitch.medium),\n",

    "    Augmentation(rate=VoiceRate.medium, pitch=VoicePitch.high),\n",

    "    Augmentation(rate=VoiceRate.xfast, pitch=VoicePitch.low),\n",

    "    Augmentation(rate=VoiceRate.xfast, pitch=VoicePitch.medium),\n",

    "    Augmentation(rate=VoiceRate.xfast, pitch=VoicePitch.high),\n",

    "]"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 9,

   "metadata": {},

   "outputs": [

    {

     "name": "stdout",

     "output_type": "stream",

     "text": [

      "Listing voices ...\n",

      "Listing configurations ...\n",

      "Voice Counts\n",

      "---------------------\n",

      "  aws   : 21\n",

      "  azure : 112\n",

      "  gcp   : 96\n",

      "  Total : 229\n",

      "\n",

      "Keyword Counts\n",

      "---------------------\n",

      "  alexa:\n",

      "    aws   : 8.0\n",

      "    azure : 60.0\n",

      "    gcp   : 32.0\n",

      "    Total : 100.0\n",

      "  _unknown_:\n",

      "    azure : 105.0\n",

      "    gcp   : 80.0\n",

      "    aws   : 15.0\n",

      "    Total : 200.0\n",

      "  Overall total: 300.0\n",

      "\n",

      "Character Counts\n",

      "---------------------\n",

      "  alexa:\n",

      "    aws   : 394.0\n",

      "    azure : 10.8k\n",

      "    gcp   : 184.0\n",

      "  _unknown_:\n",

      "    azure : 19.8k\n",

      "    gcp   : 369.0\n",

      "    aws   : 623.0\n",

      "  Backend totals:\n",

      "    aws   : 1.0k\n",

      "    azure : 30.6k\n",

      "    gcp   : 553.0\n",

      "\n",

      "Generating keywords at: E://alexa_dataset\\n\n"

     ]

    },

    {

     "name": "stderr",

     "output_type": "stream",

     "text": [

      "     alexa: 100%|██████████| 100/100 [00:07<00:00, 13.52word/s]\n",

      " _unknown_: 100%|██████████| 200/200 [00:12<00:00, 16.17word/s]\n",

      "   Overall: 100%|██████████| 300/300 [00:19<00:00, 15.17word/s]\n"

     ]

    }

   ],

   "source": [

    "###################################################################################################\n",

    "# Instantiate the AudioDatasetGenerator\n",

    "with AudioDatasetGenerator(\n",

    "    out_dir=OUT_DIR,\n",

    "    n_jobs=8 # We want to generate the keywords across 8 parallel jobs\n",

    ") as generator:\n",

    "    # Load the cloud backends, installing the Python packages if necessary\n",

    "    generator.load_backend('aws', install_python_package=True)\n",

    "    generator.load_backend('gcp', install_python_package=True)\n",

    "    generator.load_backend('azure', install_python_package=True)\n",

    "\n",

    "    print('Listing voices ...')\n",

    "    voices = generator.list_voices()\n",

    "\n",

    "    # Generate a list of all possible configurations, randomly shuffle, then truncate\n",

    "    # based on the \"max_count\" specified for each keyword\n",

    "    print('Listing configurations ...')\n",

    "    all_configurations = generator.list_configurations(\n",

    "        keywords=KEYWORDS,\n",

    "        augmentations=AUGMENTATIONS,\n",

    "        voices=voices,\n",

    "        truncate=True,\n",

    "        seed=42\n",

    "    )\n",

    "    n_configs = sum(len(x) for x in all_configurations.values())\n",

    "\n",

    "    # Print a summary of the configurations\n",

    "    print(generator.get_summary(all_configurations))\n",

    "\n",

    "    input(\n",

    "        '\\nWARNING: Running this script is NOT FREE!\\n\\n'\n",

    "        'Each cloud backend charges a different rate per character.\\n'\n",

    "        'The character counts are listed above.\\n\\n'\n",

    "        'Refer to each backend\\'s docs for the latest pricing:\\n'\n",

    "        '- AWS: https://aws.amazon.com/polly/pricing\\n'\n",

    "        '- Azure: https://azure.microsoft.com/en-us/pricing/details/cognitive-services/speech-services\\n'\n",

    "        '- Google: https://cloud.google.com/text-to-speech/pricing\\n'\n",

    "        '\\nPress \"enter\" to continue and generate the dataset\\n'\n",

    "    )\n",

    "\n",

    "    # Generate the dataset (with pretty progress bars)\n",

    "    print(f'Generating keywords at: {generator.out_dir}\\n')\n",

    "    with tqdm.tqdm(total=n_configs, desc='Overall'.rjust(10), unit='word', position=1) as pb_outer:\n",

    "        for keyword, config_list in all_configurations.items():\n",

    "            with tqdm.tqdm(desc=keyword.value.rjust(10), total=len(config_list), unit='word', position=0) as pb_inner:\n",

    "                for config in config_list:\n",

    "                    generator.generate(\n",

    "                        config,\n",

    "                        on_finished=lambda _: (pb_inner.update(1), pb_outer.update(1))\n",

    "                    )\n",

    "                generator.join() # Wait for the current keyword to finish before continuing to the next"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": null,

   "metadata": {},

   "outputs": [],

   "source": [

    "# Convert the generated dataset directory into an archive (.tar.gz)\n",

    "from mltk.utils.archive import gzip_directory_files\n",

    "\n",

    "print(f'Generating archive from {OUT_DIR} (this may take awhile) ...')\n",

    "archive_path = gzip_directory_files(OUT_DIR)\n",

    "print(f'Dataset archive path: {archive_path}')"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": null,

   "metadata": {},

   "outputs": [],

   "source": [

    "try:\n",

    "  # If this is executing from Google Colab, then download the dataset archive\n",

    "  from google.colab import files\n",

    "  files.download(archive_path)\n",

    "except:\n",

    "  pass"

   ]

  },

  {

   "attachments": {},

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "## Next Steps\n",

    "\n",

    "See the [Keyword Spotting - Alexa](../../mltk/tutorials/keyword_spotting_alexa.md) tutorial for how to use this dataset to train a keyword spotting model."

   ]

  }

 ],

 "metadata": {

  "kernelspec": {

   "display_name": ".venv",

   "language": "python",

   "name": "python3"

  },

  "language_info": {

   "codemirror_mode": {

    "name": "ipython",

    "version": 3

   },

   "file_extension": ".py",

   "mimetype": "text/x-python",

   "name": "python",

   "nbconvert_exporter": "python",

   "pygments_lexer": "ipython3",

   "version": "3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]"

  },

  "orig_nbformat": 4,

  "vscode": {

   "interpreter": {

    "hash": "1b794eb47024974fee893fdb7015f3d322c4012087fc39c73069299b7c169399"

   }

  }

 },

 "nbformat": 4,

 "nbformat_minor": 2

}

