{

 "cells": [

  {

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "# TF-Lite Micro Model API Examples\n",

    "\n",

    "This demonstrates how to use the [TF-Lite Micro Model](../../docs/python_api/tflite_micro_model/index.md) package.\n",

    "\n",

    "__NOTES:__  \n",

    "- Click here: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/siliconlabs/mltk/blob/master/mltk/examples/tflite_micro_model.ipynb) to run this example interactively in your browser  \n",

    "- Refer to the [Notebook Examples Guide](../../docs/guides/notebook_examples_guide.md) for how to run this example locally in VSCode "

   ]

  },

  {

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "## Install MLTK Python Package"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": null,

   "metadata": {},

   "outputs": [],

   "source": [

    "# Install the MLTK Python package (if necessary)\n",

    "!pip install --upgrade silabs-mltk"

   ]

  },

  {

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "## Import Python Packages"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": null,

   "metadata": {},

   "outputs": [],

   "source": [

    "# Import the standard Python packages used by the examples\n",

    "import os\n",

    "import urllib\n",

    "import shutil\n",

    "import tempfile"

   ]

  },

  {

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "## Download .tflite model file\n",

    "\n",

    "A `.tflite` model file is required to run these examples.  \n",

    "The following code downloads a model.\n",

    "\n",

    "__NOTE:__ Update `TFLITE_MODEL_URL` or `tflite_path` to point to your model if necessary"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": null,

   "metadata": {},

   "outputs": [],

   "source": [

    "# Use .tflite mode found here:\n",

    "# https://github.com/siliconlabs/mltk/tree/master/mltk/utils/test_helper/data/\n",

    "# NOTE: Update this URL to point to your model if necessary\n",

    "TFLITE_MODEL_URL = 'https://github.com/siliconlabs/mltk/raw/master/mltk/utils/test_helper/data/image_example1.tflite'\n",

    "\n",

    "# Download the .tflite file and save to the temp dir\n",

    "tflite_path = os.path.normpath(f'{tempfile.gettempdir()}/image_example1.tflite')\n",

    "with open(tflite_path, 'wb') as dst:\n",

    "    with urllib.request.urlopen(TFLITE_MODEL_URL) as src:\n",

    "        shutil.copyfileobj(src, dst)"

   ]

  },

  {

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "## Example 1: Load model and print summary\n",

    "\n",

    "This example loads `.tflite` model file and prints a summary of it"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": null,

   "metadata": {},

   "outputs": [

    {

     "name": "stdout",

     "output_type": "stream",

     "text": [

      "Using Tensorflow-Lite Micro version: b13b48c (2022-06-08)\n",

      "Runtime memory size from .tflite model: 0\n",

      "Searching for optimal runtime memory size ...\n",

      "Determined optimal runtime memory size to be 72192\n",

      "Name: image_example1\n",

      "Version: 1\n",

      "Date: 2021-08-18T16:51:34.028Z\n",

      "Description: \n",

      "Hash: e8463b1e31855c5e6319493226b8b582\n",

      "Accelerator: none\n",

      "Classes: rock, paper, scissor\n",

      "Total runtime memory: 71.472 kBytes\n",

      "\n"

     ]

    }

   ],

   "source": [

    "from mltk.core.tflite_micro import TfliteMicro\n",

    "\n",

    "tflite_micro_model = TfliteMicro.load_tflite_model(tflite_path)\n",

    "\n",

    "print(tflite_micro_model)\n",

    "\n",

    "TfliteMicro.unload_model(tflite_micro_model)"

   ]

  },

  {

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "## Example 2: Profile .tflite in TFLM interpreter\n",

    "\n",

    "This example loads `.tflite` model file, profiles it in the Tensorflow-Lite Micro interpreter, and prints the profiling summary.\n",

    "\n",

    "__NOTE:__ Some of the profile metrics are estimated, see the [Model Profiler](../../docs/guides/model_profiler.md) for more details."

   ]

  },

  {

   "cell_type": "code",

   "execution_count": null,

   "metadata": {},

   "outputs": [

    {

     "name": "stdout",

     "output_type": "stream",

     "text": [

      "Using Tensorflow-Lite Micro version: b13b48c (2022-06-08)\n",

      "Searching for optimal runtime memory size ...\n",

      "Determined optimal runtime memory size to be 72192\n",

      "Profiling Summary\n",

      "Name: None\n",

      "Accelerator: None\n",

      "Input Shape: 1x96x96x1\n",

      "Input Data Type: int8\n",

      "Output Shape: 1x3\n",

      "Output Data Type: int8\n",

      "Flash, Model File Size (bytes): 15.7k\n",

      "RAM, Runtime Memory Size (bytes): 71.5k\n",

      "Operation Count: 2.6M\n",

      "Multiply-Accumulate Count: 1.2M\n",

      "Layer Count: 8\n",

      "Unsupported Layer Count: 0\n",

      "CPU Cycle Count: 13.1M\n",

      "CPU Utilization (%): 0.0\n",

      "Clock Rate (hz): 78.0M\n",

      "Energy (J): 2.3m\n",

      "J/Op: 884.5p\n",

      "J/MAC: 2.0n\n",

      "\n",

      "Model Layers\n",

      "+-------+-----------------+--------+--------+------------+------------+-------------------------+--------------+-----------------------------------------------------+\n",

      "| Index | OpCode          | # Ops  | # MACs | CPU Cycles | Energy (J) | Input Shape             | Output Shape | Options                                             |\n",

      "+-------+-----------------+--------+--------+------------+------------+-------------------------+--------------+-----------------------------------------------------+\n",

      "| 0     | conv_2d         | 1.2M   | 497.7k | 10.0M      | 1.9m       | 1x96x96x1,24x3x3x1,24   | 1x48x48x24   | Padding:same stride:2x2 activation:relu             |\n",

      "| 1     | average_pool_2d | 69.1k  | 0      | 985.7k     | 148.0u     | 1x48x48x24              | 1x24x24x24   | Padding:valid stride:2x2 filter:2x2 activation:none |\n",

      "| 2     | conv_2d         | 842.2k | 418.2k | 1.3M       | 187.5u     | 1x24x24x24,16x3x3x24,16 | 1x11x11x16   | Padding:valid stride:2x2 activation:relu            |\n",

      "| 3     | conv_2d         | 565.7k | 279.9k | 718.6k     | 105.7u     | 1x11x11x16,24x3x3x16,24 | 1x9x9x24     | Padding:valid stride:1x1 activation:relu            |\n",

      "| 4     | average_pool_2d | 1.9k   | 0      | 30.8k      | 9.3u       | 1x9x9x24                | 1x4x4x24     | Padding:valid stride:2x2 filter:2x2 activation:none |\n",

      "| 5     | reshape         | 0      | 0      | 250.4      | 0.0p       | 1x4x4x24,2              | 1x384        | Type=none                                           |\n",

      "| 6     | fully_connected | 2.3k   | 1.2k   | 5.2k       | 21.5n      | 1x384,3x384,3           | 1x3          | Activation:none                                     |\n",

      "| 7     | softmax         | 15.0   | 0      | 3.8k       | 16.5n      | 1x3                     | 1x3          | Type=softmaxoptions                                 |\n",

      "+-------+-----------------+--------+--------+------------+------------+-------------------------+--------------+-----------------------------------------------------+\n"

     ]

    }

   ],

   "source": [

    "from mltk.core.tflite_micro import TfliteMicro\n",

    "\n",

    "# Profile the model in the TFLM interpreter\n",

    "profiling_results = TfliteMicro.profile_model(tflite_path)\n",

    "\n",

    "print(profiling_results)"

   ]

  },

  {

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "## Example 3: Record each layers' input/output tensor\n",

    "\n",

    "This runs inference in the TFLM interpreter and records each layers' input/output tensors."

   ]

  },

  {

   "cell_type": "code",

   "execution_count": null,

   "metadata": {},

   "outputs": [

    {

     "name": "stdout",

     "output_type": "stream",

     "text": [

      "Using Tensorflow-Lite Micro version: b13b48c (2022-06-08)\n",

      "Layer: op0-conv_2d\n",

      "\tInput 0: conv2d_input_int8, dtype:int8, shape:1x96x96x1\n",

      "\tInput 1: image_example1/conv2d/Conv2D, dtype:int8, shape:24x3x3x1\n",

      "\tInput 2: image_example1/conv2d/BiasAdd/ReadVariableOp/resource, dtype:int32, shape:24\n",

      "\tOutput 0: image_example1/conv2d/Relu;image_example1/conv2d/BiasAdd;image_example1/conv2d_2/Conv2D;image_example1/conv2d/Conv2D;image_example1/conv2d/BiasAdd/ReadVariableOp/resource, dtype:int8, shape:1x48x48x24\n",

      "Layer: op1-average_pool_2d\n",

      "\tInput 0: image_example1/conv2d/Relu;image_example1/conv2d/BiasAdd;image_example1/conv2d_2/Conv2D;image_example1/conv2d/Conv2D;image_example1/conv2d/BiasAdd/ReadVariableOp/resource, dtype:int8, shape:1x48x48x24\n",

      "\tOutput 0: image_example1/average_pooling2d/AvgPool, dtype:int8, shape:1x24x24x24\n",

      "Layer: op2-conv_2d\n",

      "\tInput 0: image_example1/average_pooling2d/AvgPool, dtype:int8, shape:1x24x24x24\n",

      "\tInput 1: image_example1/conv2d_1/Conv2D, dtype:int8, shape:16x3x3x24\n",

      "\tInput 2: image_example1/conv2d_1/BiasAdd/ReadVariableOp/resource, dtype:int32, shape:16\n",

      "\tOutput 0: image_example1/conv2d_1/Relu;image_example1/conv2d_1/BiasAdd;image_example1/conv2d_1/Conv2D;image_example1/conv2d_1/BiasAdd/ReadVariableOp/resource, dtype:int8, shape:1x11x11x16\n",

      "Layer: op3-conv_2d\n",

      "\tInput 0: image_example1/conv2d_1/Relu;image_example1/conv2d_1/BiasAdd;image_example1/conv2d_1/Conv2D;image_example1/conv2d_1/BiasAdd/ReadVariableOp/resource, dtype:int8, shape:1x11x11x16\n",

      "\tInput 1: image_example1/conv2d_2/Conv2D, dtype:int8, shape:24x3x3x16\n",

      "\tInput 2: image_example1/activation/Relu;image_example1/batch_normalization/FusedBatchNormV3;image_example1/conv2d_2/BiasAdd/ReadVariableOp/resource;image_example1/conv2d_2/BiasAdd;image_example1/conv2d_2/Conv2D, dtype:int32, shape:24\n",

      "\tOutput 0: image_example1/activation/Relu;image_example1/batch_normalization/FusedBatchNormV3;image_example1/conv2d_2/BiasAdd/ReadVariableOp/resource;image_example1/conv2d_2/BiasAdd;image_example1/conv2d_2/Conv2D1, dtype:int8, shape:1x9x9x24\n",

      "Layer: op4-average_pool_2d\n",

      "\tInput 0: image_example1/activation/Relu;image_example1/batch_normalization/FusedBatchNormV3;image_example1/conv2d_2/BiasAdd/ReadVariableOp/resource;image_example1/conv2d_2/BiasAdd;image_example1/conv2d_2/Conv2D1, dtype:int8, shape:1x9x9x24\n",

      "\tOutput 0: image_example1/average_pooling2d_1/AvgPool, dtype:int8, shape:1x4x4x24\n",

      "Layer: op5-reshape\n",

      "\tInput 0: image_example1/average_pooling2d_1/AvgPool, dtype:int8, shape:1x4x4x24\n",

      "\tInput 1: image_example1/flatten/Const, dtype:int32, shape:2\n",

      "\tOutput 0: image_example1/flatten/Reshape, dtype:int8, shape:1x384\n",

      "Layer: op6-fully_connected\n",

      "\tInput 0: image_example1/flatten/Reshape, dtype:int8, shape:1x384\n",

      "\tInput 1: image_example1/dense/MatMul, dtype:int8, shape:3x384\n",

      "\tInput 2: image_example1/dense/BiasAdd/ReadVariableOp/resource, dtype:int32, shape:3\n",

      "\tOutput 0: image_example1/dense/MatMul;image_example1/dense/BiasAdd, dtype:int8, shape:1x3\n",

      "Layer: op7-softmax\n",

      "\tInput 0: image_example1/dense/MatMul;image_example1/dense/BiasAdd, dtype:int8, shape:1x3\n",

      "\tOutput 0: Identity_int8, dtype:int8, shape:1x3\n"

     ]

    }

   ],

   "source": [

    "from mltk.core.tflite_micro import TfliteMicro\n",

    "\n",

    "recorded_layers = TfliteMicro.record_model(tflite_path)\n",

    "\n",

    "for layer in recorded_layers:\n",

    "    inputs = layer.inputs \n",

    "    output = layer.outputs \n",

    "\n",

    "    print(f'Layer: {layer.name}')\n",

    "    for i, inp in enumerate(inputs):\n",

    "        print(f'\\tInput {i}: {inp}')\n",

    "    for i, outp in enumerate(output):\n",

    "        print(f'\\tOutput {i}: {outp}')"

   ]

  }

 ],

 "metadata": {

  "kernelspec": {

   "display_name": "Python 3.9.7 ('.venv': venv)",

   "language": "python",

   "name": "python3"

  },

  "language_info": {

   "codemirror_mode": {

    "name": "ipython",

    "version": 3

   },

   "file_extension": ".py",

   "mimetype": "text/x-python",

   "name": "python",

   "nbconvert_exporter": "python",

   "pygments_lexer": "ipython3",

   "version": "3.9.7"

  },

  "orig_nbformat": 4,

  "vscode": {

   "interpreter": {

    "hash": "600e22ae316f8c315f552eaf99bb679bc9438a443c93affde9ac001991b79c8f"

   }

  }

 },

 "nbformat": 4,

 "nbformat_minor": 2

}

